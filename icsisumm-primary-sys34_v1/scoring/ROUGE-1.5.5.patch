diff -rupN RELEASE-1.5.5/ROUGE-1.5.5_faster.pl ROUGE-1.5.5/ROUGE-1.5.5_faster.pl
--- RELEASE-1.5.5/ROUGE-1.5.5_faster.pl	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/ROUGE-1.5.5_faster.pl	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,3325 @@
+#!/usr/bin/perl -w 
+# NOTE: faster version by caching ngrams, modified by Benoit Favre (favre@icsi.berkeley.edu) 2008-05-19
+#
+# Version:     ROUGE v1.5.5
+# Date:        05/26/2005,05/19/2005,04/26/2005,04/03/2005,10/28/2004,10/25/2004,10/21/2004
+# Author:      Chin-Yew Lin
+# Description: Given an evaluation description file, for example: test.xml,
+#              this script computes the averages of the average ROUGE scores for 
+#              the evaluation pairs listed in the ROUGE evaluation configuration file.
+#              For more information, please see:
+#              http://www.isi.edu/~cyl/ROUGE
+#              For more information about Basic Elements, please see:
+#              http://www.isi.edu/~cyl/BE
+# Revision Note:
+#              1.5.5
+#              (1) Correct stemming on multi-token BE heads and modifiers.
+#                  Previously, only single token heads and modifiers were assumed.
+#              (2) Correct the resampling routine which ignores the last evaluation
+#                  item in the evaluation list. Therefore, the average scores reported
+#                  by ROUGE is only based on the first N-1 evaluation items.
+#                  Thanks Barry Schiffman at Columbia University to report this bug.
+#                  This bug only affects ROUGE-1.5.X. For pre-1.5 ROUGE, it only affects
+#                  the computation of confidence interval (CI) estimation, i.e. CI is only
+#                  estimated by the first N-1 evaluation items, but it *does not* affect
+#                  average scores.
+#              (3) Change read_text and read_text_LCS functions to read exact words or
+#                  bytes required by users. Previous versions carry out whitespace 
+#                  compression and other string clear up actions before enforce the length
+#                  limit. 
+#              1.5.4.1
+#              (1) Minor description change about "-t 0" option.
+#              1.5.4
+#              (1) Add easy evalution mode for single reference evaluations with -z
+#                  option.
+#              1.5.3
+#              (1) Add option to compute ROUGE score based on SIMPLE BE format. Given
+#                  a set of peer and model summary file in BE format with appropriate
+#                  options, ROUGE will compute matching scores based on BE lexical
+#                  matches.
+#                  There are 6 options:
+#                  1. H    : Head only match. This is similar to unigram match but
+#                            only BE Head is used in matching. BEs generated by
+#                            Minipar-based breaker do not include head-only BEs,
+#                            therefore, the score will always be zero. Use HM or HMR
+#                            optiions instead.
+#                  2. HM   : Head and modifier match. This is similar to bigram or
+#                            skip bigram but it's head-modifier bigram match based on
+#                            parse result. Only BE triples with non-NIL modifier are
+#                            included in the matching.
+#                  3. HMR  : Head, modifier, and relation match. This is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. Only BE triples with non-NIL
+#                            relation are included in the matching.
+#                  4. HM1  : This is combination of H and HM. It is similar to unigram +
+#                            bigram or skip bigram with unigram match but it's 
+#                            head-modifier bigram match based on parse result.
+#                            In this case, the modifier field in a BE can be "NIL"
+#                  5. HMR1 : This is combination of HM and HMR. It is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. In this case, the relation
+#                            field of the BE can be "NIL".
+#                  6. HMR2 : This is combination of H, HM and HMR. It is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. In this case, the modifier and
+#                            relation fields of the BE can both be "NIL".
+#              1.5.2
+#              (1) Add option to compute ROUGE score by token using the whole corpus
+#                  as average unit instead of individual sentences. Previous versions of
+#                  ROUGE uses sentence (or unit) boundary to break counting unit and takes
+#                  the average score from the counting unit as the final score.
+#                  Using the whole corpus as one single counting unit can potentially
+#                  improve the reliablity of the final score that treats each token as
+#                  equally important; while the previous approach considers each sentence as
+#                  equally important that ignores the length effect of each individual
+#                  sentences (i.e. long sentences contribute equal weight to the final
+#                  score as short sentences.)
+#                  +v1.2 provide a choice of these two counting modes that users can
+#                  choose the one that fits their scenarios.
+#              1.5.1
+#              (1) Add precision oriented measure and f-measure to deal with different lengths
+#                  in candidates and references. Importance between recall and precision can
+#                  be controled by 'alpha' parameter:
+#                  alpha -> 0: recall is more important
+#                  alpha -> 1: precision is more important
+#                  Following Chapter 7 in C.J. van Rijsbergen's "Information Retrieval".
+#                  http://www.dcs.gla.ac.uk/Keith/Chapter.7/Ch.7.html
+#                  F = 1/(alpha * (1/P) + (1 - alpha) * (1/R)) ;;; weighted harmonic mean
+#              1.4.2
+#              (1) Enforce length limit at the time when summary text is read. Previously (before
+#                  and including v1.4.1), length limit was enforced at tokenization time.
+#              1.4.1
+#              (1) Fix potential over counting in ROUGE-L and ROUGE-W
+#                  In previous version (i.e. 1.4 and order), LCS hit is computed
+#                  by summing union hit over all model sentences. Each model sentence
+#                  is compared with all peer sentences and mark the union LCS. The
+#                  length of the union LCS is the hit of that model sentence. The
+#                  final hit is then sum over all model union LCS hits. This potentially
+#                  would over count a peer sentence which already been marked as contributed
+#                  to some other model sentence. Therefore, double counting is resulted.
+#                  This is seen in evalution where ROUGE-L score is higher than ROUGE-1 and
+#                  this is not correct.
+#                  ROUGEeval-1.4.1.pl fixes this by add a clip function to prevent
+#                  double counting.
+#              1.4
+#              (1) Remove internal Jackknifing procedure:
+#                  Now the ROUGE script will use all the references listed in the
+#                  <MODEL></MODEL> section in each <EVAL></EVAL> section and no
+#                  automatic Jackknifing is performed. Please see RELEASE-NOTE.txt
+#                  for more details.
+#              1.3
+#              (1) Add skip bigram
+#              (2) Add an option to specify the number of sampling point (default is 1000)
+#              1.2.3
+#              (1) Correct the enviroment variable option: -e. Now users can specify evironment
+#                  variable ROUGE_EVAL_HOME using the "-e" option; previously this option is
+#                  not active. Thanks Zhouyan Li of Concordia University, Canada pointing this
+#                  out.
+#              1.2.2
+#              (1) Correct confidence interval calculation for median, maximum, and minimum.
+#                  Line 390.
+#              1.2.1
+#              (1) Add sentence per line format input format. See files in Verify-SPL for examples.
+#              (2) Streamline command line arguments.
+#              (3) Use bootstrap resampling to estimate confidence intervals instead of using t-test
+#                  or z-test which assume a normal distribution.
+#              (4) Add LCS (longest common subsequence) evaluation method.
+#              (5) Add WLCS (weighted longest common subsequence) evaluation method.
+#              (6) Add length cutoff in bytes.
+#              (7) Add an option to specify the longest ngram to compute. The default is 4.
+#              1.2
+#              (1) Change zero condition check in subroutine &computeNGramScores when
+#                  computing $gram1Score from
+#                  if($totalGram2Count!=0)  to
+#                  if($totalGram1Count!=0)
+#                  Thanks Ken Litkowski for this bug report.
+#                  This original script will set gram1Score to zero if there is no
+#                  bigram matches. This should rarely has significant affect the final score
+#                  since (a) there are bigram matches most of time; (b) the computation
+#                  of gram1Score is using Jackknifing procedure. However, this definitely
+#                  did not compute the correct $gram1Score when there is no bigram matches.
+#                  Therefore, users of version 1.1 should definitely upgrade to newer
+#                  version of the script that does not contain this bug.
+# Note:        To use this script, two additional data files are needed:
+#              (1) smart_common_words.txt - contains stopword list from SMART IR engine
+#              (2) WordNet-2.0.exc.db - WordNet 2.0 exception inflexion database
+#              These two files have to be put in a directory pointed by the environment
+#              variable: "ROUGE_EVAL_HOME".
+#              If environment variable ROUGE_EVAL_HOME does not exist, this script will
+#              will assume it can find these two database files in the current directory.
+# COPYRIGHT (C) UNIVERSITY OF SOUTHERN CALIFORNIA, 2002,2003,2004
+# University of Southern California                                           
+# Information Sciences Institute                                              
+# 4676 Admiralty Way                                                          
+# Marina Del Rey, California 90292-6695                                       
+#                                                                             
+# This software was partially developed under SPAWAR Grant No.
+# N66001-00-1-8916 , and  the Government holds license rights under
+# DAR 7-104.9(a)(c)(1).  It is  
+# transmitted outside of the University of Southern California only under 
+# written license agreements or software exchange agreements, and its use   
+# is limited by these agreements.  At no time shall any recipient use       
+# this software in any manner which conflicts or interferes with the        
+# governmental license rights or other provisions of the governing           
+# agreement under which it is obtained.  It is supplied "AS IS," without     
+# any warranties of any kind.  It is furnished only on the basis that any    
+# party who receives it indemnifies and holds harmless the parties who       
+# furnish and originate it against any claims, demands or liabilities        
+# connected with using it, furnishing it to others or providing it to a      
+# third party.  THIS NOTICE MUST NOT BE REMOVED FROM THE SOFTWARE,
+# AND IN THE EVENT THAT THE SOFTWARE IS DIVIDED, IT SHOULD BE
+# ATTACHED TO EVERY PART.
+#
+# Contributor to its design is Chin-Yew Lin.
+
+use XML::DOM;
+use DB_File;
+use Getopt::Std;
+#-------------------------------------------------------------------------------------
+use vars qw($opt_a $opt_b $opt_c $opt_d $opt_e $opt_f $opt_h $opt_H $opt_m $opt_n $opt_p $opt_s $opt_t $opt_l $opt_v $opt_w $opt_2 $opt_u $opt_x $opt_U $opt_3 $opt_M $opt_z);
+my $usageFull="$0\n         [-a (evaluate all systems)] 
+         [-c cf]
+         [-d (print per evaluation scores)] 
+         [-e ROUGE_EVAL_HOME] 
+         [-h (usage)] 
+         [-H (detailed usage)] 
+         [-b n-bytes|-l n-words] 
+         [-m (use Porter stemmer)] 
+         [-n max-ngram] 
+         [-s (remove stopwords)] 
+         [-r number-of-samples (for resampling)] 
+         [-2 max-gap-length (if < 0 then no gap length limit)] 
+         [-3 <H|HM|HMR|HM1|HMR1|HMR2> (for scoring based on BE)] 
+         [-u (include unigram in skip-bigram) default no)] 
+         [-U (same as -u but also compute regular skip-bigram)] 
+         [-w weight (weighting factor for WLCS)] 
+         [-v (verbose)] 
+         [-x (do not calculate ROUGE-L)] 
+         [-f A|B (scoring formula)] 
+         [-p alpha (0 <= alpha <=1)] 
+         [-t 0|1|2 (count by token instead of sentence)] 
+         [-z <SEE|SPL|ISI|SIMPLE>] 
+         <ROUGE-eval-config-file> [<systemID>]\n
+".
+  "ROUGE-eval-config-file: Specify the evaluation setup. Three files come with the ROUGE evaluation package, i.e.\n".
+  "          ROUGE-test.xml, verify.xml, and verify-spl.xml are good examples.\n".
+  "systemID: Specify which system in the ROUGE-eval-config-file to perform the evaluation.\n".
+  "          If '-a' option is used, then all systems are evaluated and users do not need to\n".
+  "          provide this argument.\n".
+  "Default:\n".
+  "  When running ROUGE without supplying any options (except -a), the following defaults are used:\n".
+  "  (1) ROUGE-L is computed;\n".
+  "  (2) 95% confidence interval;\n".
+  "  (3) No stemming;\n".
+  "  (4) Stopwords are inlcuded in the calculations;\n".
+  "  (5) ROUGE looks for its data directory first through the ROUGE_EVAL_HOME environment variable. If\n".
+  "      it is not set, the current directory is used.\n".
+  "  (6) Use model average scoring formula.\n".
+  "  (7) Assign equal importance of ROUGE recall and precision in computing ROUGE f-measure, i.e. alpha=0.5.\n".
+  "  (8) Compute average ROUGE by averaging sentence (unit) ROUGE scores.\n".
+  "Options:\n".
+  "  -2: Compute skip bigram (ROGUE-S) co-occurrence, also specify the maximum gap length between two words (skip-bigram)\n".
+  "  -u: Compute skip bigram as -2 but include unigram, i.e. treat unigram as \"start-sentence-symbol unigram\"; -2 has to be specified.\n".
+  "  -3: Compute BE score. Currently only SIMPLE BE triple format is supported.\n".
+  "      H    -> head only scoring (does not applied to Minipar-based BEs).\n".
+  "      HM   -> head and modifier pair scoring.\n".
+  "      HMR  -> head, modifier and relation triple scoring.\n".
+  "      HM1  -> H and HM scoring (same as HM for Minipar-based BEs).\n".
+  "      HMR1 -> HM and HMR scoring (same as HMR for Minipar-based BEs).\n".
+  "      HMR2 -> H, HM and HMR scoring (same as HMR for Minipar-based BEs).\n".
+  "  -a: Evaluate all systems specified in the ROUGE-eval-config-file.\n".
+  "  -c: Specify CF\% (0 <= CF <= 100) confidence interval to compute. The default is 95\% (i.e. CF=95).\n".
+  "  -d: Print per evaluation average score for each system.\n".
+  "  -e: Specify ROUGE_EVAL_HOME directory where the ROUGE data files can be found.\n".
+  "      This will overwrite the ROUGE_EVAL_HOME specified in the environment variable.\n".
+  "  -f: Select scoring formula: 'A' => model average; 'B' => best model\n".
+  "  -h: Print usage information.\n".
+  "  -H: Print detailed usage information.\n".
+  "  -b: Only use the first n bytes in the system/peer summary for the evaluation.\n".
+  "  -l: Only use the first n words in the system/peer summary for the evaluation.\n".
+  "  -m: Stem both model and system summaries using Porter stemmer before computing various statistics.\n".
+  "  -n: Compute ROUGE-N up to max-ngram length will be computed.\n".
+  "  -p: Relative importance of recall and precision ROUGE scores. Alpha -> 1 favors precision, Alpha -> 0 favors recall.\n".
+  "  -s: Remove stopwords in model and system summaries before computing various statistics.\n".
+  "  -t: Compute average ROUGE by averaging over the whole test corpus instead of sentences (units).\n".
+  "      0: use sentence as counting unit, 1: use token as couting unit, 2: same as 1 but output raw counts\n".
+  "      instead of precision, recall, and f-measure scores. 2 is useful when computation of the final,\n".
+  "      precision, recall, and f-measure scores will be conducted later.\n".
+  "  -r: Specify the number of sampling point in bootstrap resampling (default is 1000).\n".
+  "      Smaller number will speed up the evaluation but less reliable confidence interval.\n".
+  "  -w: Compute ROUGE-W that gives consecutive matches of length L in an LCS a weight of 'L^weight' instead of just 'L' as in LCS.\n".
+  "      Typically this is set to 1.2 or other number greater than 1.\n".
+  "  -v: Print debugging information for diagnositic purpose.\n".
+  "  -x: Do not calculate ROUGE-L.\n".
+  "  -z: ROUGE-eval-config-file is a list of peer-model pair per line in the specified format (SEE|SPL|ISI|SIMPLE).\n";
+
+my $usage="$0\n         [-a (evaluate all systems)] 
+         [-c cf]
+         [-d (print per evaluation scores)] 
+         [-e ROUGE_EVAL_HOME] 
+         [-h (usage)] 
+         [-H (detailed usage)] 
+         [-b n-bytes|-l n-words] 
+         [-m (use Porter stemmer)] 
+         [-n max-ngram] 
+         [-s (remove stopwords)] 
+         [-r number-of-samples (for resampling)] 
+         [-2 max-gap-length (if < 0 then no gap length limit)] 
+         [-3 <H|HM|HMR|HM1|HMR1|HMR2> (for scoring based on BE)] 
+         [-u (include unigram in skip-bigram) default no)] 
+         [-U (same as -u but also compute regular skip-bigram)] 
+         [-w weight (weighting factor for WLCS)] 
+         [-v (verbose)] 
+         [-x (do not calculate ROUGE-L)] 
+         [-f A|B (scoring formula)] 
+         [-p alpha (0 <= alpha <=1)] 
+         [-t 0|1|2 (count by token instead of sentence)] 
+         [-z <SEE|SPL|ISI|SIMPLE>] 
+         <ROUGE-eval-config-file> [<systemID>]
+";
+getopts('ahHb:c:de:f:l:mMn:p:st:r:2:3:w:uUvxz:');
+my $systemID;
+
+die $usageFull if defined($opt_H);
+die $usage if defined($opt_h)||@ARGV==0;
+die "Please specify the ROUGE configuration file or use option '-h' for help\n" if(@ARGV==0);
+if(@ARGV==1&&defined($opt_z)) {
+  $systemID="X"; # default system ID
+}
+elsif(@ARGV==1&&!defined($opt_a)) {
+  die "Please specify a system ID to evaluate or use option '-a' to evaluate all systems. For more information, use option '-h'.\n";
+}
+elsif(@ARGV==2) {
+  $systemID=$ARGV[1];
+}
+if(defined($opt_e)) {
+  $stopwords="$opt_e/smart_common_words.txt";
+  $wordnetDB="$opt_e/WordNet-2.0.exc.db";
+}
+else {
+  if(exists($ENV{"ROUGE_EVAL_HOME"})) {
+    $stopwords="$ENV{\"ROUGE_EVAL_HOME\"}/smart_common_words.txt";
+    $wordnetDB="$ENV{\"ROUGE_EVAL_HOME\"}/WordNet-2.0.exc.db";
+  }
+  elsif(exists($ENV{"RED_EVAL_HOME"})) {
+    $stopwords="$ENV{\"RED_EVAL_HOME\"}/smart_common_words.txt";
+    $wordnetDB="$ENV{\"RED_EVAL_HOME\"}/WordNet-2.0.exc.db";
+  }
+  else {
+    # if no environment variable exists then assume data files are in the current directory
+    $stopwords="smart_common_words.txt";
+    $wordnetDB="WordNet-2.0.exc.db";
+  }
+}
+
+if(defined($opt_s)) {
+  $useStopwords=0; # do not use stop words
+}
+else {
+  $useStopwords=1; # use stop words
+}
+
+if(defined($opt_l)&&defined($opt_b)) {
+  die "Please specify length limit in words or bytes but not both.\n";
+}
+
+if(defined($opt_l)) {
+  $lengthLimit=$opt_l;
+  $byteLimit=0;   # no byte limit
+}
+elsif(defined($opt_b)) {
+  $lengthLimit=0; # no length limit in words
+  $byteLimit=$opt_b;
+}
+else {
+  $byteLimit=0;   # no byte limit
+  $lengthLimit=0; # no length limit
+}
+
+unless(defined($opt_c)) {
+  $opt_c=95;
+}
+else {
+  if($opt_c<0||$opt_c>100) {
+    die "Confidence interval should be within 0 and 100. Use option -h for more details.\n";
+  }
+}
+
+if(defined($opt_w)) {
+  if($opt_w>0) {
+    $weightFactor=$opt_w;
+  }
+  else {
+    die "ROUGE-W weight factor must greater than 0.\n";
+  }
+}
+#unless(defined($opt_n)) {
+#    $opt_n=4; # default maximum ngram is 4
+#}
+if(defined($opt_v)) {
+  $debug=1;
+}
+else {
+  $debug=0;
+}
+
+if(defined($opt_r)) {
+  $numOfResamples=$opt_r;
+}
+else {
+  $numOfResamples=1000;
+}
+
+if(defined($opt_2)) {
+  $skipDistance=$opt_2;
+}
+
+if(defined($opt_3)) {
+  $BEMode=$opt_3;
+}
+
+if(defined($opt_f)) {
+  $scoreMode=$opt_f;
+}
+else {
+  $scoreMode="A"; # default: use model average scoring formula
+}
+
+if(defined($opt_p)) {
+  $alpha=$opt_p;
+  if($alpha<0||
+     $alpha>1) {
+    die "Relative importance of ROUGE recall and precision has to be between 0 and 1 inclusively.\n";
+  }
+}
+else {
+  $alpha=0.5; # default is equal importance of ROUGE recall and precision
+}
+
+if(defined($opt_t)) {
+  # make $opt_t as undef when appropriate option is given
+  # when $opt_t is undef, sentence level average will be used
+  if($opt_t==0) {
+    $opt_t=undef;
+  }
+  elsif($opt_t!=1&&
+	$opt_t!=2) {
+    $opt_t=undef; # other than 1 or 2, let $opt_t to be undef
+  }
+}
+
+if(defined($opt_z)) {
+  # If opt_z is specified, the user has to specify a system ID that
+  # is used for identification therefore -a option is not allowed.
+  # Here we make it undef.
+  $opt_a=undef;
+}
+#-------------------------------------------------------------------------------------
+# Setup ROUGE scoring parameters
+%ROUGEParam=();   # ROUGE scoring parameter
+if(defined($lengthLimit)) {
+  $ROUGEParam{"LENGTH"}=$lengthLimit;
+}
+else {
+  $ROUGEParam{"LENGTH"}=undef;
+}
+if(defined($byteLimit)) {
+  $ROUGEParam{"BYTE"}=$byteLimit;
+}
+else {
+  $ROUGEParam{"BYTE"}=undef;
+}
+if(defined($opt_n)) { # ngram size
+  $ROUGEParam{"NSIZE"}=$opt_n;
+}
+else {
+  $ROUGEParam{"NSIZE"}=undef;
+}
+if(defined($weightFactor)) {
+  $ROUGEParam{"WEIGHT"}=$weightFactor;
+}
+else {
+  $ROUGEParam{"WEIGHT"}=undef;
+}
+if(defined($skipDistance)) {
+  $ROUGEParam{"SD"}=$skipDistance;
+}
+else {
+  $ROUGEParam{"SD"}=undef;
+}
+if(defined($scoreMode)) {
+  $ROUGEParam{"SM"}=$scoreMode;
+}
+else {
+  $ROUGEParam{"SM"}=undef;
+}
+if(defined($alpha)) {
+  $ROUGEParam{"ALPHA"}=$alpha;
+}
+else {
+  $ROUGEParam{"ALPHA"}=undef;
+}
+if(defined($opt_t)) {
+  $ROUGEParam{"AVERAGE"}=$opt_t;
+}
+else {
+  $ROUGEParam{"AVERAGE"}=undef;
+}
+if(defined($opt_3)) {
+  $ROUGEParam{"BEMODE"}=$opt_3;
+}
+else {
+  $ROUGEParam{"BEMODE"}=undef;
+}
+#-------------------------------------------------------------------------------------
+# load stopwords
+%stopwords=();
+open(STOP,$stopwords)||die "Cannot open $stopwords\n";
+while(defined($line=<STOP>)) {
+  chomp($line);
+  $stopwords{$line}=1;
+}
+close(STOP);
+# load WordNet database
+if(-e "$wordnetDB") {
+  tie %exceptiondb,'DB_File',"$wordnetDB",O_RDONLY,0440,$DB_HASH or
+    die "Cannot open exception db file for reading: $wordnetDB\n";
+}
+else {
+  die "Cannot open exception db file for reading: $wordnetDB\n";
+}
+#-------------------------------------------------------------------------------------
+# Initialize Porter Stemmer
+&initialise();
+#-------------------------------------------------------------------------------------
+# Read and parse the document
+my $parser = new XML::DOM::Parser;
+my $doc;
+unless(defined($opt_z)) {
+  $doc=$parser->parsefile($ARGV[0]);
+}
+else {
+  open($doc,$ARGV[0])||die "Cannot open $ARGV[0]\n";
+}
+%ROUGEEvals=();
+@ROUGEEvalIDs=();
+%ROUGEPeerIDTable=();
+@allPeerIDs=();
+%knownMissing=(); # remember missing submission already known
+if(defined($doc)) {
+  # read evaluation description file
+  &readEvals(\%ROUGEEvals,\@ROUGEEvalIDs,\%ROUGEPeerIDTable,$doc,undef);
+  # print evaluation configuration
+  if(defined($opt_z)) {
+    if(defined($ARGV[1])) {
+      $systemID=$ARGV[1];
+    }
+    else {
+      $systemID="X"; # default system ID in BE file list evaluation mode
+    }
+    push(@allPeerIDs,$systemID);
+  }
+  else {
+    unless(defined($opt_a)) {
+      $systemID=$ARGV[1];
+      push(@allPeerIDs,$systemID);
+    }
+    else {
+      # run evaluation for each peer listed in the description file
+      @allPeerIDs=sort (keys %ROUGEPeerIDTable);
+    }
+  }
+  foreach $peerID (@allPeerIDs) {
+    %testIDs=();
+    #	print "\@PEER($peerID)--------------------------------------------------\n";
+    if(defined($opt_n)) {
+      # evaluate a specific peer
+      # compute ROUGE score up to $opt_n-gram
+      for($n=1;$n<=$opt_n;$n++) {
+	my (%ROUGEScores,%ROUGEAverages);
+	
+	%ROUGEScores=();
+	foreach $e (@ROUGEEvalIDs) {
+	  if($debug) {
+	    print "\@Eval ($e)\n";
+	  }
+	  $ROUGEParam{"NSIZE"}=$n;
+	  &computeROUGEX("N",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	}
+	# compute averages
+	%ROUGEAverages=();
+	&computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	&printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-$n",$opt_c,$opt_t,$opt_d);
+      }
+    }
+    unless(defined($opt_x)||defined($opt_3)) {
+      #-----------------------------------------------
+      # compute LCS score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("L",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-L",$opt_c,$opt_t,$opt_d);
+    }
+    if(defined($opt_w)) {
+      #-----------------------------------------------
+      # compute WLCS score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("W",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-W-$weightFactor",$opt_c,$opt_t,$opt_d);
+    }
+    if(defined($opt_2)) {
+      #-----------------------------------------------
+      # compute skip bigram score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      if($skipDistance>=0) {
+	if(defined($opt_u)) {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+	elsif(defined($opt_U)) {
+	  # print regular skip bigram results
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S$skipDistance",$opt_c,$opt_t,$opt_d);
+	  #-----------------------------------------------
+	  # compute skip bigram with unigram extension score
+	  $opt_u=1;
+	  %ROUGEScores=();
+	  foreach $e (@ROUGEEvalIDs) {
+	    &computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	  }
+	  $opt_u=undef;
+	  # compute averages
+	  %ROUGEAverages=();
+	  &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+	else {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+      }
+      else {
+	if(defined($opt_u)) {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU*",$opt_c,$opt_t,$opt_d);
+	}
+	else {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S*",$opt_c,$opt_t,$opt_d);
+	  if(defined($opt_U)) {
+	    #-----------------------------------------------
+	    # compute skip bigram with unigram extension score
+	    $opt_u=1;
+	    %ROUGEScores=();
+	    foreach $e (@ROUGEEvalIDs) {
+	      &computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	    }
+	    $opt_u=undef;
+	    # compute averages
+	    %ROUGEAverages=();
+	    &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	    &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU*",$opt_c,$opt_t,$opt_d);
+	  }
+	}
+      }
+    }
+    if(defined($opt_3)) {
+      #-----------------------------------------------
+      # compute Basic Element triple score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("BE",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-BE-$BEMode",$opt_c,$opt_t,$opt_d);
+    }
+  }
+}
+else {
+  die "Document undefined\n";
+}
+if(defined($opt_z)) {
+  close($doc);
+}
+untie %exceptiondb;
+
+sub printResults {
+  my $peerID=shift;
+  my $ROUGEAverages=shift;
+  my $ROUGEScores=shift;
+  my $methodTag=shift;
+  my $opt_c=shift;
+  my $opt_t=shift;
+  my $opt_d=shift;
+
+  print "---------------------------------------------\n";
+  if(!defined($opt_t)||$opt_t==1) {
+    print "$peerID $methodTag Average_R: $ROUGEAverages->{'AvgR'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_R'} - $ROUGEAverages->{'CIAvgU_R'})\n";
+    print "$peerID $methodTag Average_P: $ROUGEAverages->{'AvgP'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_P'} - $ROUGEAverages->{'CIAvgU_P'})\n";
+    print "$peerID $methodTag Average_F: $ROUGEAverages->{'AvgF'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_F'} - $ROUGEAverages->{'CIAvgU_F'})\n";
+  }
+  else {
+    print "$peerID $methodTag M_count: ";
+    print int($ROUGEAverages->{'M_cnt'});
+    print " P_count: ";
+    print int($ROUGEAverages->{'P_cnt'});
+    print " H_count: ";
+    print int($ROUGEAverages->{'H_cnt'});
+    print "\n";
+  }
+  if(defined($opt_d)) {
+    print ".............................................\n";
+    &printPerEvalData($ROUGEScores,"$peerID $methodTag Eval");
+  }
+}
+
+sub bootstrapResampling {
+  my $scores=shift;
+  my $instances=shift;
+  my $seed=shift;
+  my $opt_t=shift;
+  my $sample;
+  my ($i,$ridx);
+  
+  # Use $seed to seed the random number generator to make sure
+  # we have the same random sequence every time, therefore a
+  # consistent estimation of confidence interval in different runs.
+  # This is not necessary. To ensure a consistent result in reporting
+  # results using ROUGE, this is implemented.
+  srand($seed);
+  for($i=0;$i<@{$instances};$i++) {
+    # generate a random index
+    $ridx=int(rand(@{$instances}));
+    unless(defined($sample)) {
+      # setup the resampling array
+      $sample=[];
+      push(@$sample,$scores->{$instances->[$ridx]}[0]);
+      push(@$sample,$scores->{$instances->[$ridx]}[1]);
+      push(@$sample,$scores->{$instances->[$ridx]}[2]);
+    }
+    else {
+      # update the resampling array
+      $sample->[0]+=$scores->{$instances->[$ridx]}[0];
+      $sample->[1]+=$scores->{$instances->[$ridx]}[1];
+      $sample->[2]+=$scores->{$instances->[$ridx]}[2];
+    }
+  }
+  # compute the average result for this resampling procedure
+  unless(defined($opt_t)) {
+    # per instance or sentence average
+    if(@{$instances}>0) {
+      $sample->[0]/=@{$instances};
+      $sample->[1]/=@{$instances};
+      $sample->[2]/=@{$instances};
+    }
+    else {
+      $sample->[0]=0;
+      $sample->[1]=0;
+      $sample->[2]=0;
+    }
+  }
+  else {
+    if($opt_t==1) {
+      # per token or corpus level average
+      # output recall, precision, and f-measure score
+      my ($tmpR,$tmpP,$tmpF);
+      if($sample->[0]>0) {
+	$tmpR=$sample->[2]/$sample->[0]; # recall
+      }
+      else {
+	$tmpR=0;
+      }
+      if($sample->[1]>0) {
+	$tmpP=$sample->[2]/$sample->[1]; # precision
+      }
+      else {
+	$tmpP=0;
+      }
+      if((1-$alpha)*$tmpP+$alpha*$tmpR>0) {
+	$tmpF=($tmpR*$tmpP)/((1-$alpha)*$tmpP+$alpha*$tmpR); # f-measure
+      }
+      else {
+	$tmpF=0;
+      }
+      $sample->[0]=$tmpR;
+      $sample->[1]=$tmpP;
+      $sample->[2]=$tmpF;
+    }
+    else {
+      # $opt_t!=1 => output raw model token count, peer token count, and hit count
+      # do nothing, just return $sample
+    }
+  }
+  return $sample;
+}
+
+sub by_value {
+  $a<=>$b;
+}
+
+sub printPerEvalData {
+  my $ROUGEScores=shift;
+  my $tag=shift; # tag to identify each evaluation
+  my (@instances,$i,$j);
+  
+  @instances=sort by_evalID (keys %$ROUGEScores);
+  foreach $i (@instances) {
+    # print average per evaluation score
+    print "$tag $i R:$ROUGEScores->{$i}[0] P:$ROUGEScores->{$i}[1] F:$ROUGEScores->{$i}[2]\n";
+  }
+}
+
+sub by_evalID {
+  my ($a1,$b1);
+
+  if($a=~/^([0-9]+)/o) {
+    $a1=$1;
+  }
+  if($b=~/^([0-9]+)/o) {
+    $b1=$1;
+  }
+  if(defined($a1)&&defined($b1)) {
+    return $a1<=>$b1;
+  }
+  else {
+    return $a cmp $b;
+  }
+}
+
+sub computeAverages {
+  my $ROUGEScores=shift;
+  my $ROUGEAverages=shift;
+  my $opt_t=shift;
+  my ($avgAvgROUGE_R,$resampleAvgROUGE_R);
+  my ($avgAvgROUGE_P,$resampleAvgROUGE_P);
+  my ($avgAvgROUGE_F,$resampleAvgROUGE_F);
+  my ($ciU,$ciL);
+  my (@instances,$i,$j,@rankedArray_R,@rankedArray_P,@RankedArray_F);
+  
+  @instances=sort (keys %$ROUGEScores);
+  $avgAvgROUGE_R=0;
+  $avgAvgROUGE_P=0;
+  $avgAvgROUGE_F=0;
+  $resampleAvgROUGE_R=0;
+  $resampleAvgROUGE_P=0;
+  $resampleAvgROUGE_F=0;
+  # compute totals
+  foreach $i (@instances) {
+    $avgAvgROUGE_R+=$ROUGEScores->{$i}[0]; # recall     ; or model token count
+    $avgAvgROUGE_P+=$ROUGEScores->{$i}[1]; # precision  ; or peer token count
+    $avgAvgROUGE_F+=$ROUGEScores->{$i}[2]; # f1-measure ; or match token count (hit)
+  }
+  # compute averages
+  unless(defined($opt_t)) {
+    # per sentence average
+    if((scalar @instances)>0) {
+      $avgAvgROUGE_R=sprintf("%7.5f",$avgAvgROUGE_R/(scalar @instances));
+      $avgAvgROUGE_P=sprintf("%7.5f",$avgAvgROUGE_P/(scalar @instances));
+      $avgAvgROUGE_F=sprintf("%7.5f",$avgAvgROUGE_F/(scalar @instances));
+    }
+    else {
+      $avgAvgROUGE_R=sprintf("%7.5f",0);
+      $avgAvgROUGE_P=sprintf("%7.5f",0);
+      $avgAvgROUGE_F=sprintf("%7.5f",0);
+    }
+  }
+  else {
+    if($opt_t==1) {
+      # per token average on corpus level
+      my ($tmpR,$tmpP,$tmpF);
+      if($avgAvgROUGE_R>0) {
+	$tmpR=$avgAvgROUGE_F/$avgAvgROUGE_R;
+      }
+      else {
+	$tmpR=0;
+      }
+      if($avgAvgROUGE_P>0) {
+	$tmpP=$avgAvgROUGE_F/$avgAvgROUGE_P;
+      }
+      else {
+	$tmpP=0;
+      }
+      if((1-$alpha)*$tmpP+$alpha*$tmpR>0) {
+	$tmpF=($tmpR+$tmpP)/((1-$alpha)*$tmpP+$alpha*$tmpR);
+      }
+      else {
+	$tmpF=0;
+      }
+      $avgAvgROUGE_R=sprintf("%7.5f",$tmpR);
+      $avgAvgROUGE_P=sprintf("%7.5f",$tmpP);
+      $avgAvgROUGE_F=sprintf("%7.5f",$tmpF);
+    }
+  }
+  if(!defined($opt_t)||$opt_t==1) {
+    # compute confidence intervals using bootstrap resampling
+    @ResamplingArray=();
+    for($i=0;$i<$numOfResamples;$i++) {
+      my $sample;
+      
+      $sample=&bootstrapResampling($ROUGEScores,\@instances,$i,$opt_t);
+      # sample contains average sum of the sample
+      if(@ResamplingArray==0) {
+	# setup the resampling array for Avg
+	my $s;
+	
+	$s=[];
+	push(@$s,$sample->[0]);
+	push(@ResamplingArray,$s);
+	$s=[];
+	push(@$s,$sample->[1]);
+	push(@ResamplingArray,$s);
+	$s=[];
+	push(@$s,$sample->[2]);
+	push(@ResamplingArray,$s);
+      }
+      else {
+	$rsa=$ResamplingArray[0];
+	push(@{$rsa},$sample->[0]);
+	$rsa=$ResamplingArray[1];
+	push(@{$rsa},$sample->[1]);
+	$rsa=$ResamplingArray[2];
+	push(@{$rsa},$sample->[2]);
+      }
+    }
+    # sort resampling results
+    {
+      # recall
+      @rankedArray_R=sort by_value (@{$ResamplingArray[0]});
+      $ResamplingArray[0]=\@rankedArray_R;
+      for($x=0;$x<=$#rankedArray_R;$x++) {
+	$resampleAvgROUGE_R+=$rankedArray_R[$x];
+	#	print "*R ($x): $rankedArray_R[$x]\n";
+      }
+      $resampleAvgROUGE_R=sprintf("%7.5f",$resampleAvgROUGE_R/(scalar @rankedArray_R));
+      # precision
+      @rankedArray_P=sort by_value (@{$ResamplingArray[1]});
+      $ResamplingArray[1]=\@rankedArray_P;
+      for($x=0;$x<=$#rankedArray_P;$x++) {
+	$resampleAvgROUGE_P+=$rankedArray_P[$x];
+	#	print "*P ($x): $rankedArray_P[$x]\n";
+      }
+      $resampleAvgROUGE_P=sprintf("%7.5f",$resampleAvgROUGE_P/(scalar @rankedArray_P));
+      # f1-measure
+      @rankedArray_F=sort by_value (@{$ResamplingArray[2]});
+      $ResamplingArray[2]=\@rankedArray_F;
+      for($x=0;$x<=$#rankedArray_F;$x++) {
+	$resampleAvgROUGE_F+=$rankedArray_F[$x];
+	#	print "*F ($x): $rankedArray_F[$x]\n";
+      }
+      $resampleAvgROUGE_F=sprintf("%7.5f",$resampleAvgROUGE_F/(scalar @rankedArray_F));
+    }
+    #    $ciU=999-int((100-$opt_c)*10/2); # upper bound index
+    #    $ciL=int((100-$opt_c)*10/2);     # lower bound index
+    $delta=$numOfResamples*((100-$opt_c)/2.0)/100.0;
+    $ciUa=int($numOfResamples-$delta-1); # upper confidence interval lower index
+    $ciUb=$ciUa+1;                       # upper confidence interval upper index
+    $ciLa=int($delta);                   # lower confidence interval lower index
+    $ciLb=$ciLa+1;                       # lower confidence interval upper index
+    $ciR=$numOfResamples-$delta-1-$ciUa; # ratio bewteen lower and upper indexes
+    #    $ROUGEAverages->{"AvgR"}=$avgAvgROUGE_R;
+    #-------
+    # recall
+    $ROUGEAverages->{"AvgR"}=$resampleAvgROUGE_R;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_R"}=sprintf("%7.5f",$ResamplingArray[0][$ciLa]+
+					 ($ResamplingArray[0][$ciLb]-$ResamplingArray[0][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_R"}=sprintf("%7.5f",$ResamplingArray[0][$ciUa]+
+					 ($ResamplingArray[0][$ciUb]-$ResamplingArray[0][$ciUa])*$ciR);
+    #-------
+    # precision
+    $ROUGEAverages->{"AvgP"}=$resampleAvgROUGE_P;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_P"}=sprintf("%7.5f",$ResamplingArray[1][$ciLa]+
+					 ($ResamplingArray[1][$ciLb]-$ResamplingArray[1][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_P"}=sprintf("%7.5f",$ResamplingArray[1][$ciUa]+
+					 ($ResamplingArray[1][$ciUb]-$ResamplingArray[1][$ciUa])*$ciR);
+    #-------
+    # f1-measure
+    $ROUGEAverages->{"AvgF"}=$resampleAvgROUGE_F;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_F"}=sprintf("%7.5f",$ResamplingArray[2][$ciLa]+
+					 ($ResamplingArray[2][$ciLb]-$ResamplingArray[2][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_F"}=sprintf("%7.5f",$ResamplingArray[2][$ciUa]+
+					 ($ResamplingArray[2][$ciUb]-$ResamplingArray[2][$ciUa])*$ciR);
+    $ROUGEAverages->{"M_cnt"}=$avgAvgROUGE_R; # model token count
+    $ROUGEAverages->{"P_cnt"}=$avgAvgROUGE_P; # peer token count
+    $ROUGEAverages->{"H_cnt"}=$avgAvgROUGE_F; # hit token count
+  }
+  else {
+    # $opt_t==2 => output raw count instead of precision, recall, and f-measure values
+    # in this option, no resampling is necessary, just output the raw counts
+    $ROUGEAverages->{"M_cnt"}=$avgAvgROUGE_R; # model token count
+    $ROUGEAverages->{"P_cnt"}=$avgAvgROUGE_P; # peer token count
+    $ROUGEAverages->{"H_cnt"}=$avgAvgROUGE_F; # hit token count
+  }
+}
+
+sub computeROUGEX {
+  my $metric=shift;       # which ROUGE metric to compute?
+  my $ROUGEScores=shift;
+  my $evalID=shift;
+  my $ROUGEEval=shift;    # one particular evaluation pair
+  my $peerID=shift;       # a specific peer ID
+  my $ROUGEParam=shift;   # ROUGE scoring parameters
+  my $lengthLimit;        # lenght limit in words
+  my $byteLimit;          # length limit in bytes
+  my $NSIZE;              # ngram size for ROUGE-N
+  my $weightFactor;       # weight factor for ROUGE-W
+  my $skipDistance;       # skip distance for ROUGE-S
+  my $scoreMode;          # scoring mode: A = model average; B = best model
+  my $alpha;              # relative importance between recall and precision
+  my $opt_t;              # ROUGE score counting mode
+  my $BEMode;             # Basic Element scoring mode
+  my ($c,$cx,@modelPaths,$modelIDs,$modelRoot,$inputFormat);
+
+  $lengthLimit=$ROUGEParam->{"LENGTH"};
+  $byteLimit=$ROUGEParam->{"BYTE"};
+  $NSIZE=$ROUGEParam->{"NSIZE"};
+  $weightFactor=$ROUGEParam->{"WEIGHT"};
+  $skipDistance=$ROUGEParam->{"SD"};
+  $scoreMode=$ROUGEParam->{"SM"};
+  $alpha=$ROUGEParam->{"ALPHA"};
+  $opt_t=$ROUGEParam->{"AVERAGE"};
+  $BEMode=$ROUGEParam->{"BEMODE"};
+  
+  # Check to see if this evaluation trial contains this $peerID.
+  # Sometimes not every peer provides response for each
+  # evaluation trial.
+  unless(exists($ROUGEEval->{"Ps"}{$peerID})) {
+    unless(exists($knownMissing{$evalID})) {
+      $knownMissing{$evalID}={};
+    }
+    unless(exists($knownMissing{$evalID}{$peerID})) {
+      print STDERR "\*ROUGE Warning: test instance for peer $peerID does not exist for evaluation $evalID\n";
+      $knownMissing{$evalID}{$peerID}=1;
+    }
+    return;
+  }
+  unless(defined($opt_z)) {
+    $peerPath=$ROUGEEval->{"PR"}."/".$ROUGEEval->{"Ps"}{$peerID};
+  }
+  else {
+    # if opt_z is set then peerPath is read from a file list that
+    # includes the path to the peer.
+    $peerPath=$ROUGEEval->{"Ps"}{$peerID};
+  }
+  if(defined($ROUGEEval->{"MR"})) {
+    $modelRoot=$ROUGEEval->{"MR"};
+  }
+  else {
+    # if opt_z is set then modelPath is read from a file list that
+    # includes the path to the model.
+    $modelRoot="";
+  }
+  $modelIDs=$ROUGEEval->{"MIDList"};
+  $inputFormat=$ROUGEEval->{"IF"};
+  # construct combined model
+  @modelPaths=(); # reset model paths
+  for($cx=0;$cx<=$#{$modelIDs};$cx++) {
+    my $modelID;
+    $modelID=$modelIDs->[$cx];
+    unless(defined($opt_z)) {
+      $modelPath="$modelRoot/$ROUGEEval->{\"Ms\"}{$modelID}"; # get full model path
+    }
+    else {
+      # if opt_z is set then modelPath is read from a file list that
+      # includes the full path to the model.
+      $modelPath="$ROUGEEval->{\"Ms\"}{$modelID}"; # get full model path
+    }
+    if(-e "$modelPath") {
+      #		    print "*$modelPath\n";
+    }
+    else {
+      die "Cannot find model summary: $modelPath\n";
+    }
+    push(@modelPaths,$modelPath);
+  }
+  #---------------------------------------------------------------
+  # evaluate peer
+  {
+    my (@results);
+    my ($testID,$avgROUGE,$avgROUGE_P,$avgROUGE_F);
+    @results=();
+    if($metric eq "N") {
+      &computeNGramScore(\@modelPaths,$peerPath,\@results,$NSIZE,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "L") {
+      &computeLCSScore(\@modelPaths,$peerPath,\@results,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "W") {
+      &computeWLCSScore(\@modelPaths,$peerPath,\@results,$lengthLimit,$byteLimit,$inputFormat,$weightFactor,$scoreMode,$alpha);
+    }
+    elsif($metric eq "S") {
+      &computeSkipBigramScore(\@modelPaths,$peerPath,\@results,$skipDistance,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "BE") {
+      &computeBEScore(\@modelPaths,$peerPath,\@results,$BEMode,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    else {
+      die "Unknown ROUGE metric ID: $metric, has to be N, L, W, or S\n";
+      
+    }
+    unless(defined($opt_t)) {
+      # sentence level average
+      $avgROUGE=sprintf("%7.5f",$results[2]);
+      $avgROUGE_P=sprintf("%7.5f",$results[4]);
+      $avgROUGE_F=sprintf("%7.5f",$results[5]);
+    }
+    else {
+      # corpus level per token average
+      $avgROUGE=$results[0]; # total model token count
+      $avgROUGE_P=$results[3]; # total peer token count
+      $avgROUGE_F=$results[1]; # total match count between model and peer, i.e. hit
+    }
+    # record ROUGE scores for the current test
+    $testID="$evalID\.$peerID";
+    if($debug) {
+      print "$testID\n";
+    }
+    unless(exists($testIDs{$testID})) {
+      $testIDs{$testID}=1;
+    }
+    unless(exists($ROUGEScores->{$testID})) {
+      $ROUGEScores->{$testID}=[];
+      push(@{$ROUGEScores->{$testID}},$avgROUGE);   # average ; or model token count
+      push(@{$ROUGEScores->{$testID}},$avgROUGE_P); # average ; or peer token count
+      push(@{$ROUGEScores->{$testID}},$avgROUGE_F); # average ; or match token count (hit)
+    }
+  }
+}
+
+# 10/21/2004 add selection of scoring mode
+# A: average over all models
+# B: take only the best score
+sub computeNGramScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $NSIZE=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,$modelText,$peerText,$text,@tokens);
+  my (%model_grams,%peer_grams);
+  my ($gramHit,$gramScore,$gramScoreBest);
+  my ($totalGramHit,$totalGramCount);
+  my ($gramScoreP,$gramScoreF,$totalGramCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalGramHit=0;
+  $totalGramCount=0;
+  $gramScoreBest=-1;
+  $gramScoreP=0; # precision
+  $gramScoreF=0; # f-measure
+  $totalGramCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  %peer_grams=();
+  $peerText="";
+  &readText($peerPath,\$peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText,\%peer_grams,$NSIZE);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(defined($peerText)) {
+      print "$peerText\n";
+      print join("|",%peer_grams),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_grams=();
+    $modelText="";
+    &readText($modelPath,\$modelText,$inputFormat,$lengthLimit,$byteLimit);
+    &createNGram($modelText,\%model_grams,$NSIZE);
+    if($debug) {
+      if(defined($modelText)) {
+	print "$modelText\n";
+	print join("|",%model_grams),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute ngram score
+    &ngramScore(\%model_grams,\%peer_grams,\$gramHit,\$gramScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($gramScore>$gramScoreBest) {
+	# only take a better score (i.e. better match)
+	$gramScoreBest=$gramScore;
+	$totalGramHit=$gramHit;
+	$totalGramCount=$model_grams{"_cn_"};
+	$totalGramCountP=$peer_grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # unigram
+  push(@$results,$totalGramCount); # total number of ngrams in models
+  push(@$results,$totalGramHit);
+  if($totalGramCount!=0) {
+    $gramScore=sprintf("%7.5f",$totalGramHit/$totalGramCount);
+  }
+  else {
+    $gramScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScore);
+  push(@$results,$totalGramCountP); # total number of ngrams in peers
+  if($totalGramCountP!=0) {
+    $gramScoreP=sprintf("%7.5f",$totalGramHit/$totalGramCountP);
+  }
+  else {
+    $gramScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreP);      # precision score
+  if((1-$alpha)*$gramScoreP+$alpha*$gramScore>0) {
+    $gramScoreF=sprintf("%7.5f",($gramScoreP*$gramScore)/((1-$alpha)*$gramScoreP+$alpha*$gramScore));
+  }
+  else {
+    $gramScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreF);      # f1-measure score
+  if($debug) {
+    print "total $NSIZE-gram model count: $totalGramCount\n";
+    print "total $NSIZE-gram peer count: $totalGramCountP\n";
+    print "total $NSIZE-gram hit: $totalGramHit\n";
+    print "total ROUGE-$NSIZE\-R: $gramScore\n";
+    print "total ROUGE-$NSIZE\-P: $gramScoreP\n";
+    print "total ROUGE-$NSIZE\-F: $gramScoreF\n";
+  }
+}
+
+sub computeSkipBigramScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $skipDistance=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,$modelText,$peerText,$text,@tokens);
+  my (%model_grams,%peer_grams);
+  my ($gramHit,$gramScore,$gramScoreBest);
+  my ($totalGramHitm,$totalGramCount);
+  my ($gramScoreP,$gramScoreF,$totalGramCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalGramHit=0;
+  $totalGramCount=0;
+  $gramScoreBest=-1;
+  $gramScoreP=0; # precision
+  $gramScoreF=0; # f-measure
+  $totalGramCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  %peer_grams=();
+  $peerText="";
+  &readText($peerPath,\$peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &createSkipBigram($peerText,\%peer_grams,$skipDistance);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(defined($peerText)) {
+      print "$peerText\n";
+      print join("|",%peer_grams),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_grams=();
+    $modelText="";
+    &readText($modelPath,\$modelText,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createSkipBigram($modelText,\%model_grams,$skipDistance);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    if($debug) {
+      if(defined($modelText)) {
+	print "$modelText\n";
+	print join("|",%model_grams),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute ngram score
+    &skipBigramScore(\%model_grams,\%peer_grams,\$gramHit,\$gramScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($gramScore>$gramScoreBest) {
+	# only take a better score (i.e. better match)
+	$gramScoreBest=$gramScore;
+	$totalGramHit=$gramHit;
+	$totalGramCount=$model_grams{"_cn_"};
+	$totalGramCountP=$peer_grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # unigram
+  push(@$results,$totalGramCount); # total number of ngrams
+  push(@$results,$totalGramHit);
+  if($totalGramCount!=0) {
+    $gramScore=sprintf("%7.5f",$totalGramHit/$totalGramCount);
+  }
+  else {
+    $gramScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScore);
+  push(@$results,$totalGramCountP); # total number of ngrams in peers
+  if($totalGramCountP!=0) {
+    $gramScoreP=sprintf("%7.5f",$totalGramHit/$totalGramCountP);
+  }
+  else {
+    $gramScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreP);      # precision score
+  if((1-$alpha)*$gramScoreP+$alpha*$gramScore>0) {
+    $gramScoreF=sprintf("%7.5f",($gramScoreP*$gramScore)/((1-$alpha)*$gramScoreP+$alpha*$gramScore));
+  }
+  else {
+    $gramScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreF);      # f1-measure score
+  if($debug) {
+    print "total ROUGE-S$skipDistance model count: $totalGramCount\n";
+    print "total ROUGE-S$skipDistance peer count: $totalGramCountP\n";
+    print "total ROUGE-S$skipDistance hit: $totalGramHit\n";
+    print "total ROUGE-S$skipDistance\-R: $gramScore\n";
+    print "total ROUGE-S$skipDistance\-P: $gramScore\n";
+    print "total ROUGE-S$skipDistance\-F: $gramScore\n";
+  }
+}
+
+sub computeLCSScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelText,@peerText,$text,@tokens);
+  my (@modelTokens,@peerTokens);
+  my ($lcsHit,$lcsScore,$lcsBase,$lcsScoreBest);
+  my ($totalLCSHitm,$totalLCSCount);
+  my (%peer_1grams,%tmp_peer_1grams,%model_1grams,$peerText1,$modelText1);
+  my ($lcsScoreP,$lcsScoreF,$totalLCSCountP);
+  
+  #------------------------------------------------
+  $totalLCSHit=0;
+  $totalLCSCount=0;
+  $lcsScoreBest=-1;
+  $lcsScoreP=0;
+  $lcsScoreF=0;
+  $totalLCSCountP=0;
+  #------------------------------------------------
+  # read peer file and create peer n-gram maps
+  @peerTokens=();
+  @peerText=();
+  &readText_LCS($peerPath,\@peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &tokenizeText_LCS(\@peerText,\@peerTokens);
+  #------------------------------------------------
+  # create unigram for clipping
+  %peer_1grams=();
+  &readText($peerPath,\$peerText1,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText1,\%peer_1grams,1);
+  if($debug) {
+    my $i;
+    print "***P $peerPath\n";
+    print join("\n",@peerText),"\n";
+    for($i=0;$i<=$#peerText;$i++) {
+      print $i,": ",join("|",@{$peerTokens[$i]}),"\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %tmp_peer_1grams=%peer_1grams; # renew peer unigram hash, so the peer count can be reset to the orignal number
+    @modelTokens=();
+    @modelText=();
+    &readText_LCS($modelPath,\@modelText,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) {
+      $opt_m=1;
+      &tokenizeText_LCS(\@modelText,\@modelTokens);
+      $opt_m=undef;
+    }
+    else {
+      &tokenizeText_LCS(\@modelText,\@modelTokens);
+    }
+    #------------------------------------------------
+    # create unigram for clipping
+    %model_1grams=();
+    &readText($modelPath,\$modelText1,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }        
+    &createNGram($modelText1,\%model_1grams,1);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    #------------------------------------------------
+    # compute LCS score
+    &lcs(\@modelTokens,\@peerTokens,\$lcsHit,\$lcsScore,\$lcsBase,\%model_1grams,\%tmp_peer_1grams);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reductant information contained in the peer summary.
+    # Previous method that lumps model text together and inflates the peer summary
+    # the number of references time would reward redundant information
+    if($scoreMode eq "A") {
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=$lcsBase;
+      $totalLCSCountP+=$peer_1grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($lcsScore>$lcsScoreBest) {
+	# only take a better score (i.e. better match)
+	$lcsScoreBest=$lcsScore;
+	$totalLCSHit=$lcsHit;
+	$totalLCSCount=$lcsBase;
+	$totalLCSCountP=$peer_1grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=$lcsBase;
+      $totalLCSCountP+=$peer_1grams{"_cn_"};
+    }
+    if($debug) {
+      my $i;
+      print "***M $modelPath\n";
+      print join("\n",@modelText),"\n";
+      for($i=0;$i<=$#modelText;$i++) {
+	print $i,": ",join("|",@{$modelTokens[$i]}),"\n";
+      }
+    }
+  }
+  # prepare score result for return
+  push(@$results,$totalLCSCount); # total number of ngrams
+  push(@$results,$totalLCSHit);
+  if($totalLCSCount!=0) {
+    $lcsScore=sprintf("%7.5f",$totalLCSHit/$totalLCSCount);
+  }
+  else {
+    $lcsScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScore);
+  push(@$results,$totalLCSCountP); # total number of token in peers
+  if($totalLCSCountP!=0) {
+    $lcsScoreP=sprintf("%7.5f",$totalLCSHit/$totalLCSCountP);
+  }
+  else {
+    $lcsScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreP);
+  if((1-$alpha)*$lcsScoreP+$alpha*$lcsScore>0) {
+    $lcsScoreF=sprintf("%7.5f",($lcsScoreP*$lcsScore)/((1-$alpha)*$lcsScoreP+$alpha*$lcsScore));
+  }
+  else {
+    $lcsScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreF);
+  if($debug) {
+    print "total ROUGE-L model count: $totalLCSCount\n";
+    print "total ROUGE-L peer count: $totalLCSCountP\n";
+    print "total ROUGE-L hit: $totalLCSHit\n";
+    print "total ROUGE-L-R score: $lcsScore\n";
+    print "total ROUGE-L-P: $lcsScoreP\n";
+    print "total ROUGE-L-F: $lcsScoreF\n";
+  }
+}
+
+sub computeWLCSScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $weightFactor=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelText,@peerText,$text,@tokens);
+  my (@modelTokens,@peerTokens);
+  my ($lcsHit,$lcsScore,$lcsBase,$lcsScoreBest);
+  my ($totalLCSHitm,$totalLCSCount);
+  my (%peer_1grams,%tmp_peer_1grams,%model_1grams,$peerText1,$modelText1);
+  my ($lcsScoreP,$lcsScoreF,$totalLCSCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalLCSHit=0;
+  $totalLCSCount=0;
+  $lcsScoreBest=-1;
+  $lcsScoreP=0;
+  $lcsScoreF=0;
+  $totalLCSCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  @peerTokens=();
+  @peerText=();
+  &readText_LCS($peerPath,\@peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &tokenizeText_LCS(\@peerText,\@peerTokens);
+  #------------------------------------------------
+  # create unigram for clipping
+  %peer_1grams=();
+  &readText($peerPath,\$peerText1,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText1,\%peer_1grams,1);
+  if($debug) {
+    my $i;
+    print "***P $peerPath\n";
+    print join("\n",@peerText),"\n";
+    for($i=0;$i<=$#peerText;$i++) {
+      print $i,": ",join("|",@{$peerTokens[$i]}),"\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %tmp_peer_1grams=%peer_1grams; # renew peer unigram hash, so the peer count can be reset to the orignal number
+    @modelTokens=();
+    @modelText=();
+    &readText_LCS($modelPath,\@modelText,$inputFormat,$lengthLimit,$byteLimit);
+    &tokenizeText_LCS(\@modelText,\@modelTokens);
+    #------------------------------------------------
+    # create unigram for clipping
+    %model_1grams=();
+    &readText($modelPath,\$modelText1,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createNGram($modelText1,\%model_1grams,1);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    #------------------------------------------------
+    # compute WLCS score
+    &wlcs(\@modelTokens,\@peerTokens,\$lcsHit,\$lcsScore,\$lcsBase,$weightFactor,\%model_1grams,\%tmp_peer_1grams);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reductant information contained in the peer summary.
+    # Previous method that lumps model text together and inflates the peer summary
+    # the number of references time would reward redundant information
+    if($scoreMode eq "A") {
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=&wlcsWeight($lcsBase,$weightFactor);
+      $totalLCSCountP+=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+    }
+    elsif($scoreMode eq "B") {
+      if($lcsScore>$lcsScoreBest) {
+	# only take a better score (i.e. better match)
+	$lcsScoreBest=$lcsScore;
+	$totalLCSHit=$lcsHit;
+	$totalLCSCount=&wlcsWeight($lcsBase,$weightFactor);
+	$totalLCSCountP=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+      }
+    }
+    else {
+      # use average mode
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=&wlcsWeight($lcsBase,$weightFactor);
+      $totalLCSCountP+=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+    }
+    if($debug) {
+      my $i;
+      print "***M $modelPath\n";
+      print join("\n",@modelText),"\n";
+      for($i=0;$i<=$#modelText;$i++) {
+	print $i,": ",join("|",@{$modelTokens[$i]}),"\n";
+      }
+    }
+  }
+  # prepare score result for return
+  push(@$results,$totalLCSCount); # total number of ngrams
+  push(@$results,$totalLCSHit);
+  if($totalLCSCount!=0) {
+    $lcsScore=sprintf("%7.5f",&wlcsWeightInverse($totalLCSHit/$totalLCSCount,$weightFactor));
+  }
+  else {
+    $lcsScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScore);
+  push(@$results,$totalLCSCountP); # total number of token in peers
+  if($totalLCSCountP!=0) {
+    $lcsScoreP=sprintf("%7.5f",&wlcsWeightInverse($totalLCSHit/$totalLCSCountP,$weightFactor));
+  }
+  else {
+    $lcsScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreP);
+  if((1-$alpha)*$lcsScoreP+$alpha*$lcsScore>0) {
+    $lcsScoreF=sprintf("%7.5f",($lcsScoreP*$lcsScore)/((1-$alpha)*$lcsScoreP+$alpha*$lcsScore));
+  }
+  else {
+    $lcsScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreF);
+  if($debug) {
+    print "total ROUGE-W-$weightFactor model count: $totalLCSCount\n";
+    print "total ROUGE-W-$weightFactor peer count: $totalLCSCountP\n";
+    print "total ROUGE-W-$weightFactor hit: $totalLCSHit\n";
+    print "total ROUGE-W-$weightFactor-R score: $lcsScore\n";
+    print "total ROUGE-W-$weightFactor-P score: $lcsScoreP\n";
+    print "total ROUGE-W-$weightFactor-F score: $lcsScoreF\n";
+  }
+}
+
+sub computeBEScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $BEMode=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelBEList,@peerBEList,$text,@tokens);
+  my (%model_BEs,%peer_BEs);
+  my ($BEHit,$BEScore,$BEScoreBest);
+  my ($totalBEHit,$totalBECount);
+  my ($BEScoreP,$BEScoreF,$totalBECountP);
+  
+  #------------------------------------------------
+  # read model file and create model BE maps
+  $totalBEHit=0;
+  $totalBECount=0;
+  $BEScoreBest=-1;
+  $BEScoreP=0; # precision
+  $BEScoreF=0; # f-measure
+  $totalBECountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-BE maps
+  %peer_BEs=();
+  @peerBEList=();
+  &readBE($peerPath,\@peerBEList,$inputFormat);
+  &createBE(\@peerBEList,\%peer_BEs,$BEMode);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(scalar @peerBEList > 0) {
+#      print join("\n",@peerBEList);
+#      print "\n";
+      print join("#",%peer_BEs),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_BEs=();
+    @modelBEList=();
+    &readBE($modelPath,\@modelBEList,$inputFormat);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createBE(\@modelBEList,\%model_BEs,$BEMode);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    if($debug) {
+      if(scalar @modelBEList > 0) {
+#	print join("\n",@modelBEList);
+#	print "\n";
+	print join("#",%model_BEs),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute BE score
+    &getBEScore(\%model_BEs,\%peer_BEs,\$BEHit,\$BEScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalBEHit+=$BEHit;
+      $totalBECount+=$model_BEs{"_cn_"};
+      $totalBECountP+=$peer_BEs{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($BEScore>$BEScoreBest) {
+	# only take a better score (i.e. better match)
+	$BEScoreBest=$BEScore;
+	$totalBEHit=$BEHit;
+	$totalBECount=$model_BEs{"_cn_"};
+	$totalBECountP=$peer_BEs{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalBEHit+=$BEHit;
+      $totalBECount+=$model_BEs{"_cn_"};
+      $totalBECountP+=$peer_BEs{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # uniBE
+  push(@$results,$totalBECount); # total number of nbes in models
+  push(@$results,$totalBEHit);
+  if($totalBECount!=0) {
+    $BEScore=sprintf("%7.5f",$totalBEHit/$totalBECount);
+  }
+  else {
+    $BEScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScore);
+  push(@$results,$totalBECountP); # total number of nBEs in peers
+  if($totalBECountP!=0) {
+    $BEScoreP=sprintf("%7.5f",$totalBEHit/$totalBECountP);
+  }
+  else {
+    $BEScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScoreP);      # precision score
+  if((1-$alpha)*$BEScoreP+$alpha*$BEScore>0) {
+    $BEScoreF=sprintf("%7.5f",($BEScoreP*$BEScore)/((1-$alpha)*$BEScoreP+$alpha*$BEScore));
+  }
+  else {
+    $BEScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScoreF);      # f1-measure score
+  if($debug) {
+    print "total BE-$BEMode model count: $totalBECount\n";
+    print "total BE-$BEMode peer count: $totalBECountP\n";
+    print "total BE-$BEMode hit: $totalBEHit\n";
+    print "total ROUGE-BE-$BEMode\-R: $BEScore\n";
+    print "total ROUGE-BE-$BEMode\-P: $BEScoreP\n";
+    print "total ROUGE-BE-$BEMode\-F: $BEScoreF\n";
+  }
+}
+
+sub readTextOld {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$bsize,$wsize,@words,$done);
+  
+  $$tokenizedText=undef;
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a (size=\"[0-9]+\" )?name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$3;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      $line=~s/^\s+//;
+      $line=~s/\s+$//;
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(defined($$tokenizedText)) {
+    $$tokenizedText=~s/\-/ \- /g;
+    $$tokenizedText=~s/[^A-Za-z0-9\-]/ /g;
+    $$tokenizedText=~s/^\s+//;
+    $$tokenizedText=~s/\s+$//;
+    $$tokenizedText=~s/\s+/ /g;
+  }
+  else {
+    print STDERR "readText: $inPath -> empty text\n";
+  }
+  #    print "($$tokenizedText)\n\n";
+}
+
+# enforce length cutoff at the file level
+# convert different input format into SPL format then put them into
+# tokenizedText
+sub readText {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+####### modified by Benoit Favre
+	my $readText_signature = "$inPath $type $lengthLimit $byteLimit";
+	if(exists $readText_cache{$readText_signature}) {
+		$$tokenizedText = $readText_cache{$readText_signature};
+		return;
+	}
+####### end of modification
+  my ($text,$bsize,$wsize,@words,$done,@sntList);
+  
+  $$tokenizedText=undef;
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  @sntList=();
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a size=\"[0-9]+\" name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o||
+	 $line=~/^<a name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$2;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if($lengthLimit==0&&$byteLimit==0) {
+    $$tokenizedText=join(" ",@sntList);
+  }
+  elsif($lengthLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen,@tokens);
+      @tokens=split(/\s+/,$s);
+      $sLen=scalar @tokens;
+      if($tmpTextLen+$sLen<$lengthLimit) {
+	if($tmpTextLen!=0) {
+	  $tmpText.=" $s";
+	}
+	else {
+	  $tmpText.="$s";
+	}
+	$tmpTextLen+=$sLen;
+      }
+      else {
+	if($tmpTextLen>0) {
+	  $tmpText.=" ";
+	}
+	$tmpText.=join(" ",@tokens[0..$lengthLimit-$tmpTextLen-1]);
+	last;
+      }
+    }
+    if(length($tmpText)>0) {
+      $$tokenizedText=$tmpText;
+    }
+  }
+  elsif($byteLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen);
+      $sLen=length($s);
+      if($tmpTextLen+$sLen<$byteLimit) {
+	if($tmpTextLen!=0) {
+	  $tmpText.=" $s";
+	}
+	else {
+	  $tmpText.="$s";
+	}
+	$tmpTextLen+=$sLen;
+      }
+      else {
+	if($tmpTextLen>0) {
+	  $tmpText.=" ";
+	}
+	$tmpText.=substr($s,0,$byteLimit-$tmpTextLen);
+	last;
+      }
+    }
+    if(length($tmpText)>0) {
+      $$tokenizedText=$tmpText;
+    }
+  }
+  if(defined($$tokenizedText)) {
+    $$tokenizedText=~s/\-/ \- /g;
+    $$tokenizedText=~s/[^A-Za-z0-9\-]/ /g;
+    $$tokenizedText=~s/^\s+//;
+    $$tokenizedText=~s/\s+$//;
+    $$tokenizedText=~s/\s+/ /g;
+  }
+  else {
+    print STDERR "readText: $inPath -> empty text\n";
+  }
+####### modified by Benoit Favre
+  $readText_cache{$readText_signature} = "$$tokenizedText";
+###### end of modification
+}
+
+sub readBE {
+  my $inPath=shift;
+  my $BEList=shift;
+  my $type=shift;
+  my ($line);
+  
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if(defined($opt_v)) {
+    print STDERR "$inPath\n";
+  }
+  if($type=~/^SIMPLE$/oi) {
+    while(defined($line=<TEXT>)) { # Simple BE triple format
+      chomp($line);
+      push(@{$BEList},$line);
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard BE format
+    while(defined($line=<TEXT>)) {
+      # place holder
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(scalar @{$BEList} ==0) {
+    print STDERR "readBE: $inPath -> empty text\n";
+  }
+}
+
+sub checkSummarySize {
+  my $tokenizedText=shift;
+  my $text=shift;
+  my $wsize=shift;
+  my $bsize=shift;
+  my $done=shift;
+  my $lenghtLimit=shift;
+  my $byteLimit=shift;
+  my (@words);
+  
+  @words=split(/\s+/,$$text);
+  if(($lengthLimit==0&&$byteLimit==0)||
+     ($lengthLimit!=0&&(scalar @words)+$$wsize<=$lengthLimit)||
+     ($byteLimit!=0&&length($$text)+$$bsize<=$byteLimit)) {
+    if(defined($$tokenizedText)) {
+      $$tokenizedText.=" $$text";
+    }
+    else {
+      $$tokenizedText=$$text;
+    }
+    $$bsize+=length($$text);
+    $$wsize+=(scalar @words);
+  }
+  elsif($lengthLimit!=0&&(scalar @words)+$$wsize>$lengthLimit) {
+    if($$done==0) {
+      if(defined($$tokenizedText)) {
+	$$tokenizedText.=" ";
+	$$tokenizedText.=join(" ",@words[0..$lengthLimit-$$wsize-1]);
+      }
+      else {
+	$$tokenizedText=join(" ",@words[0..$lengthLimit-$$wsize-1]);
+      }
+      $$done=1;
+    }
+  }
+  elsif($byteLimit!=0&&length($$text)+$$bsize>$byteLimit) {
+    if($$done==0) {
+      if(defined($$tokenizedText)) {
+	$$tokenizedText.=" ";
+	$$tokenizedText.=substr($$text,0,$byteLimit-$$bsize);
+      }
+      else {
+	$$tokenizedText=substr($$text,0,$byteLimit-$$bsize);
+	
+      }
+      $$done=1;
+    }
+  }
+}
+
+# LCS computing is based on unit and cannot lump all the text together
+# as in computing ngram co-occurrences
+sub readText_LCS {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$t,$bsize,$wsize,$done,@sntList);
+  
+  @{$tokenizedText}=();
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  @sntList=();
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a size=\"[0-9]+\" name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o||
+	 $line=~/^<a name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$2;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if($lengthLimit==0&&$byteLimit==0) {
+    @{$tokenizedText}=@sntList;
+  }
+  elsif($lengthLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen,@tokens);
+      @tokens=split(/\s+/,$s);
+      $sLen=scalar @tokens;
+      if($tmpTextLen+$sLen<$lengthLimit) {
+	$tmpTextLen+=$sLen;
+	push(@{$tokenizedText},$s);
+      }
+      else {
+	push(@{$tokenizedText},join(" ",@tokens[0..$lengthLimit-$tmpTextLen-1]));
+	last;
+      }
+    }
+  }
+  elsif($byteLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen);
+      $sLen=length($s);
+      if($tmpTextLen+$sLen<$byteLimit) {
+	push(@{$tokenizedText},$s);
+      }
+      else {
+	push(@{$tokenizedText},substr($s,0,$byteLimit-$tmpTextLen));
+	last;
+      }
+    }
+  }
+  if(defined(@{$tokenizedText}>0)) {
+    for($t=0;$t<@{$tokenizedText};$t++) {
+      $tokenizedText->[$t]=~s/\-/ \- /g;
+      $tokenizedText->[$t]=~s/[^A-Za-z0-9\-]/ /g;
+      $tokenizedText->[$t]=~s/^\s+//;
+      $tokenizedText->[$t]=~s/\s+$//;
+      $tokenizedText->[$t]=~s/\s+/ /g;
+    }
+  }
+  else {
+    print STDERR "readText_LCS: $inPath -> empty text\n";
+  }
+}
+
+# LCS computing is based on unit and cannot lump all the text together
+# as in computing ngram co-occurrences
+sub readText_LCS_old {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$t,$bsize,$wsize,$done);
+  
+  @{$tokenizedText}=();
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a (size=\"[0-9]+\" )?name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$3;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      $line=~s/^\s+//;
+      $line=~s/\s+$//;
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(defined(@{$tokenizedText}>0)) {
+    for($t=0;$t<@{$tokenizedText};$t++) {
+      $tokenizedText->[$t]=~s/\-/ \- /g;
+      $tokenizedText->[$t]=~s/[^A-Za-z0-9\-]/ /g;
+      $tokenizedText->[$t]=~s/^\s+//;
+      $tokenizedText->[$t]=~s/\s+$//;
+      $tokenizedText->[$t]=~s/\s+/ /g;
+    }
+  }
+  else {
+    print STDERR "readText_LCS: $inPath -> empty text\n";
+  }
+}
+
+sub checkSummarySize_LCS {
+  my $tokenizedText=shift;
+  my $text=shift;
+  my $wsize=shift;
+  my $bsize=shift;
+  my $done=shift;
+  my $lenghtLimit=shift;
+  my $byteLimit=shift;
+  my (@words);
+  
+  @words=split(/\s+/,$$text);
+  if(($lengthLimit==0&&$byteLimit==0)||
+     ($lengthLimit!=0&&(scalar @words)+$$wsize<=$lengthLimit)||
+     ($byteLimit!=0&&length($$text)+$$bsize<=$byteLimit)) {
+    push(@{$tokenizedText},$$text);
+    $$bsize+=length($$text);
+    $$wsize+=(scalar @words);
+  }
+  elsif($lengthLimit!=0&&(scalar @words)+$$wsize>$lengthLimit) {
+    if($$done==0) {
+      push(@{$tokenizedText},$$text);
+      $$done=1;
+    }
+  }
+  elsif($byteLimit!=0&&length($$text)+$$bsize>$byteLimit) {
+    if($$done==0) {
+      push(@{$tokenizedText},$$text);
+      $$done=1;
+    }
+  }
+}
+
+sub ngramScore {
+  my $model_grams=shift;
+  my $peer_grams=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$model_grams);
+  foreach $t (@tokens) {
+    if($t ne "_cn_") {
+      my $h;
+      $h=0;
+      if(exists($peer_grams->{$t})) {
+	$h=$peer_grams->{$t}<=$model_grams->{$t}?
+	  $peer_grams->{$t}:$model_grams->{$t}; # clip
+	$$hit+=$h;
+      }
+    }
+  }
+  if($model_grams->{"_cn_"}!=0) {
+    $$score=sprintf("%07.5f",$$hit/$model_grams->{"_cn_"});
+  }
+  else {
+    # no instance of n-gram at this length
+    $$score=0;
+    #	die "model n-grams has zero instance\n";
+  }
+}
+
+sub skipBigramScore {
+  my $model_grams=shift;
+  my $peer_grams=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$model_grams);
+  foreach $t (@tokens) {
+    if($t ne "_cn_") {
+      my $h;
+      $h=0;
+      if(exists($peer_grams->{$t})) {
+	$h=$peer_grams->{$t}<=$model_grams->{$t}?
+	  $peer_grams->{$t}:$model_grams->{$t}; # clip
+	$$hit+=$h;
+      }
+    }
+  }
+  if($model_grams->{"_cn_"}!=0) {
+    $$score=sprintf("%07.5f",$$hit/$model_grams->{"_cn_"});
+  }
+  else {
+    # no instance of n-gram at this length
+    $$score=0;
+    #	die "model n-grams has zero instance\n";
+  }
+}
+
+sub lcs {
+  my $model=shift;
+  my $peer=shift;
+  my $hit=shift;
+  my $score=shift;
+  my $base=shift;
+  my $model_1grams=shift;
+  my $peer_1grams=shift;
+  my ($i,$j,@hitMask,@LCS);
+  
+  $$hit=0;
+  $$base=0;
+  # compute LCS length for each model/peer pair
+  for($i=0;$i<@{$model};$i++) {
+    # use @hitMask to make sure multiple peer hit won't be counted as multiple hits
+    @hitMask=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      push(@hitMask,0); # initialize hit mask
+    }
+    $$base+=scalar @{$model->[$i]}; # add model length
+    for($j=0;$j<@{$peer};$j++) {
+      &lcs_inner($model->[$i],$peer->[$j],\@hitMask);
+    }
+    @LCS=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      if($hitMask[$j]==1) {
+	if(exists($model_1grams->{$model->[$i][$j]})&&
+	   exists($peer_1grams->{$model->[$i][$j]})&&
+	   $model_1grams->{$model->[$i][$j]}>0&&
+	   $peer_1grams->{$model->[$i][$j]}>0) {
+	  $$hit++;
+	  #---------------------------------------------
+	  # bookkeeping to clip over counting
+	  # everytime a hit is found it is deducted
+	  # from both model and peer unigram count
+	  # if a unigram count already involve in
+	  # one LCS match then it will not be counted
+	  # if it match another token in the model
+	  # unit. This will make sure LCS score
+	  # is always lower than unigram score
+	  $model_1grams->{$model->[$i][$j]}--;
+	  $peer_1grams->{$model->[$i][$j]}--;
+	  push(@LCS,$model->[$i][$j]);
+	}
+      }
+    }
+    if($debug) {
+      print "LCS: ";
+      if(@LCS) {
+	print join(" ",@LCS),"\n";
+      }
+      else {
+	print "-\n";
+      }
+    }
+  }
+  if($$base>0) {
+    $$score=$$hit/$$base;
+  }
+  else {
+    $$score=0;
+  }
+}
+
+sub lcs_inner {
+  my $model=shift;
+  my $peer=shift;
+  my $hitMask=shift;
+  my $m=scalar @$model; # length of model
+  my $n=scalar @$peer; # length of peer
+  my ($i,$j);
+  my (@c,@b);
+  
+  if(@{$model}==0) {
+    return;
+  }
+  @c=();
+  @b=();
+  # initialize boundary condition and
+  # the DP array
+  for($i=0;$i<=$m;$i++) {
+    push(@c,[]);
+    push(@b,[]);
+    for($j=0;$j<=$n;$j++) {
+      push(@{$c[$i]},0);
+      push(@{$b[$i]},0);
+    }
+  }
+  for($i=1;$i<=$m;$i++) {
+    for($j=1;$j<=$n;$j++) {
+      if($model->[$i-1] eq $peer->[$j-1]) {
+	# recursively solve the i-1 subproblem
+	$c[$i][$j]=$c[$i-1][$j-1]+1;
+	$b[$i][$j]="\\"; # go diagonal
+      }
+      elsif($c[$i-1][$j]>=$c[$i][$j-1]) {
+	$c[$i][$j]=$c[$i-1][$j];
+	$b[$i][$j]="^"; # go up
+      }
+      else {
+	$c[$i][$j]=$c[$i][$j-1];
+	$b[$i][$j]="<"; # go left
+      }
+    }
+  }
+  &markLCS($hitMask,\@b,$m,$n);
+}
+
+sub wlcs {
+  my $model=shift;
+  my $peer=shift;
+  my $hit=shift;
+  my $score=shift;
+  my $base=shift;
+  my $weightFactor=shift;
+  my $model_1grams=shift;
+  my $peer_1grams=shift;
+  my ($i,$j,@hitMask,@LCS,$hitLen);
+  
+  $$hit=0;
+  $$base=0;
+  # compute LCS length for each model/peer pair
+  for($i=0;$i<@{$model};$i++) {
+    # use @hitMask to make sure multiple peer hit won't be counted as multiple hits
+    @hitMask=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      push(@hitMask,0); # initialize hit mask
+    }
+    $$base+=&wlcsWeight(scalar @{$model->[$i]},$weightFactor); # add model length
+    for($j=0;$j<@{$peer};$j++) {
+      &wlcs_inner($model->[$i],$peer->[$j],\@hitMask,$weightFactor);
+    }
+    @LCS=();
+    $hitLen=0;
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      if($hitMask[$j]==1) {
+	if(exists($model_1grams->{$model->[$i][$j]})&&
+	   exists($peer_1grams->{$model->[$i][$j]})&&
+	   $model_1grams->{$model->[$i][$j]}>0&&
+	   $peer_1grams->{$model->[$i][$j]}>0) {
+	  $hitLen++;
+	  if($j+1<@{$model->[$i]}&&$hitMask[$j+1]==0) {
+	    $$hit+=&wlcsWeight($hitLen,$weightFactor);
+	    $hitLen=0; # reset hit length
+	  }
+	  elsif($j+1==@{$model->[$i]}) {
+	    # end of sentence
+	    $$hit+=&wlcsWeight($hitLen,$weightFactor);
+	    $hitLen=0; # reset hit length
+	  }
+	  #---------------------------------------------
+	  # bookkeeping to clip over counting
+	  # everytime a hit is found it is deducted
+	  # from both model and peer unigram count
+	  # if a unigram count already involve in
+	  # one LCS match then it will not be counted
+	  # if it match another token in the model
+	  # unit. This will make sure LCS score
+	  # is always lower than unigram score
+	  $model_1grams->{$model->[$i][$j]}--;
+	  $peer_1grams->{$model->[$i][$j]}--;
+	  push(@LCS,$model->[$i][$j]);
+	}
+      }
+    }
+    if($debug) {
+      print "ROUGE-W: ";
+      if(@LCS) {
+	print join(" ",@LCS),"\n";
+      }
+      else {
+	print "-\n";
+      }
+    }
+  }
+  $$score=wlcsWeightInverse($$hit/$$base,$weightFactor);
+}
+
+sub wlcsWeight {
+  my $r=shift;
+  my $power=shift;
+  
+  return $r**$power;
+}
+
+sub wlcsWeightInverse {
+  my $r=shift;
+  my $power=shift;
+  
+  return $r**(1/$power);
+}
+
+sub wlcs_inner {
+  my $model=shift;
+  my $peer=shift;
+  my $hitMask=shift;
+  my $weightFactor=shift;
+  my $m=scalar @$model; # length of model
+  my $n=scalar @$peer; # length of peer
+  my ($i,$j);
+  my (@c,@b,@l);
+  
+  if(@{$model}==0) {
+    return;
+  }
+  @c=();
+  @b=();
+  @l=(); # the length of consecutive matches so far
+  # initialize boundary condition and
+  # the DP array
+  for($i=0;$i<=$m;$i++) {
+    push(@c,[]);
+    push(@b,[]);
+    push(@l,[]);
+    for($j=0;$j<=$n;$j++) {
+      push(@{$c[$i]},0);
+      push(@{$b[$i]},0);
+      push(@{$l[$i]},0);
+    }
+  }
+  for($i=1;$i<=$m;$i++) {
+    for($j=1;$j<=$n;$j++) {
+      if($model->[$i-1] eq $peer->[$j-1]) {
+	# recursively solve the i-1 subproblem
+	$k=$l[$i-1][$j-1];
+	$c[$i][$j]=$c[$i-1][$j-1]+&wlcsWeight($k+1,$weightFactor)-&wlcsWeight($k,$weightFactor);
+	$b[$i][$j]="\\"; # go diagonal
+	$l[$i][$j]=$k+1; # extend the consecutive matching sequence
+      }
+      elsif($c[$i-1][$j]>=$c[$i][$j-1]) {
+	$c[$i][$j]=$c[$i-1][$j];
+	$b[$i][$j]="^"; # go up
+	$l[$i][$j]=0; # no match at this position
+      }
+      else {
+	$c[$i][$j]=$c[$i][$j-1];
+	$b[$i][$j]="<"; # go left
+	$l[$i][$j]=0; # no match at this position
+      }
+    }
+  }
+  &markLCS($hitMask,\@b,$m,$n);
+}
+
+sub markLCS {
+  my $hitMask=shift;
+  my $b=shift;
+  my $i=shift;
+  my $j=shift;
+  
+  while($i!=0&&$j!=0) {
+    if($b->[$i][$j] eq "\\") {
+      $i--;
+      $j--;
+      $hitMask->[$i]=1; # mark current model position as a hit
+    }
+    elsif($b->[$i][$j] eq "^") {
+      $i--;
+    }
+    elsif($b->[$i][$j] eq "<") {
+      $j--;
+    }
+    else {
+      die "Illegal move in markLCS: ($i,$j): \"$b->[$i][$j]\".\n";
+    }
+  }
+}
+
+# currently only support simple lexical matching
+sub getBEScore {
+  my $modelBEs=shift;
+  my $peerBEs=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$modelBEs);
+  foreach $t (@tokens) {
+    if($t ne "_cn_") {
+      my $h;
+      $h=0;
+      if(exists($peerBEs->{$t})) {
+	$h=$peerBEs->{$t}<=$modelBEs->{$t}?
+	  $peerBEs->{$t}:$modelBEs->{$t}; # clip
+	$$hit+=$h;
+	if(defined($opt_v)) {
+	  print "* Match: $t\n";
+	}
+      }
+    }
+  }
+  if($modelBEs->{"_cn_"}!=0) {
+    $$score=sprintf("%07.5f",$$hit/$modelBEs->{"_cn_"});
+  }
+  else {
+    # no instance of BE at this length
+    $$score=0;
+    #	die "model BE has zero instance\n";
+  }
+}
+
+sub MorphStem {
+  my $token=shift;
+  my ($os,$ltoken);
+  
+  if(!defined($token)||length($token)==0) {
+    return undef;
+  }
+  
+  $ltoken=$token;
+  $ltoken=~tr/A-Z/a-z/;
+  if(exists($exceptiondb{$ltoken})) {
+    return $exceptiondb{$ltoken};
+  }
+  $os=$ltoken;
+  return stem($os);
+}
+
+sub createNGram {
+  my $text=shift;
+  my $g=shift;
+  my $NSIZE=shift;
+####### modified by Benoit Favre
+	$createNGram_signature = "$text $NSIZE";
+	if(exists $createNGram_cache{$createNGram_signature}) {
+		%{$g} = %{$createNGram_cache{$createNGram_signature}};
+		return;
+	}
+####### end of modification
+  my @mx_tokens=();
+  my @m_tokens=();
+  my ($i,$j);
+  my ($gram);
+  my ($count);
+  my ($byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    $g->{"_cn_"}=0;
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  for($i=0;$i<=$#mx_tokens;$i++) {
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@m_tokens,&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@m_tokens,$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@m_tokens,$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+  #-------------------------------------
+  # create ngram
+  $count=0;
+  for($i=0;$i<=$#m_tokens-$NSIZE+1;$i++) {
+    $gram=$m_tokens[$i];
+    for($j=$i+1;$j<=$i+$NSIZE-1;$j++) {
+      $gram.=" $m_tokens[$j]";
+    }
+    $count++;
+    unless(exists($g->{$gram})) {
+      $g->{$gram}=1;
+    }
+    else {
+      $g->{$gram}++;
+    }
+  }
+  # save total number of tokens
+  $g->{"_cn_"}=$count;
+####### modified by Benoit Favre
+	$createNGram_cache{$createNGram_signature} = {%$g};
+####### end of modification
+}
+
+sub createSkipBigram {
+  my $text=shift;
+  my $g=shift;
+  my $skipDistance=shift;
+####### modified by Benoit Favre
+	my $createSkipBigram_signature = "$text $skipDistance";
+	if(exists $createSkipBigram_cache{$createSkipBigram_signature}) {
+		%{$g} = %{$createSkipBigram_cache{$createSkipBigram_signature}};
+		return;
+	}
+####### end of modification
+  my @mx_tokens=();
+  my @m_tokens=();
+  my ($i,$j);
+  my ($gram);
+  my ($count);
+  my ($byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    $g->{"_cn_"}=0;
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  for($i=0;$i<=$#mx_tokens;$i++) {
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@m_tokens,&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@m_tokens,$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@m_tokens,$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+  #-------------------------------------
+  # create ngram
+  $count=0;
+  for($i=0;$i<$#m_tokens;$i++) {
+    if(defined($opt_u)) {
+      # add unigram count
+      $gram=$m_tokens[$i];
+      $count++;
+      unless(exists($g->{$gram})) {
+	$g->{$gram}=1;
+      }
+      else {
+	$g->{$gram}++;
+      }
+    }
+    for($j=$i+1;
+	$j<=$#m_tokens&&($skipDistance<0||$j<=$i+$skipDistance+1);
+	$j++) {
+      $gram=$m_tokens[$i];
+      $gram.=" $m_tokens[$j]";
+      $count++;
+      unless(exists($g->{$gram})) {
+	$g->{$gram}=1;
+      }
+      else {
+	$g->{$gram}++;
+      }
+    }
+  }
+  # save total number of tokens
+  $g->{"_cn_"}=$count;
+####### modified by Benoit Favre
+	$createSkipBigram_cache{$createSkipBigram_signature} = {%$g};
+####### end of modification
+}
+
+sub createBE {
+  my $BEList=shift;
+  my $BEMap=shift;
+  my $BEMode=shift;
+  my ($i);
+  
+  $BEMap->{"_cn_"}=0;
+  unless(scalar @{$BEList} > 0) {
+    return;
+  }
+  for($i=0;$i<=$#{$BEList};$i++) {
+    my (@fds);
+    my ($be,$stemH,$stemM);
+    $be=$BEList->[$i];
+    $be=~tr/A-Z/a-z/;
+    @fds=split(/\|/,$be);
+    if(@fds!=3) {
+      print STDERR "Basic Element (BE) input file is invalid: *$be*\n";
+      print STDERR "A BE file has to be in this format per line: HEAD|MODIFIER|RELATION\n";
+      die "For more infomation about BE, go to: http://www.isi.edu/~cyl/BE\n";
+    }
+    $stemH=$fds[0];
+    $stemM=$fds[1];
+    if(defined($opt_m)) {
+      # use stemmer
+      # only consider words starting with these characters
+      # use Porter stemmer
+      if(length($stemH)>3) {
+	$stemH=&MorphStemMulti($stemH);
+      }
+      if($stemM ne "NIL"&&
+	 length($stemM)>3) {
+	$stemM=&MorphStemMulti($stemM);
+      }
+    }
+    if($BEMode eq "H"&&
+      $stemM eq "nil") {
+      unless(exists($BEMap->{$stemH})) {
+	$BEMap->{$stemH}=0;
+      }
+      $BEMap->{$stemH}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HM"&&
+	  $stemM ne "nil") {
+      my $pair="$stemH|$stemM";
+      unless(exists($BEMap->{$pair})) {
+	$BEMap->{$pair}=0;
+      }
+      $BEMap->{$pair}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR"&&
+	  $fds[2] ne "nil") {
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HM1") {
+      my $pair="$stemH|$stemM";
+      unless(exists($BEMap->{$pair})) {
+	$BEMap->{$pair}=0;
+      }
+      $BEMap->{$pair}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR1"&&
+	  $fds[1] ne "nil") { 
+      # relation can be "NIL" but modifier has to have value
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR2") {
+      # modifier and relation can be "NIL"
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+  }
+}
+
+sub MorphStemMulti {
+  my $string=shift;
+  my (@tokens,@stems,$t,$i);
+  
+  @tokens=split(/\s+/,$string);
+  foreach $t (@tokens) {
+    if($t=~/[A-Za-z0-9]/o&&
+       $t!~/(-LRB-|-RRB-|-LSB-|-RSB-|-LCB-|-RCB-)/o) {
+      my $s;
+      if(defined($s=&MorphStem($t))) {
+	$t=$s;
+      }
+      push(@stems,$t);
+    }
+    else {
+      push(@stems,$t);
+    }
+  }
+  return join(" ",@stems);
+}
+
+sub tokenizeText {
+  my $text=shift;
+  my $tokenizedText=shift;
+  my @mx_tokens=();
+  my ($i,$byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  @{$tokenizedText}=();
+  for($i=0;$i<=$#mx_tokens;$i++) {
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@{$tokenizedText},&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@{$tokenizedText},$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@{$tokenizedText},$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+}
+
+sub tokenizeText_LCS {
+  my $text=shift;
+  my $tokenizedText=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my @mx_tokens=();
+  my ($i,$byteSize,$t,$done);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  if(@{$text}==0) {
+    return;
+  }
+  $byteSize=0;
+  @{$tokenizedText}=();
+  $done=0;
+  for($t=0;$t<@{$text}&&$done==0;$t++) {
+    @mx_tokens=split(/\s+/,$text->[$t]);
+    # tokenized array for each separate unit (for example, sentence)
+    push(@{$tokenizedText},[]);
+    for($i=0;$i<=$#mx_tokens;$i++) {
+      unless(exists($stopwords{$mx_tokens[$i]})) {
+	$byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+	if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	  if(defined($opt_m)) {
+	    # use stemmer
+	    # only consider words starting with these characters
+	    # use Porter stemmer
+	    my $stem;
+	    $stem=$mx_tokens[$i];
+	    if(length($stem)>3) {
+	      push(@{$tokenizedText->[$t]},&MorphStem($stem));
+	    }
+	    else { # no stemmer as default
+	      push(@{$tokenizedText->[$t]},$mx_tokens[$i]);
+	    }
+	  }
+	  else { # no stemmer
+	    push(@{$tokenizedText->[$t]},$mx_tokens[$i]);
+	  }
+	}
+      }
+    }
+  }
+}
+
+# Input file configuration is a list of peer/model pair for each evaluation
+# instance. Each evaluation pair is in a line separated by white spaces
+# characters.
+sub readFileList {
+  my ($ROUGEEvals)=shift;
+  my ($ROUGEEvalIDs)=shift;
+  my ($ROUGEPeerIDTable)=shift;
+  my ($doc)=shift;
+  my ($evalID,$pair);
+  my ($inputFormat,$peerFile,$modelFile,$peerID,$modelID);
+  my (@files);
+
+  $evalID=1;  # automatically generated evaluation ID starting from 1
+  $peerID=$systemID;
+  $modelID="M";
+  unless(exists($ROUGEPeerIDTable->{$peerID})) {
+    $ROUGEPeerIDTable->{$peerID}=1;
+  }
+  while(defined($pair=<$doc>)) {
+    my ($peerPath,$modelPath);
+    if($pair!~/^\#/o&&
+       $pair!~/^\s*$/o) { # Lines start with '#' is a comment line
+      chomp($pair);
+      $pair=~s/^\s+//;
+      $pair=~s/\s+$//;
+      @files=split(/\s+/,$pair);
+      if(scalar @files < 2) {
+	die "File list has to have at least 2 filenames per line (peer model1 model2 ... modelN)\n";
+      }
+      $peerFile=$files[0];
+      unless(exists($ROUGEEvals->{$evalID})) {
+	$ROUGEEvals->{$evalID}={};
+	push(@{$ROUGEEvalIDs},$evalID);
+	$ROUGEEvals->{$evalID}{"IF"}=$opt_z;
+      }
+      unless(exists($ROUGEPeerIDTable->{$peerID})) {
+	$ROUGEPeerIDTable->{$peerID}=1; # save peer ID for reference
+      }
+      if(exists($ROUGEEvals->{$evalID})) {
+	unless(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+	  $ROUGEEvals->{$evalID}{"Ps"}={};
+	  $ROUGEEvals->{$evalID}{"PIDList"}=[];
+	}
+	push(@{$ROUGEEvals->{$evalID}{"PIDList"}},$peerID); # save peer IDs
+      }
+      else {
+	die "(PEERS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+      }
+      # remove leading and trailing newlines and
+      # spaces
+      if(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+	$ROUGEEvals->{$evalID}{"Ps"}{$peerID}=$peerFile; # save peer filename
+      }
+      else {
+	die "(P) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+      }
+      for($mid=1;$mid<=$#files;$mid++) {
+	$modelFile=$files[$mid];
+	if(exists($ROUGEEvals->{$evalID})) {
+	  unless(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+	    $ROUGEEvals->{$evalID}{"Ms"}={};
+	    $ROUGEEvals->{$evalID}{"MIDList"}=[];
+	  }
+	  push(@{$ROUGEEvals->{$evalID}{"MIDList"}},"$modelID.$mid"); # save model IDs
+	}
+	else {
+	  die "(MODELS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	}
+	# remove leading and trailing newlines and
+	# spaces
+	if(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+	  $ROUGEEvals->{$evalID}{"Ms"}{"$modelID.$mid"}=$modelFile; # save peer filename
+	}
+	else {
+	  die "(M) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	}
+      }
+      $evalID++;
+    }
+  }
+}
+
+# read and parse ROUGE evaluation file
+sub readEvals {
+  my ($ROUGEEvals)=shift;
+  my ($ROUGEEvalIDs)=shift;
+  my ($ROUGEPeerIDTable)=shift;
+  my ($node)=shift;
+  my ($evalID)=shift;
+  my ($inputFormat,$peerRoot,$modelRoot,$peerFile,$modelFile,$peerID,$modelID);
+  
+  if(defined($opt_z)) {
+    # Input file configuration is a list of peer/model pair for each evaluation
+    # instance. Each evaluation pair is in a line separated by white spaces
+    # characters.
+    &readFileList($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$node);
+    return;
+  }
+  # Otherwise, the input file is the standard ROUGE XML evaluation configuration
+  # file.
+  if($node->getNodeType==ELEMENT_NODE||
+     $node->getNodeType==DOCUMENT_NODE) {
+    if($node->getNodeType==ELEMENT_NODE) {
+      $nodeName=$node->getNodeName;
+      if($nodeName=~/^EVAL$/oi) {
+	$evalID=$node->getAttributeNode("ID")->getValue;
+	unless(exists($ROUGEEvals->{$evalID})) {
+	  $ROUGEEvals->{$evalID}={};
+	  push(@{$ROUGEEvalIDs},$evalID);
+	}
+	foreach my $child ($node->getChildNodes()) {
+	  &readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+	}
+      }
+      elsif($nodeName=~/^INPUT-FORMAT$/oi) {
+	$inputFormat=$node->getAttributeNode("TYPE")->getValue;
+	if($inputFormat=~/^(SEE|ISI|SPL|SIMPLE)$/oi) { # SPL: one sentence per line
+	  if(exists($ROUGEEvals->{$evalID})) {
+	    $ROUGEEvals->{$evalID}{"IF"}=$inputFormat;
+	  }
+	  else {
+	    die "(INPUT-FORMAT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	  }
+	}
+	else {
+	  die "Unknown input type: $inputFormat\n";
+	}
+      }
+      elsif($nodeName=~/^PEER-ROOT$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==TEXT_NODE) {
+	    $peerRoot=$child->getData;
+	    # remove leading and trailing newlines and
+	    # spaces
+	    $peerRoot=~s/^[\n\s]+//;
+	    $peerRoot=~s/[\n\s]+$//;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      $ROUGEEvals->{$evalID}{"PR"}=$peerRoot;
+	    }
+	    else {
+	      die "(PEER-ROOT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^MODEL-ROOT$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==TEXT_NODE) {
+	    $modelRoot=$child->getData;
+	    # remove leading and trailing newlines and
+	    # spaces
+	    $modelRoot=~s/^[\n\s]+//;
+	    $modelRoot=~s/[\n\s]+$//;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      $ROUGEEvals->{$evalID}{"MR"}=$modelRoot;
+	    }
+	    else {
+	      die "(MODEL-ROOT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^PEERS$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==ELEMENT_NODE&&
+	     $child->getNodeName=~/^P$/oi) {
+	    $peerID=$child->getAttributeNode("ID")->getValue;
+	    unless(exists($ROUGEPeerIDTable->{$peerID})) {
+	      $ROUGEPeerIDTable->{$peerID}=1; # save peer ID for reference
+	    }
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      unless(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+		$ROUGEEvals->{$evalID}{"Ps"}={};
+		$ROUGEEvals->{$evalID}{"PIDList"}=[];
+	      }
+	      push(@{$ROUGEEvals->{$evalID}{"PIDList"}},$peerID); # save peer IDs
+	    }
+	    else {
+	      die "(PEERS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	    foreach my $grandchild ($child->getChildNodes()) {
+	      if($grandchild->getNodeType==TEXT_NODE) {
+		$peerFile=$grandchild->getData;
+		# remove leading and trailing newlines and
+		# spaces
+		$peerFile=~s/^[\n\s]+//;
+		$peerFile=~s/[\n\s]+$//;
+		if(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+		  $ROUGEEvals->{$evalID}{"Ps"}{$peerID}=$peerFile; # save peer filename
+		}
+		else {
+		  die "(P) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+		}
+	      }
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^MODELS$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==ELEMENT_NODE&&
+	     $child->getNodeName=~/^M$/oi) {
+	    $modelID=$child->getAttributeNode("ID")->getValue;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      unless(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+		$ROUGEEvals->{$evalID}{"Ms"}={};
+		$ROUGEEvals->{$evalID}{"MIDList"}=[];
+	      }
+	      push(@{$ROUGEEvals->{$evalID}{"MIDList"}},$modelID); # save model IDs
+	    }
+	    else {
+	      die "(MODELS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	    foreach my $grandchild ($child->getChildNodes()) {
+	      if($grandchild->getNodeType==TEXT_NODE) {
+		$modelFile=$grandchild->getData;
+		# remove leading and trailing newlines and
+		# spaces
+		$modelFile=~s/^[\n\s]+//;
+		$modelFile=~s/[\n\s]+$//;
+		if(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+		  $ROUGEEvals->{$evalID}{"Ms"}{$modelID}=$modelFile; # save peer filename
+		}
+		else {
+		  die "(M) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+		}
+	      }
+	    }
+	  }
+	}
+      }
+      else {
+	foreach my $child ($node->getChildNodes()) {
+	  &readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+	}
+      }
+    }
+    else {
+      foreach my $child ($node->getChildNodes()) {
+	&readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+      }
+    }
+  }
+  else {
+    if(defined($node->getChildNodes())) {
+      foreach my $child ($node->getChildNodes()) {
+	&readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+      }
+    }
+  }
+}
+
+# Porter stemmer in Perl. Few comments, but it's easy to follow against the rules in the original
+# paper, in
+#
+#   Porter, 1980, An algorithm for suffix stripping, Program, Vol. 14,
+#   no. 3, pp 130-137,
+#
+# see also http://www.tartarus.org/~martin/PorterStemmer
+
+# Release 1
+
+local %step2list;
+local %step3list;
+local ($c, $v, $C, $V, $mgr0, $meq1, $mgr1, $_v);
+
+
+sub stem
+  {  my ($stem, $suffix, $firstch);
+     my $w = shift;
+     if (length($w) < 3) { return $w; } # length at least 3
+     # now map initial y to Y so that the patterns never treat it as vowel:
+     $w =~ /^./; $firstch = $&;
+     if ($firstch =~ /^y/) { $w = ucfirst $w; }
+     
+     # Step 1a
+     if ($w =~ /(ss|i)es$/) { $w=$`.$1; }
+     elsif ($w =~ /([^s])s$/) { $w=$`.$1; }
+     # Step 1b
+     if ($w =~ /eed$/) { if ($` =~ /$mgr0/o) { chop($w); } }
+     elsif ($w =~ /(ed|ing)$/)
+       {  $stem = $`;
+	  if ($stem =~ /$_v/o)
+	    {  $w = $stem;
+	       if ($w =~ /(at|bl|iz)$/) { $w .= "e"; }
+	       elsif ($w =~ /([^aeiouylsz])\1$/) { chop($w); }
+	       elsif ($w =~ /^${C}${v}[^aeiouwxy]$/o) { $w .= "e"; }
+   }
+}
+# Step 1c
+  if ($w =~ /y$/) { $stem = $`; if ($stem =~ /$_v/o) { $w = $stem."i"; } }
+
+# Step 2
+if ($w =~ /(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/)
+  { $stem = $`; $suffix = $1;
+    if ($stem =~ /$mgr0/o) { $w = $stem . $step2list{$suffix}; }
+  }
+
+# Step 3
+
+if ($w =~ /(icate|ative|alize|iciti|ical|ful|ness)$/)
+  { $stem = $`; $suffix = $1;
+    if ($stem =~ /$mgr0/o) { $w = $stem . $step3list{$suffix}; }
+  }
+
+# Step 4
+
+   # CYL: Modified 02/14/2004, a word ended in -ement will not try the rules "-ment" and "-ent"
+#   if ($w =~ /(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/)
+#   elsif ($w =~ /(s|t)(ion)$/)
+#   { $stem = $` . $1; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /(al|ance|ence|er|ic|able|ible|ant|ement|ou|ism|ate|iti|ous|ive|ize)$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /ment$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /ent$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   elsif ($w =~ /(s|t)(ion)$/)
+   { $stem = $` . $1; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+
+#  Step 5
+
+if ($w =~ /e$/)
+  { $stem = $`;
+    if ($stem =~ /$mgr1/o or
+	($stem =~ /$meq1/o and not $stem =~ /^${C}${v}[^aeiouwxy]$/o))
+{ $w = $stem; }
+}
+if ($w =~ /ll$/ and $w =~ /$mgr1/o) { chop($w); }
+
+# and turn initial Y back to y
+if ($firstch =~ /^y/) { $w = lcfirst $w; }
+return $w;
+}
+
+  sub initialise {
+    
+    %step2list =
+      ( 'ational'=>'ate', 'tional'=>'tion', 'enci'=>'ence', 'anci'=>'ance', 'izer'=>'ize', 'bli'=>'ble',
+	'alli'=>'al', 'entli'=>'ent', 'eli'=>'e', 'ousli'=>'ous', 'ization'=>'ize', 'ation'=>'ate',
+	'ator'=>'ate', 'alism'=>'al', 'iveness'=>'ive', 'fulness'=>'ful', 'ousness'=>'ous', 'aliti'=>'al',
+	'iviti'=>'ive', 'biliti'=>'ble', 'logi'=>'log');
+    
+    %step3list =
+      ('icate'=>'ic', 'ative'=>'', 'alize'=>'al', 'iciti'=>'ic', 'ical'=>'ic', 'ful'=>'', 'ness'=>'');
+    
+    
+    $c =    "[^aeiou]";          # consonant
+    $v =    "[aeiouy]";          # vowel
+    $C =    "${c}[^aeiouy]*";    # consonant sequence
+    $V =    "${v}[aeiou]*";      # vowel sequence
+    
+    $mgr0 = "^(${C})?${V}${C}";               # [C]VC... is m>0
+    $meq1 = "^(${C})?${V}${C}(${V})?" . '$';  # [C]VC[V] is m=1
+   $mgr1 = "^(${C})?${V}${C}${V}${C}";       # [C]VCVC... is m>1
+   $_v   = "^(${C})?${v}";                   # vowel in stem
+
+}
+
diff -rupN RELEASE-1.5.5/ROUGE-1.5.5_nobonus.pl ROUGE-1.5.5/ROUGE-1.5.5_nobonus.pl
--- RELEASE-1.5.5/ROUGE-1.5.5_nobonus.pl	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/ROUGE-1.5.5_nobonus.pl	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,3338 @@
+#!/usr/bin/perl -w
+# NOTE: faster version by caching ngrams, modified by Benoit Favre (favre@icsi.berkeley.edu) 2008-05-19
+#
+# Version:     ROUGE v1.5.5
+# Date:        05/26/2005,05/19/2005,04/26/2005,04/03/2005,10/28/2004,10/25/2004,10/21/2004
+# Author:      Chin-Yew Lin
+# Description: Given an evaluation description file, for example: test.xml,
+#              this script computes the averages of the average ROUGE scores for 
+#              the evaluation pairs listed in the ROUGE evaluation configuration file.
+#              For more information, please see:
+#              http://www.isi.edu/~cyl/ROUGE
+#              For more information about Basic Elements, please see:
+#              http://www.isi.edu/~cyl/BE
+# Revision Note:
+#              1.5.5
+#              (1) Correct stemming on multi-token BE heads and modifiers.
+#                  Previously, only single token heads and modifiers were assumed.
+#              (2) Correct the resampling routine which ignores the last evaluation
+#                  item in the evaluation list. Therefore, the average scores reported
+#                  by ROUGE is only based on the first N-1 evaluation items.
+#                  Thanks Barry Schiffman at Columbia University to report this bug.
+#                  This bug only affects ROUGE-1.5.X. For pre-1.5 ROUGE, it only affects
+#                  the computation of confidence interval (CI) estimation, i.e. CI is only
+#                  estimated by the first N-1 evaluation items, but it *does not* affect
+#                  average scores.
+#              (3) Change read_text and read_text_LCS functions to read exact words or
+#                  bytes required by users. Previous versions carry out whitespace 
+#                  compression and other string clear up actions before enforce the length
+#                  limit. 
+#              1.5.4.1
+#              (1) Minor description change about "-t 0" option.
+#              1.5.4
+#              (1) Add easy evalution mode for single reference evaluations with -z
+#                  option.
+#              1.5.3
+#              (1) Add option to compute ROUGE score based on SIMPLE BE format. Given
+#                  a set of peer and model summary file in BE format with appropriate
+#                  options, ROUGE will compute matching scores based on BE lexical
+#                  matches.
+#                  There are 6 options:
+#                  1. H    : Head only match. This is similar to unigram match but
+#                            only BE Head is used in matching. BEs generated by
+#                            Minipar-based breaker do not include head-only BEs,
+#                            therefore, the score will always be zero. Use HM or HMR
+#                            optiions instead.
+#                  2. HM   : Head and modifier match. This is similar to bigram or
+#                            skip bigram but it's head-modifier bigram match based on
+#                            parse result. Only BE triples with non-NIL modifier are
+#                            included in the matching.
+#                  3. HMR  : Head, modifier, and relation match. This is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. Only BE triples with non-NIL
+#                            relation are included in the matching.
+#                  4. HM1  : This is combination of H and HM. It is similar to unigram +
+#                            bigram or skip bigram with unigram match but it's 
+#                            head-modifier bigram match based on parse result.
+#                            In this case, the modifier field in a BE can be "NIL"
+#                  5. HMR1 : This is combination of HM and HMR. It is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. In this case, the relation
+#                            field of the BE can be "NIL".
+#                  6. HMR2 : This is combination of H, HM and HMR. It is similar to
+#                            trigram match but it's head-modifier-relation trigram
+#                            match based on parse result. In this case, the modifier and
+#                            relation fields of the BE can both be "NIL".
+#              1.5.2
+#              (1) Add option to compute ROUGE score by token using the whole corpus
+#                  as average unit instead of individual sentences. Previous versions of
+#                  ROUGE uses sentence (or unit) boundary to break counting unit and takes
+#                  the average score from the counting unit as the final score.
+#                  Using the whole corpus as one single counting unit can potentially
+#                  improve the reliablity of the final score that treats each token as
+#                  equally important; while the previous approach considers each sentence as
+#                  equally important that ignores the length effect of each individual
+#                  sentences (i.e. long sentences contribute equal weight to the final
+#                  score as short sentences.)
+#                  +v1.2 provide a choice of these two counting modes that users can
+#                  choose the one that fits their scenarios.
+#              1.5.1
+#              (1) Add precision oriented measure and f-measure to deal with different lengths
+#                  in candidates and references. Importance between recall and precision can
+#                  be controled by 'alpha' parameter:
+#                  alpha -> 0: recall is more important
+#                  alpha -> 1: precision is more important
+#                  Following Chapter 7 in C.J. van Rijsbergen's "Information Retrieval".
+#                  http://www.dcs.gla.ac.uk/Keith/Chapter.7/Ch.7.html
+#                  F = 1/(alpha * (1/P) + (1 - alpha) * (1/R)) ;;; weighted harmonic mean
+#              1.4.2
+#              (1) Enforce length limit at the time when summary text is read. Previously (before
+#                  and including v1.4.1), length limit was enforced at tokenization time.
+#              1.4.1
+#              (1) Fix potential over counting in ROUGE-L and ROUGE-W
+#                  In previous version (i.e. 1.4 and order), LCS hit is computed
+#                  by summing union hit over all model sentences. Each model sentence
+#                  is compared with all peer sentences and mark the union LCS. The
+#                  length of the union LCS is the hit of that model sentence. The
+#                  final hit is then sum over all model union LCS hits. This potentially
+#                  would over count a peer sentence which already been marked as contributed
+#                  to some other model sentence. Therefore, double counting is resulted.
+#                  This is seen in evalution where ROUGE-L score is higher than ROUGE-1 and
+#                  this is not correct.
+#                  ROUGEeval-1.4.1.pl fixes this by add a clip function to prevent
+#                  double counting.
+#              1.4
+#              (1) Remove internal Jackknifing procedure:
+#                  Now the ROUGE script will use all the references listed in the
+#                  <MODEL></MODEL> section in each <EVAL></EVAL> section and no
+#                  automatic Jackknifing is performed. Please see RELEASE-NOTE.txt
+#                  for more details.
+#              1.3
+#              (1) Add skip bigram
+#              (2) Add an option to specify the number of sampling point (default is 1000)
+#              1.2.3
+#              (1) Correct the enviroment variable option: -e. Now users can specify evironment
+#                  variable ROUGE_EVAL_HOME using the "-e" option; previously this option is
+#                  not active. Thanks Zhouyan Li of Concordia University, Canada pointing this
+#                  out.
+#              1.2.2
+#              (1) Correct confidence interval calculation for median, maximum, and minimum.
+#                  Line 390.
+#              1.2.1
+#              (1) Add sentence per line format input format. See files in Verify-SPL for examples.
+#              (2) Streamline command line arguments.
+#              (3) Use bootstrap resampling to estimate confidence intervals instead of using t-test
+#                  or z-test which assume a normal distribution.
+#              (4) Add LCS (longest common subsequence) evaluation method.
+#              (5) Add WLCS (weighted longest common subsequence) evaluation method.
+#              (6) Add length cutoff in bytes.
+#              (7) Add an option to specify the longest ngram to compute. The default is 4.
+#              1.2
+#              (1) Change zero condition check in subroutine &computeNGramScores when
+#                  computing $gram1Score from
+#                  if($totalGram2Count!=0)  to
+#                  if($totalGram1Count!=0)
+#                  Thanks Ken Litkowski for this bug report.
+#                  This original script will set gram1Score to zero if there is no
+#                  bigram matches. This should rarely has significant affect the final score
+#                  since (a) there are bigram matches most of time; (b) the computation
+#                  of gram1Score is using Jackknifing procedure. However, this definitely
+#                  did not compute the correct $gram1Score when there is no bigram matches.
+#                  Therefore, users of version 1.1 should definitely upgrade to newer
+#                  version of the script that does not contain this bug.
+# Note:        To use this script, two additional data files are needed:
+#              (1) smart_common_words.txt - contains stopword list from SMART IR engine
+#              (2) WordNet-2.0.exc.db - WordNet 2.0 exception inflexion database
+#              These two files have to be put in a directory pointed by the environment
+#              variable: "ROUGE_EVAL_HOME".
+#              If environment variable ROUGE_EVAL_HOME does not exist, this script will
+#              will assume it can find these two database files in the current directory.
+# COPYRIGHT (C) UNIVERSITY OF SOUTHERN CALIFORNIA, 2002,2003,2004
+# University of Southern California                                           
+# Information Sciences Institute                                              
+# 4676 Admiralty Way                                                          
+# Marina Del Rey, California 90292-6695                                       
+#                                                                             
+# This software was partially developed under SPAWAR Grant No.
+# N66001-00-1-8916 , and  the Government holds license rights under
+# DAR 7-104.9(a)(c)(1).  It is  
+# transmitted outside of the University of Southern California only under 
+# written license agreements or software exchange agreements, and its use   
+# is limited by these agreements.  At no time shall any recipient use       
+# this software in any manner which conflicts or interferes with the        
+# governmental license rights or other provisions of the governing           
+# agreement under which it is obtained.  It is supplied "AS IS," without     
+# any warranties of any kind.  It is furnished only on the basis that any    
+# party who receives it indemnifies and holds harmless the parties who       
+# furnish and originate it against any claims, demands or liabilities        
+# connected with using it, furnishing it to others or providing it to a      
+# third party.  THIS NOTICE MUST NOT BE REMOVED FROM THE SOFTWARE,
+# AND IN THE EVENT THAT THE SOFTWARE IS DIVIDED, IT SHOULD BE
+# ATTACHED TO EVERY PART.
+#
+# Contributor to its design is Chin-Yew Lin.
+
+use XML::DOM;
+use DB_File;
+use Getopt::Std;
+#-------------------------------------------------------------------------------------
+use vars qw($opt_a $opt_b $opt_c $opt_d $opt_e $opt_f $opt_h $opt_H $opt_m $opt_n $opt_p $opt_s $opt_t $opt_l $opt_v $opt_w $opt_2 $opt_u $opt_x $opt_U $opt_3 $opt_M $opt_z);
+my $usageFull="$0\n         [-a (evaluate all systems)] 
+         [-c cf]
+         [-d (print per evaluation scores)] 
+         [-e ROUGE_EVAL_HOME] 
+         [-h (usage)] 
+         [-H (detailed usage)] 
+         [-b n-bytes|-l n-words] 
+         [-m (use Porter stemmer)] 
+         [-n max-ngram] 
+         [-s (remove stopwords)] 
+         [-r number-of-samples (for resampling)] 
+         [-2 max-gap-length (if < 0 then no gap length limit)] 
+         [-3 <H|HM|HMR|HM1|HMR1|HMR2> (for scoring based on BE)] 
+         [-u (include unigram in skip-bigram) default no)] 
+         [-U (same as -u but also compute regular skip-bigram)] 
+         [-w weight (weighting factor for WLCS)] 
+         [-v (verbose)] 
+         [-x (do not calculate ROUGE-L)] 
+         [-f A|B (scoring formula)] 
+         [-p alpha (0 <= alpha <=1)] 
+         [-t 0|1|2 (count by token instead of sentence)] 
+         [-z <SEE|SPL|ISI|SIMPLE>] 
+         <ROUGE-eval-config-file> [<systemID>]\n
+".
+  "ROUGE-eval-config-file: Specify the evaluation setup. Three files come with the ROUGE evaluation package, i.e.\n".
+  "          ROUGE-test.xml, verify.xml, and verify-spl.xml are good examples.\n".
+  "systemID: Specify which system in the ROUGE-eval-config-file to perform the evaluation.\n".
+  "          If '-a' option is used, then all systems are evaluated and users do not need to\n".
+  "          provide this argument.\n".
+  "Default:\n".
+  "  When running ROUGE without supplying any options (except -a), the following defaults are used:\n".
+  "  (1) ROUGE-L is computed;\n".
+  "  (2) 95% confidence interval;\n".
+  "  (3) No stemming;\n".
+  "  (4) Stopwords are inlcuded in the calculations;\n".
+  "  (5) ROUGE looks for its data directory first through the ROUGE_EVAL_HOME environment variable. If\n".
+  "      it is not set, the current directory is used.\n".
+  "  (6) Use model average scoring formula.\n".
+  "  (7) Assign equal importance of ROUGE recall and precision in computing ROUGE f-measure, i.e. alpha=0.5.\n".
+  "  (8) Compute average ROUGE by averaging sentence (unit) ROUGE scores.\n".
+  "Options:\n".
+  "  -2: Compute skip bigram (ROGUE-S) co-occurrence, also specify the maximum gap length between two words (skip-bigram)\n".
+  "  -u: Compute skip bigram as -2 but include unigram, i.e. treat unigram as \"start-sentence-symbol unigram\"; -2 has to be specified.\n".
+  "  -3: Compute BE score. Currently only SIMPLE BE triple format is supported.\n".
+  "      H    -> head only scoring (does not applied to Minipar-based BEs).\n".
+  "      HM   -> head and modifier pair scoring.\n".
+  "      HMR  -> head, modifier and relation triple scoring.\n".
+  "      HM1  -> H and HM scoring (same as HM for Minipar-based BEs).\n".
+  "      HMR1 -> HM and HMR scoring (same as HMR for Minipar-based BEs).\n".
+  "      HMR2 -> H, HM and HMR scoring (same as HMR for Minipar-based BEs).\n".
+  "  -a: Evaluate all systems specified in the ROUGE-eval-config-file.\n".
+  "  -c: Specify CF\% (0 <= CF <= 100) confidence interval to compute. The default is 95\% (i.e. CF=95).\n".
+  "  -d: Print per evaluation average score for each system.\n".
+  "  -e: Specify ROUGE_EVAL_HOME directory where the ROUGE data files can be found.\n".
+  "      This will overwrite the ROUGE_EVAL_HOME specified in the environment variable.\n".
+  "  -f: Select scoring formula: 'A' => model average; 'B' => best model\n".
+  "  -h: Print usage information.\n".
+  "  -H: Print detailed usage information.\n".
+  "  -b: Only use the first n bytes in the system/peer summary for the evaluation.\n".
+  "  -l: Only use the first n words in the system/peer summary for the evaluation.\n".
+  "  -m: Stem both model and system summaries using Porter stemmer before computing various statistics.\n".
+  "  -n: Compute ROUGE-N up to max-ngram length will be computed.\n".
+  "  -p: Relative importance of recall and precision ROUGE scores. Alpha -> 1 favors precision, Alpha -> 0 favors recall.\n".
+  "  -s: Remove stopwords in model and system summaries before computing various statistics.\n".
+  "  -t: Compute average ROUGE by averaging over the whole test corpus instead of sentences (units).\n".
+  "      0: use sentence as counting unit, 1: use token as couting unit, 2: same as 1 but output raw counts\n".
+  "      instead of precision, recall, and f-measure scores. 2 is useful when computation of the final,\n".
+  "      precision, recall, and f-measure scores will be conducted later.\n".
+  "  -r: Specify the number of sampling point in bootstrap resampling (default is 1000).\n".
+  "      Smaller number will speed up the evaluation but less reliable confidence interval.\n".
+  "  -w: Compute ROUGE-W that gives consecutive matches of length L in an LCS a weight of 'L^weight' instead of just 'L' as in LCS.\n".
+  "      Typically this is set to 1.2 or other number greater than 1.\n".
+  "  -v: Print debugging information for diagnositic purpose.\n".
+  "  -x: Do not calculate ROUGE-L.\n".
+  "  -z: ROUGE-eval-config-file is a list of peer-model pair per line in the specified format (SEE|SPL|ISI|SIMPLE).\n";
+
+my $usage="$0\n         [-a (evaluate all systems)] 
+         [-c cf]
+         [-d (print per evaluation scores)] 
+         [-e ROUGE_EVAL_HOME] 
+         [-h (usage)] 
+         [-H (detailed usage)] 
+         [-b n-bytes|-l n-words] 
+         [-m (use Porter stemmer)] 
+         [-n max-ngram] 
+         [-s (remove stopwords)] 
+         [-r number-of-samples (for resampling)] 
+         [-2 max-gap-length (if < 0 then no gap length limit)] 
+         [-3 <H|HM|HMR|HM1|HMR1|HMR2> (for scoring based on BE)] 
+         [-u (include unigram in skip-bigram) default no)] 
+         [-U (same as -u but also compute regular skip-bigram)] 
+         [-w weight (weighting factor for WLCS)] 
+         [-v (verbose)] 
+         [-x (do not calculate ROUGE-L)] 
+         [-f A|B (scoring formula)] 
+         [-p alpha (0 <= alpha <=1)] 
+         [-t 0|1|2 (count by token instead of sentence)] 
+         [-z <SEE|SPL|ISI|SIMPLE>] 
+         <ROUGE-eval-config-file> [<systemID>]
+";
+getopts('ahHb:c:de:f:l:mMn:p:st:r:2:3:w:uUvxz:');
+my $systemID;
+
+die $usageFull if defined($opt_H);
+die $usage if defined($opt_h)||@ARGV==0;
+die "Please specify the ROUGE configuration file or use option '-h' for help\n" if(@ARGV==0);
+if(@ARGV==1&&defined($opt_z)) {
+  $systemID="X"; # default system ID
+}
+elsif(@ARGV==1&&!defined($opt_a)) {
+  die "Please specify a system ID to evaluate or use option '-a' to evaluate all systems. For more information, use option '-h'.\n";
+}
+elsif(@ARGV==2) {
+  $systemID=$ARGV[1];
+}
+if(defined($opt_e)) {
+  $stopwords="$opt_e/smart_common_words.txt";
+  $wordnetDB="$opt_e/WordNet-2.0.exc.db";
+}
+else {
+  if(exists($ENV{"ROUGE_EVAL_HOME"})) {
+    $stopwords="$ENV{\"ROUGE_EVAL_HOME\"}/smart_common_words.txt";
+    $wordnetDB="$ENV{\"ROUGE_EVAL_HOME\"}/WordNet-2.0.exc.db";
+  }
+  elsif(exists($ENV{"RED_EVAL_HOME"})) {
+    $stopwords="$ENV{\"RED_EVAL_HOME\"}/smart_common_words.txt";
+    $wordnetDB="$ENV{\"RED_EVAL_HOME\"}/WordNet-2.0.exc.db";
+  }
+  else {
+    # if no environment variable exists then assume data files are in the current directory
+    $stopwords="smart_common_words.txt";
+    $wordnetDB="WordNet-2.0.exc.db";
+  }
+}
+
+if(defined($opt_s)) {
+  $useStopwords=0; # do not use stop words
+}
+else {
+  $useStopwords=1; # use stop words
+}
+
+if(defined($opt_l)&&defined($opt_b)) {
+  die "Please specify length limit in words or bytes but not both.\n";
+}
+
+if(defined($opt_l)) {
+  $lengthLimit=$opt_l;
+  $byteLimit=0;   # no byte limit
+}
+elsif(defined($opt_b)) {
+  $lengthLimit=0; # no length limit in words
+  $byteLimit=$opt_b;
+}
+else {
+  $byteLimit=0;   # no byte limit
+  $lengthLimit=0; # no length limit
+}
+
+unless(defined($opt_c)) {
+  $opt_c=95;
+}
+else {
+  if($opt_c<0||$opt_c>100) {
+    die "Confidence interval should be within 0 and 100. Use option -h for more details.\n";
+  }
+}
+
+if(defined($opt_w)) {
+  if($opt_w>0) {
+    $weightFactor=$opt_w;
+  }
+  else {
+    die "ROUGE-W weight factor must greater than 0.\n";
+  }
+}
+#unless(defined($opt_n)) {
+#    $opt_n=4; # default maximum ngram is 4
+#}
+if(defined($opt_v)) {
+  $debug=1;
+}
+else {
+  $debug=0;
+}
+
+if(defined($opt_r)) {
+  $numOfResamples=$opt_r;
+}
+else {
+  $numOfResamples=1000;
+}
+
+if(defined($opt_2)) {
+  $skipDistance=$opt_2;
+}
+
+if(defined($opt_3)) {
+  $BEMode=$opt_3;
+}
+
+if(defined($opt_f)) {
+  $scoreMode=$opt_f;
+}
+else {
+  $scoreMode="A"; # default: use model average scoring formula
+}
+
+if(defined($opt_p)) {
+  $alpha=$opt_p;
+  if($alpha<0||
+     $alpha>1) {
+    die "Relative importance of ROUGE recall and precision has to be between 0 and 1 inclusively.\n";
+  }
+}
+else {
+  $alpha=0.5; # default is equal importance of ROUGE recall and precision
+}
+
+if(defined($opt_t)) {
+  # make $opt_t as undef when appropriate option is given
+  # when $opt_t is undef, sentence level average will be used
+  if($opt_t==0) {
+    $opt_t=undef;
+  }
+  elsif($opt_t!=1&&
+	$opt_t!=2) {
+    $opt_t=undef; # other than 1 or 2, let $opt_t to be undef
+  }
+}
+
+if(defined($opt_z)) {
+  # If opt_z is specified, the user has to specify a system ID that
+  # is used for identification therefore -a option is not allowed.
+  # Here we make it undef.
+  $opt_a=undef;
+}
+#-------------------------------------------------------------------------------------
+# Setup ROUGE scoring parameters
+%ROUGEParam=();   # ROUGE scoring parameter
+if(defined($lengthLimit)) {
+  $ROUGEParam{"LENGTH"}=$lengthLimit;
+}
+else {
+  $ROUGEParam{"LENGTH"}=undef;
+}
+if(defined($byteLimit)) {
+  $ROUGEParam{"BYTE"}=$byteLimit;
+}
+else {
+  $ROUGEParam{"BYTE"}=undef;
+}
+if(defined($opt_n)) { # ngram size
+  $ROUGEParam{"NSIZE"}=$opt_n;
+}
+else {
+  $ROUGEParam{"NSIZE"}=undef;
+}
+if(defined($weightFactor)) {
+  $ROUGEParam{"WEIGHT"}=$weightFactor;
+}
+else {
+  $ROUGEParam{"WEIGHT"}=undef;
+}
+if(defined($skipDistance)) {
+  $ROUGEParam{"SD"}=$skipDistance;
+}
+else {
+  $ROUGEParam{"SD"}=undef;
+}
+if(defined($scoreMode)) {
+  $ROUGEParam{"SM"}=$scoreMode;
+}
+else {
+  $ROUGEParam{"SM"}=undef;
+}
+if(defined($alpha)) {
+  $ROUGEParam{"ALPHA"}=$alpha;
+}
+else {
+  $ROUGEParam{"ALPHA"}=undef;
+}
+if(defined($opt_t)) {
+  $ROUGEParam{"AVERAGE"}=$opt_t;
+}
+else {
+  $ROUGEParam{"AVERAGE"}=undef;
+}
+if(defined($opt_3)) {
+  $ROUGEParam{"BEMODE"}=$opt_3;
+}
+else {
+  $ROUGEParam{"BEMODE"}=undef;
+}
+#-------------------------------------------------------------------------------------
+# load stopwords
+%stopwords=();
+open(STOP,$stopwords)||die "Cannot open $stopwords\n";
+while(defined($line=<STOP>)) {
+  chomp($line);
+  $stopwords{$line}=1;
+}
+close(STOP);
+# load WordNet database
+if(-e "$wordnetDB") {
+  tie %exceptiondb,'DB_File',"$wordnetDB",O_RDONLY,0440,$DB_HASH or
+    die "Cannot open exception db file for reading: $wordnetDB\n";
+}
+else {
+  die "Cannot open exception db file for reading: $wordnetDB\n";
+}
+#-------------------------------------------------------------------------------------
+# Initialize Porter Stemmer
+&initialise();
+#-------------------------------------------------------------------------------------
+# Read and parse the document
+my $parser = new XML::DOM::Parser;
+my $doc;
+unless(defined($opt_z)) {
+  $doc=$parser->parsefile($ARGV[0]);
+}
+else {
+  open($doc,$ARGV[0])||die "Cannot open $ARGV[0]\n";
+}
+%ROUGEEvals=();
+@ROUGEEvalIDs=();
+%ROUGEPeerIDTable=();
+@allPeerIDs=();
+%knownMissing=(); # remember missing submission already known
+if(defined($doc)) {
+  # read evaluation description file
+  &readEvals(\%ROUGEEvals,\@ROUGEEvalIDs,\%ROUGEPeerIDTable,$doc,undef);
+  # print evaluation configuration
+  if(defined($opt_z)) {
+    if(defined($ARGV[1])) {
+      $systemID=$ARGV[1];
+    }
+    else {
+      $systemID="X"; # default system ID in BE file list evaluation mode
+    }
+    push(@allPeerIDs,$systemID);
+  }
+  else {
+    unless(defined($opt_a)) {
+      $systemID=$ARGV[1];
+      push(@allPeerIDs,$systemID);
+    }
+    else {
+      # run evaluation for each peer listed in the description file
+      @allPeerIDs=sort (keys %ROUGEPeerIDTable);
+    }
+  }
+  foreach $peerID (@allPeerIDs) {
+    %testIDs=();
+    #	print "\@PEER($peerID)--------------------------------------------------\n";
+    if(defined($opt_n)) {
+      # evaluate a specific peer
+      # compute ROUGE score up to $opt_n-gram
+      for($n=1;$n<=$opt_n;$n++) {
+	my (%ROUGEScores,%ROUGEAverages);
+	
+	%ROUGEScores=();
+	foreach $e (@ROUGEEvalIDs) {
+	  if($debug) {
+	    print "\@Eval ($e)\n";
+	  }
+	  $ROUGEParam{"NSIZE"}=$n;
+	  &computeROUGEX("N",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	}
+	# compute averages
+	%ROUGEAverages=();
+	&computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	&printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-$n",$opt_c,$opt_t,$opt_d);
+      }
+    }
+    unless(defined($opt_x)||defined($opt_3)) {
+      #-----------------------------------------------
+      # compute LCS score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("L",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-L",$opt_c,$opt_t,$opt_d);
+    }
+    if(defined($opt_w)) {
+      #-----------------------------------------------
+      # compute WLCS score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("W",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-W-$weightFactor",$opt_c,$opt_t,$opt_d);
+    }
+    if(defined($opt_2)) {
+      #-----------------------------------------------
+      # compute skip bigram score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      if($skipDistance>=0) {
+	if(defined($opt_u)) {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+	elsif(defined($opt_U)) {
+	  # print regular skip bigram results
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S$skipDistance",$opt_c,$opt_t,$opt_d);
+	  #-----------------------------------------------
+	  # compute skip bigram with unigram extension score
+	  $opt_u=1;
+	  %ROUGEScores=();
+	  foreach $e (@ROUGEEvalIDs) {
+	    &computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	  }
+	  $opt_u=undef;
+	  # compute averages
+	  %ROUGEAverages=();
+	  &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+	else {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S$skipDistance",$opt_c,$opt_t,$opt_d);
+	}
+      }
+      else {
+	if(defined($opt_u)) {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU*",$opt_c,$opt_t,$opt_d);
+	}
+	else {
+	  &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-S*",$opt_c,$opt_t,$opt_d);
+	  if(defined($opt_U)) {
+	    #-----------------------------------------------
+	    # compute skip bigram with unigram extension score
+	    $opt_u=1;
+	    %ROUGEScores=();
+	    foreach $e (@ROUGEEvalIDs) {
+	      &computeROUGEX("S",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+	    }
+	    $opt_u=undef;
+	    # compute averages
+	    %ROUGEAverages=();
+	    &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+	    &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-SU*",$opt_c,$opt_t,$opt_d);
+	  }
+	}
+      }
+    }
+    if(defined($opt_3)) {
+      #-----------------------------------------------
+      # compute Basic Element triple score
+      %ROUGEScores=();
+      foreach $e (@ROUGEEvalIDs) {
+	&computeROUGEX("BE",\%ROUGEScores,$e,$ROUGEEvals{$e},$peerID,\%ROUGEParam);
+      }
+      # compute averages
+      %ROUGEAverages=();
+      &computeAverages(\%ROUGEScores,\%ROUGEAverages,$opt_t);
+      &printResults($peerID,\%ROUGEAverages,\%ROUGEScores,"ROUGE-BE-$BEMode",$opt_c,$opt_t,$opt_d);
+    }
+  }
+}
+else {
+  die "Document undefined\n";
+}
+if(defined($opt_z)) {
+  close($doc);
+}
+untie %exceptiondb;
+
+sub printResults {
+  my $peerID=shift;
+  my $ROUGEAverages=shift;
+  my $ROUGEScores=shift;
+  my $methodTag=shift;
+  my $opt_c=shift;
+  my $opt_t=shift;
+  my $opt_d=shift;
+
+  print "---------------------------------------------\n";
+  if(!defined($opt_t)||$opt_t==1) {
+    print "$peerID $methodTag Average_R: $ROUGEAverages->{'AvgR'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_R'} - $ROUGEAverages->{'CIAvgU_R'})\n";
+    print "$peerID $methodTag Average_P: $ROUGEAverages->{'AvgP'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_P'} - $ROUGEAverages->{'CIAvgU_P'})\n";
+    print "$peerID $methodTag Average_F: $ROUGEAverages->{'AvgF'} ";
+    print "($opt_c\%-conf.int. $ROUGEAverages->{'CIAvgL_F'} - $ROUGEAverages->{'CIAvgU_F'})\n";
+  }
+  else {
+    print "$peerID $methodTag M_count: ";
+    print int($ROUGEAverages->{'M_cnt'});
+    print " P_count: ";
+    print int($ROUGEAverages->{'P_cnt'});
+    print " H_count: ";
+    print int($ROUGEAverages->{'H_cnt'});
+    print "\n";
+  }
+  if(defined($opt_d)) {
+    print ".............................................\n";
+    &printPerEvalData($ROUGEScores,"$peerID $methodTag Eval");
+  }
+}
+
+sub bootstrapResampling {
+  my $scores=shift;
+  my $instances=shift;
+  my $seed=shift;
+  my $opt_t=shift;
+  my $sample;
+  my ($i,$ridx);
+  
+  # Use $seed to seed the random number generator to make sure
+  # we have the same random sequence every time, therefore a
+  # consistent estimation of confidence interval in different runs.
+  # This is not necessary. To ensure a consistent result in reporting
+  # results using ROUGE, this is implemented.
+  srand($seed);
+  for($i=0;$i<@{$instances};$i++) {
+    # generate a random index
+    $ridx=int(rand(@{$instances}));
+    unless(defined($sample)) {
+      # setup the resampling array
+      $sample=[];
+      push(@$sample,$scores->{$instances->[$ridx]}[0]);
+      push(@$sample,$scores->{$instances->[$ridx]}[1]);
+      push(@$sample,$scores->{$instances->[$ridx]}[2]);
+    }
+    else {
+      # update the resampling array
+      $sample->[0]+=$scores->{$instances->[$ridx]}[0];
+      $sample->[1]+=$scores->{$instances->[$ridx]}[1];
+      $sample->[2]+=$scores->{$instances->[$ridx]}[2];
+    }
+  }
+  # compute the average result for this resampling procedure
+  unless(defined($opt_t)) {
+    # per instance or sentence average
+    if(@{$instances}>0) {
+      $sample->[0]/=@{$instances};
+      $sample->[1]/=@{$instances};
+      $sample->[2]/=@{$instances};
+    }
+    else {
+      $sample->[0]=0;
+      $sample->[1]=0;
+      $sample->[2]=0;
+    }
+  }
+  else {
+    if($opt_t==1) {
+      # per token or corpus level average
+      # output recall, precision, and f-measure score
+      my ($tmpR,$tmpP,$tmpF);
+      if($sample->[0]>0) {
+	$tmpR=$sample->[2]/$sample->[0]; # recall
+      }
+      else {
+	$tmpR=0;
+      }
+      if($sample->[1]>0) {
+	$tmpP=$sample->[2]/$sample->[1]; # precision
+      }
+      else {
+	$tmpP=0;
+      }
+      if((1-$alpha)*$tmpP+$alpha*$tmpR>0) {
+	$tmpF=($tmpR*$tmpP)/((1-$alpha)*$tmpP+$alpha*$tmpR); # f-measure
+      }
+      else {
+	$tmpF=0;
+      }
+      $sample->[0]=$tmpR;
+      $sample->[1]=$tmpP;
+      $sample->[2]=$tmpF;
+    }
+    else {
+      # $opt_t!=1 => output raw model token count, peer token count, and hit count
+      # do nothing, just return $sample
+    }
+  }
+  return $sample;
+}
+
+sub by_value {
+  $a<=>$b;
+}
+
+sub printPerEvalData {
+  my $ROUGEScores=shift;
+  my $tag=shift; # tag to identify each evaluation
+  my (@instances,$i,$j);
+  
+  @instances=sort by_evalID (keys %$ROUGEScores);
+  foreach $i (@instances) {
+    # print average per evaluation score
+    print "$tag $i R:$ROUGEScores->{$i}[0] P:$ROUGEScores->{$i}[1] F:$ROUGEScores->{$i}[2]\n";
+  }
+}
+
+sub by_evalID {
+  my ($a1,$b1);
+
+  if($a=~/^([0-9]+)/o) {
+    $a1=$1;
+  }
+  if($b=~/^([0-9]+)/o) {
+    $b1=$1;
+  }
+  if(defined($a1)&&defined($b1)) {
+    return $a1<=>$b1;
+  }
+  else {
+    return $a cmp $b;
+  }
+}
+
+sub computeAverages {
+  my $ROUGEScores=shift;
+  my $ROUGEAverages=shift;
+  my $opt_t=shift;
+  my ($avgAvgROUGE_R,$resampleAvgROUGE_R);
+  my ($avgAvgROUGE_P,$resampleAvgROUGE_P);
+  my ($avgAvgROUGE_F,$resampleAvgROUGE_F);
+  my ($ciU,$ciL);
+  my (@instances,$i,$j,@rankedArray_R,@rankedArray_P,@RankedArray_F);
+  
+  @instances=sort (keys %$ROUGEScores);
+  $avgAvgROUGE_R=0;
+  $avgAvgROUGE_P=0;
+  $avgAvgROUGE_F=0;
+  $resampleAvgROUGE_R=0;
+  $resampleAvgROUGE_P=0;
+  $resampleAvgROUGE_F=0;
+  # compute totals
+  foreach $i (@instances) {
+    $avgAvgROUGE_R+=$ROUGEScores->{$i}[0]; # recall     ; or model token count
+    $avgAvgROUGE_P+=$ROUGEScores->{$i}[1]; # precision  ; or peer token count
+    $avgAvgROUGE_F+=$ROUGEScores->{$i}[2]; # f1-measure ; or match token count (hit)
+  }
+  # compute averages
+  unless(defined($opt_t)) {
+    # per sentence average
+    if((scalar @instances)>0) {
+      $avgAvgROUGE_R=sprintf("%7.5f",$avgAvgROUGE_R/(scalar @instances));
+      $avgAvgROUGE_P=sprintf("%7.5f",$avgAvgROUGE_P/(scalar @instances));
+      $avgAvgROUGE_F=sprintf("%7.5f",$avgAvgROUGE_F/(scalar @instances));
+    }
+    else {
+      $avgAvgROUGE_R=sprintf("%7.5f",0);
+      $avgAvgROUGE_P=sprintf("%7.5f",0);
+      $avgAvgROUGE_F=sprintf("%7.5f",0);
+    }
+  }
+  else {
+    if($opt_t==1) {
+      # per token average on corpus level
+      my ($tmpR,$tmpP,$tmpF);
+      if($avgAvgROUGE_R>0) {
+	$tmpR=$avgAvgROUGE_F/$avgAvgROUGE_R;
+      }
+      else {
+	$tmpR=0;
+      }
+      if($avgAvgROUGE_P>0) {
+	$tmpP=$avgAvgROUGE_F/$avgAvgROUGE_P;
+      }
+      else {
+	$tmpP=0;
+      }
+      if((1-$alpha)*$tmpP+$alpha*$tmpR>0) {
+	$tmpF=($tmpR+$tmpP)/((1-$alpha)*$tmpP+$alpha*$tmpR);
+      }
+      else {
+	$tmpF=0;
+      }
+      $avgAvgROUGE_R=sprintf("%7.5f",$tmpR);
+      $avgAvgROUGE_P=sprintf("%7.5f",$tmpP);
+      $avgAvgROUGE_F=sprintf("%7.5f",$tmpF);
+    }
+  }
+  if(!defined($opt_t)||$opt_t==1) {
+    # compute confidence intervals using bootstrap resampling
+    @ResamplingArray=();
+    for($i=0;$i<$numOfResamples;$i++) {
+      my $sample;
+      
+      $sample=&bootstrapResampling($ROUGEScores,\@instances,$i,$opt_t);
+      # sample contains average sum of the sample
+      if(@ResamplingArray==0) {
+	# setup the resampling array for Avg
+	my $s;
+	
+	$s=[];
+	push(@$s,$sample->[0]);
+	push(@ResamplingArray,$s);
+	$s=[];
+	push(@$s,$sample->[1]);
+	push(@ResamplingArray,$s);
+	$s=[];
+	push(@$s,$sample->[2]);
+	push(@ResamplingArray,$s);
+      }
+      else {
+	$rsa=$ResamplingArray[0];
+	push(@{$rsa},$sample->[0]);
+	$rsa=$ResamplingArray[1];
+	push(@{$rsa},$sample->[1]);
+	$rsa=$ResamplingArray[2];
+	push(@{$rsa},$sample->[2]);
+      }
+    }
+    # sort resampling results
+    {
+      # recall
+      @rankedArray_R=sort by_value (@{$ResamplingArray[0]});
+      $ResamplingArray[0]=\@rankedArray_R;
+      for($x=0;$x<=$#rankedArray_R;$x++) {
+	$resampleAvgROUGE_R+=$rankedArray_R[$x];
+	#	print "*R ($x): $rankedArray_R[$x]\n";
+      }
+      $resampleAvgROUGE_R=sprintf("%7.5f",$resampleAvgROUGE_R/(scalar @rankedArray_R));
+      # precision
+      @rankedArray_P=sort by_value (@{$ResamplingArray[1]});
+      $ResamplingArray[1]=\@rankedArray_P;
+      for($x=0;$x<=$#rankedArray_P;$x++) {
+	$resampleAvgROUGE_P+=$rankedArray_P[$x];
+	#	print "*P ($x): $rankedArray_P[$x]\n";
+      }
+      $resampleAvgROUGE_P=sprintf("%7.5f",$resampleAvgROUGE_P/(scalar @rankedArray_P));
+      # f1-measure
+      @rankedArray_F=sort by_value (@{$ResamplingArray[2]});
+      $ResamplingArray[2]=\@rankedArray_F;
+      for($x=0;$x<=$#rankedArray_F;$x++) {
+	$resampleAvgROUGE_F+=$rankedArray_F[$x];
+	#	print "*F ($x): $rankedArray_F[$x]\n";
+      }
+      $resampleAvgROUGE_F=sprintf("%7.5f",$resampleAvgROUGE_F/(scalar @rankedArray_F));
+    }
+    #    $ciU=999-int((100-$opt_c)*10/2); # upper bound index
+    #    $ciL=int((100-$opt_c)*10/2);     # lower bound index
+    $delta=$numOfResamples*((100-$opt_c)/2.0)/100.0;
+    $ciUa=int($numOfResamples-$delta-1); # upper confidence interval lower index
+    $ciUb=$ciUa+1;                       # upper confidence interval upper index
+    $ciLa=int($delta);                   # lower confidence interval lower index
+    $ciLb=$ciLa+1;                       # lower confidence interval upper index
+    $ciR=$numOfResamples-$delta-1-$ciUa; # ratio bewteen lower and upper indexes
+    #    $ROUGEAverages->{"AvgR"}=$avgAvgROUGE_R;
+    #-------
+    # recall
+    $ROUGEAverages->{"AvgR"}=$resampleAvgROUGE_R;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_R"}=sprintf("%7.5f",$ResamplingArray[0][$ciLa]+
+					 ($ResamplingArray[0][$ciLb]-$ResamplingArray[0][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_R"}=sprintf("%7.5f",$ResamplingArray[0][$ciUa]+
+					 ($ResamplingArray[0][$ciUb]-$ResamplingArray[0][$ciUa])*$ciR);
+    #-------
+    # precision
+    $ROUGEAverages->{"AvgP"}=$resampleAvgROUGE_P;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_P"}=sprintf("%7.5f",$ResamplingArray[1][$ciLa]+
+					 ($ResamplingArray[1][$ciLb]-$ResamplingArray[1][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_P"}=sprintf("%7.5f",$ResamplingArray[1][$ciUa]+
+					 ($ResamplingArray[1][$ciUb]-$ResamplingArray[1][$ciUa])*$ciR);
+    #-------
+    # f1-measure
+    $ROUGEAverages->{"AvgF"}=$resampleAvgROUGE_F;
+    # find condifence intervals; take maximum distance from the mean
+    $ROUGEAverages->{"CIAvgL_F"}=sprintf("%7.5f",$ResamplingArray[2][$ciLa]+
+					 ($ResamplingArray[2][$ciLb]-$ResamplingArray[2][$ciLa])*$ciR);
+    $ROUGEAverages->{"CIAvgU_F"}=sprintf("%7.5f",$ResamplingArray[2][$ciUa]+
+					 ($ResamplingArray[2][$ciUb]-$ResamplingArray[2][$ciUa])*$ciR);
+    $ROUGEAverages->{"M_cnt"}=$avgAvgROUGE_R; # model token count
+    $ROUGEAverages->{"P_cnt"}=$avgAvgROUGE_P; # peer token count
+    $ROUGEAverages->{"H_cnt"}=$avgAvgROUGE_F; # hit token count
+  }
+  else {
+    # $opt_t==2 => output raw count instead of precision, recall, and f-measure values
+    # in this option, no resampling is necessary, just output the raw counts
+    $ROUGEAverages->{"M_cnt"}=$avgAvgROUGE_R; # model token count
+    $ROUGEAverages->{"P_cnt"}=$avgAvgROUGE_P; # peer token count
+    $ROUGEAverages->{"H_cnt"}=$avgAvgROUGE_F; # hit token count
+  }
+}
+
+sub computeROUGEX {
+  my $metric=shift;       # which ROUGE metric to compute?
+  my $ROUGEScores=shift;
+  my $evalID=shift;
+  my $ROUGEEval=shift;    # one particular evaluation pair
+  my $peerID=shift;       # a specific peer ID
+  my $ROUGEParam=shift;   # ROUGE scoring parameters
+  my $lengthLimit;        # lenght limit in words
+  my $byteLimit;          # length limit in bytes
+  my $NSIZE;              # ngram size for ROUGE-N
+  my $weightFactor;       # weight factor for ROUGE-W
+  my $skipDistance;       # skip distance for ROUGE-S
+  my $scoreMode;          # scoring mode: A = model average; B = best model
+  my $alpha;              # relative importance between recall and precision
+  my $opt_t;              # ROUGE score counting mode
+  my $BEMode;             # Basic Element scoring mode
+  my ($c,$cx,@modelPaths,$modelIDs,$modelRoot,$inputFormat);
+
+  $lengthLimit=$ROUGEParam->{"LENGTH"};
+  $byteLimit=$ROUGEParam->{"BYTE"};
+  $NSIZE=$ROUGEParam->{"NSIZE"};
+  $weightFactor=$ROUGEParam->{"WEIGHT"};
+  $skipDistance=$ROUGEParam->{"SD"};
+  $scoreMode=$ROUGEParam->{"SM"};
+  $alpha=$ROUGEParam->{"ALPHA"};
+  $opt_t=$ROUGEParam->{"AVERAGE"};
+  $BEMode=$ROUGEParam->{"BEMODE"};
+  
+  # Check to see if this evaluation trial contains this $peerID.
+  # Sometimes not every peer provides response for each
+  # evaluation trial.
+  unless(exists($ROUGEEval->{"Ps"}{$peerID})) {
+    unless(exists($knownMissing{$evalID})) {
+      $knownMissing{$evalID}={};
+    }
+    unless(exists($knownMissing{$evalID}{$peerID})) {
+      print STDERR "\*ROUGE Warning: test instance for peer $peerID does not exist for evaluation $evalID\n";
+      $knownMissing{$evalID}{$peerID}=1;
+    }
+    return;
+  }
+  unless(defined($opt_z)) {
+    $peerPath=$ROUGEEval->{"PR"}."/".$ROUGEEval->{"Ps"}{$peerID};
+  }
+  else {
+    # if opt_z is set then peerPath is read from a file list that
+    # includes the path to the peer.
+    $peerPath=$ROUGEEval->{"Ps"}{$peerID};
+  }
+  if(defined($ROUGEEval->{"MR"})) {
+    $modelRoot=$ROUGEEval->{"MR"};
+  }
+  else {
+    # if opt_z is set then modelPath is read from a file list that
+    # includes the path to the model.
+    $modelRoot="";
+  }
+  $modelIDs=$ROUGEEval->{"MIDList"};
+  $inputFormat=$ROUGEEval->{"IF"};
+  # construct combined model
+  @modelPaths=(); # reset model paths
+  for($cx=0;$cx<=$#{$modelIDs};$cx++) {
+    my $modelID;
+    $modelID=$modelIDs->[$cx];
+    unless(defined($opt_z)) {
+      $modelPath="$modelRoot/$ROUGEEval->{\"Ms\"}{$modelID}"; # get full model path
+    }
+    else {
+      # if opt_z is set then modelPath is read from a file list that
+      # includes the full path to the model.
+      $modelPath="$ROUGEEval->{\"Ms\"}{$modelID}"; # get full model path
+    }
+    if(-e "$modelPath") {
+      #		    print "*$modelPath\n";
+    }
+    else {
+      die "Cannot find model summary: $modelPath\n";
+    }
+    push(@modelPaths,$modelPath);
+  }
+  #---------------------------------------------------------------
+  # evaluate peer
+  {
+    my (@results);
+    my ($testID,$avgROUGE,$avgROUGE_P,$avgROUGE_F);
+    @results=();
+    if($metric eq "N") {
+      &computeNGramScore(\@modelPaths,$peerPath,\@results,$NSIZE,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "L") {
+      &computeLCSScore(\@modelPaths,$peerPath,\@results,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "W") {
+      &computeWLCSScore(\@modelPaths,$peerPath,\@results,$lengthLimit,$byteLimit,$inputFormat,$weightFactor,$scoreMode,$alpha);
+    }
+    elsif($metric eq "S") {
+      &computeSkipBigramScore(\@modelPaths,$peerPath,\@results,$skipDistance,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    elsif($metric eq "BE") {
+      &computeBEScore(\@modelPaths,$peerPath,\@results,$BEMode,$lengthLimit,$byteLimit,$inputFormat,$scoreMode,$alpha);
+    }
+    else {
+      die "Unknown ROUGE metric ID: $metric, has to be N, L, W, or S\n";
+      
+    }
+    unless(defined($opt_t)) {
+      # sentence level average
+      $avgROUGE=sprintf("%7.5f",$results[2]);
+      $avgROUGE_P=sprintf("%7.5f",$results[4]);
+      $avgROUGE_F=sprintf("%7.5f",$results[5]);
+    }
+    else {
+      # corpus level per token average
+      $avgROUGE=$results[0]; # total model token count
+      $avgROUGE_P=$results[3]; # total peer token count
+      $avgROUGE_F=$results[1]; # total match count between model and peer, i.e. hit
+    }
+    # record ROUGE scores for the current test
+    $testID="$evalID\.$peerID";
+    if($debug) {
+      print "$testID\n";
+    }
+    unless(exists($testIDs{$testID})) {
+      $testIDs{$testID}=1;
+    }
+    unless(exists($ROUGEScores->{$testID})) {
+      $ROUGEScores->{$testID}=[];
+      push(@{$ROUGEScores->{$testID}},$avgROUGE);   # average ; or model token count
+      push(@{$ROUGEScores->{$testID}},$avgROUGE_P); # average ; or peer token count
+      push(@{$ROUGEScores->{$testID}},$avgROUGE_F); # average ; or match token count (hit)
+    }
+  }
+}
+
+# 10/21/2004 add selection of scoring mode
+# A: average over all models
+# B: take only the best score
+sub computeNGramScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $NSIZE=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,$modelText,$peerText,$text,@tokens);
+  my (%model_grams,%peer_grams);
+  my ($gramHit,$gramScore,$gramScoreBest);
+  my ($totalGramHit,$totalGramCount);
+  my ($gramScoreP,$gramScoreF,$totalGramCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalGramHit=0;
+  $totalGramCount=0;
+  $gramScoreBest=-1;
+  $gramScoreP=0; # precision
+  $gramScoreF=0; # f-measure
+  $totalGramCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  %peer_grams=();
+  $peerText="";
+  &readText($peerPath,\$peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText,\%peer_grams,$NSIZE);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(defined($peerText)) {
+      print "$peerText\n";
+      print join("|",%peer_grams),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_grams=();
+    $modelText="";
+    &readText($modelPath,\$modelText,$inputFormat,$lengthLimit,$byteLimit);
+    &createNGram($modelText,\%model_grams,$NSIZE);
+    if($debug) {
+      if(defined($modelText)) {
+	print "$modelText\n";
+	print join("|",%model_grams),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute ngram score
+    &ngramScore(\%model_grams,\%peer_grams,\$gramHit,\$gramScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($gramScore>$gramScoreBest) {
+	# only take a better score (i.e. better match)
+	$gramScoreBest=$gramScore;
+	$totalGramHit=$gramHit;
+	$totalGramCount=$model_grams{"_cn_"};
+	$totalGramCountP=$peer_grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # unigram
+  push(@$results,$totalGramCount); # total number of ngrams in models
+  push(@$results,$totalGramHit);
+  if($totalGramCount!=0) {
+    $gramScore=sprintf("%7.5f",$totalGramHit/$totalGramCount);
+  }
+  else {
+    $gramScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScore);
+  push(@$results,$totalGramCountP); # total number of ngrams in peers
+  if($totalGramCountP!=0) {
+    $gramScoreP=sprintf("%7.5f",$totalGramHit/$totalGramCountP);
+  }
+  else {
+    $gramScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreP);      # precision score
+  if((1-$alpha)*$gramScoreP+$alpha*$gramScore>0) {
+    $gramScoreF=sprintf("%7.5f",($gramScoreP*$gramScore)/((1-$alpha)*$gramScoreP+$alpha*$gramScore));
+  }
+  else {
+    $gramScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreF);      # f1-measure score
+  if($debug) {
+    print "total $NSIZE-gram model count: $totalGramCount\n";
+    print "total $NSIZE-gram peer count: $totalGramCountP\n";
+    print "total $NSIZE-gram hit: $totalGramHit\n";
+    print "total ROUGE-$NSIZE\-R: $gramScore\n";
+    print "total ROUGE-$NSIZE\-P: $gramScoreP\n";
+    print "total ROUGE-$NSIZE\-F: $gramScoreF\n";
+  }
+}
+
+sub computeSkipBigramScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $skipDistance=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,$modelText,$peerText,$text,@tokens);
+  my (%model_grams,%peer_grams);
+  my ($gramHit,$gramScore,$gramScoreBest);
+  my ($totalGramHitm,$totalGramCount);
+  my ($gramScoreP,$gramScoreF,$totalGramCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalGramHit=0;
+  $totalGramCount=0;
+  $gramScoreBest=-1;
+  $gramScoreP=0; # precision
+  $gramScoreF=0; # f-measure
+  $totalGramCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  %peer_grams=();
+  $peerText="";
+  &readText($peerPath,\$peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &createSkipBigram($peerText,\%peer_grams,$skipDistance);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(defined($peerText)) {
+      print "$peerText\n";
+      print join("|",%peer_grams),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_grams=();
+    $modelText="";
+    &readText($modelPath,\$modelText,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createSkipBigram($modelText,\%model_grams,$skipDistance);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    if($debug) {
+      if(defined($modelText)) {
+	print "$modelText\n";
+	print join("|",%model_grams),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute ngram score
+    &skipBigramScore(\%model_grams,\%peer_grams,\$gramHit,\$gramScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($gramScore>$gramScoreBest) {
+	# only take a better score (i.e. better match)
+	$gramScoreBest=$gramScore;
+	$totalGramHit=$gramHit;
+	$totalGramCount=$model_grams{"_cn_"};
+	$totalGramCountP=$peer_grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalGramHit+=$gramHit;
+      $totalGramCount+=$model_grams{"_cn_"};
+      $totalGramCountP+=$peer_grams{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # unigram
+  push(@$results,$totalGramCount); # total number of ngrams
+  push(@$results,$totalGramHit);
+  if($totalGramCount!=0) {
+    $gramScore=sprintf("%7.5f",$totalGramHit/$totalGramCount);
+  }
+  else {
+    $gramScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScore);
+  push(@$results,$totalGramCountP); # total number of ngrams in peers
+  if($totalGramCountP!=0) {
+    $gramScoreP=sprintf("%7.5f",$totalGramHit/$totalGramCountP);
+  }
+  else {
+    $gramScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreP);      # precision score
+  if((1-$alpha)*$gramScoreP+$alpha*$gramScore>0) {
+    $gramScoreF=sprintf("%7.5f",($gramScoreP*$gramScore)/((1-$alpha)*$gramScoreP+$alpha*$gramScore));
+  }
+  else {
+    $gramScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$gramScoreF);      # f1-measure score
+  if($debug) {
+    print "total ROUGE-S$skipDistance model count: $totalGramCount\n";
+    print "total ROUGE-S$skipDistance peer count: $totalGramCountP\n";
+    print "total ROUGE-S$skipDistance hit: $totalGramHit\n";
+    print "total ROUGE-S$skipDistance\-R: $gramScore\n";
+    print "total ROUGE-S$skipDistance\-P: $gramScore\n";
+    print "total ROUGE-S$skipDistance\-F: $gramScore\n";
+  }
+}
+
+sub computeLCSScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelText,@peerText,$text,@tokens);
+  my (@modelTokens,@peerTokens);
+  my ($lcsHit,$lcsScore,$lcsBase,$lcsScoreBest);
+  my ($totalLCSHitm,$totalLCSCount);
+  my (%peer_1grams,%tmp_peer_1grams,%model_1grams,$peerText1,$modelText1);
+  my ($lcsScoreP,$lcsScoreF,$totalLCSCountP);
+  
+  #------------------------------------------------
+  $totalLCSHit=0;
+  $totalLCSCount=0;
+  $lcsScoreBest=-1;
+  $lcsScoreP=0;
+  $lcsScoreF=0;
+  $totalLCSCountP=0;
+  #------------------------------------------------
+  # read peer file and create peer n-gram maps
+  @peerTokens=();
+  @peerText=();
+  &readText_LCS($peerPath,\@peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &tokenizeText_LCS(\@peerText,\@peerTokens);
+  #------------------------------------------------
+  # create unigram for clipping
+  %peer_1grams=();
+  &readText($peerPath,\$peerText1,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText1,\%peer_1grams,1);
+  if($debug) {
+    my $i;
+    print "***P $peerPath\n";
+    print join("\n",@peerText),"\n";
+    for($i=0;$i<=$#peerText;$i++) {
+      print $i,": ",join("|",@{$peerTokens[$i]}),"\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %tmp_peer_1grams=%peer_1grams; # renew peer unigram hash, so the peer count can be reset to the orignal number
+    @modelTokens=();
+    @modelText=();
+    &readText_LCS($modelPath,\@modelText,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) {
+      $opt_m=1;
+      &tokenizeText_LCS(\@modelText,\@modelTokens);
+      $opt_m=undef;
+    }
+    else {
+      &tokenizeText_LCS(\@modelText,\@modelTokens);
+    }
+    #------------------------------------------------
+    # create unigram for clipping
+    %model_1grams=();
+    &readText($modelPath,\$modelText1,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }        
+    &createNGram($modelText1,\%model_1grams,1);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    #------------------------------------------------
+    # compute LCS score
+    &lcs(\@modelTokens,\@peerTokens,\$lcsHit,\$lcsScore,\$lcsBase,\%model_1grams,\%tmp_peer_1grams);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reductant information contained in the peer summary.
+    # Previous method that lumps model text together and inflates the peer summary
+    # the number of references time would reward redundant information
+    if($scoreMode eq "A") {
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=$lcsBase;
+      $totalLCSCountP+=$peer_1grams{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($lcsScore>$lcsScoreBest) {
+	# only take a better score (i.e. better match)
+	$lcsScoreBest=$lcsScore;
+	$totalLCSHit=$lcsHit;
+	$totalLCSCount=$lcsBase;
+	$totalLCSCountP=$peer_1grams{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=$lcsBase;
+      $totalLCSCountP+=$peer_1grams{"_cn_"};
+    }
+    if($debug) {
+      my $i;
+      print "***M $modelPath\n";
+      print join("\n",@modelText),"\n";
+      for($i=0;$i<=$#modelText;$i++) {
+	print $i,": ",join("|",@{$modelTokens[$i]}),"\n";
+      }
+    }
+  }
+  # prepare score result for return
+  push(@$results,$totalLCSCount); # total number of ngrams
+  push(@$results,$totalLCSHit);
+  if($totalLCSCount!=0) {
+    $lcsScore=sprintf("%7.5f",$totalLCSHit/$totalLCSCount);
+  }
+  else {
+    $lcsScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScore);
+  push(@$results,$totalLCSCountP); # total number of token in peers
+  if($totalLCSCountP!=0) {
+    $lcsScoreP=sprintf("%7.5f",$totalLCSHit/$totalLCSCountP);
+  }
+  else {
+    $lcsScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreP);
+  if((1-$alpha)*$lcsScoreP+$alpha*$lcsScore>0) {
+    $lcsScoreF=sprintf("%7.5f",($lcsScoreP*$lcsScore)/((1-$alpha)*$lcsScoreP+$alpha*$lcsScore));
+  }
+  else {
+    $lcsScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreF);
+  if($debug) {
+    print "total ROUGE-L model count: $totalLCSCount\n";
+    print "total ROUGE-L peer count: $totalLCSCountP\n";
+    print "total ROUGE-L hit: $totalLCSHit\n";
+    print "total ROUGE-L-R score: $lcsScore\n";
+    print "total ROUGE-L-P: $lcsScoreP\n";
+    print "total ROUGE-L-F: $lcsScoreF\n";
+  }
+}
+
+sub computeWLCSScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $weightFactor=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelText,@peerText,$text,@tokens);
+  my (@modelTokens,@peerTokens);
+  my ($lcsHit,$lcsScore,$lcsBase,$lcsScoreBest);
+  my ($totalLCSHitm,$totalLCSCount);
+  my (%peer_1grams,%tmp_peer_1grams,%model_1grams,$peerText1,$modelText1);
+  my ($lcsScoreP,$lcsScoreF,$totalLCSCountP);
+  
+  #------------------------------------------------
+  # read model file and create model n-gram maps
+  $totalLCSHit=0;
+  $totalLCSCount=0;
+  $lcsScoreBest=-1;
+  $lcsScoreP=0;
+  $lcsScoreF=0;
+  $totalLCSCountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-gram maps
+  @peerTokens=();
+  @peerText=();
+  &readText_LCS($peerPath,\@peerText,$inputFormat,$lengthLimit,$byteLimit);
+  &tokenizeText_LCS(\@peerText,\@peerTokens);
+  #------------------------------------------------
+  # create unigram for clipping
+  %peer_1grams=();
+  &readText($peerPath,\$peerText1,$inputFormat,$lengthLimit,$byteLimit);
+  &createNGram($peerText1,\%peer_1grams,1);
+  if($debug) {
+    my $i;
+    print "***P $peerPath\n";
+    print join("\n",@peerText),"\n";
+    for($i=0;$i<=$#peerText;$i++) {
+      print $i,": ",join("|",@{$peerTokens[$i]}),"\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %tmp_peer_1grams=%peer_1grams; # renew peer unigram hash, so the peer count can be reset to the orignal number
+    @modelTokens=();
+    @modelText=();
+    &readText_LCS($modelPath,\@modelText,$inputFormat,$lengthLimit,$byteLimit);
+    &tokenizeText_LCS(\@modelText,\@modelTokens);
+    #------------------------------------------------
+    # create unigram for clipping
+    %model_1grams=();
+    &readText($modelPath,\$modelText1,$inputFormat,$lengthLimit,$byteLimit);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createNGram($modelText1,\%model_1grams,1);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    #------------------------------------------------
+    # compute WLCS score
+    &wlcs(\@modelTokens,\@peerTokens,\$lcsHit,\$lcsScore,\$lcsBase,$weightFactor,\%model_1grams,\%tmp_peer_1grams);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reductant information contained in the peer summary.
+    # Previous method that lumps model text together and inflates the peer summary
+    # the number of references time would reward redundant information
+    if($scoreMode eq "A") {
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=&wlcsWeight($lcsBase,$weightFactor);
+      $totalLCSCountP+=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+    }
+    elsif($scoreMode eq "B") {
+      if($lcsScore>$lcsScoreBest) {
+	# only take a better score (i.e. better match)
+	$lcsScoreBest=$lcsScore;
+	$totalLCSHit=$lcsHit;
+	$totalLCSCount=&wlcsWeight($lcsBase,$weightFactor);
+	$totalLCSCountP=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+      }
+    }
+    else {
+      # use average mode
+      $totalLCSHit+=$lcsHit;
+      $totalLCSCount+=&wlcsWeight($lcsBase,$weightFactor);
+      $totalLCSCountP+=&wlcsWeight($peer_1grams{"_cn_"},$weightFactor);
+    }
+    if($debug) {
+      my $i;
+      print "***M $modelPath\n";
+      print join("\n",@modelText),"\n";
+      for($i=0;$i<=$#modelText;$i++) {
+	print $i,": ",join("|",@{$modelTokens[$i]}),"\n";
+      }
+    }
+  }
+  # prepare score result for return
+  push(@$results,$totalLCSCount); # total number of ngrams
+  push(@$results,$totalLCSHit);
+  if($totalLCSCount!=0) {
+    $lcsScore=sprintf("%7.5f",&wlcsWeightInverse($totalLCSHit/$totalLCSCount,$weightFactor));
+  }
+  else {
+    $lcsScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScore);
+  push(@$results,$totalLCSCountP); # total number of token in peers
+  if($totalLCSCountP!=0) {
+    $lcsScoreP=sprintf("%7.5f",&wlcsWeightInverse($totalLCSHit/$totalLCSCountP,$weightFactor));
+  }
+  else {
+    $lcsScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreP);
+  if((1-$alpha)*$lcsScoreP+$alpha*$lcsScore>0) {
+    $lcsScoreF=sprintf("%7.5f",($lcsScoreP*$lcsScore)/((1-$alpha)*$lcsScoreP+$alpha*$lcsScore));
+  }
+  else {
+    $lcsScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$lcsScoreF);
+  if($debug) {
+    print "total ROUGE-W-$weightFactor model count: $totalLCSCount\n";
+    print "total ROUGE-W-$weightFactor peer count: $totalLCSCountP\n";
+    print "total ROUGE-W-$weightFactor hit: $totalLCSHit\n";
+    print "total ROUGE-W-$weightFactor-R score: $lcsScore\n";
+    print "total ROUGE-W-$weightFactor-P score: $lcsScoreP\n";
+    print "total ROUGE-W-$weightFactor-F score: $lcsScoreF\n";
+  }
+}
+
+sub computeBEScore {
+  my $modelPaths=shift;
+  my $peerPath=shift;
+  my $results=shift;
+  my $BEMode=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my $inputFormat=shift;
+  my $scoreMode=shift;
+  my $alpha=shift;
+  my ($modelPath,@modelBEList,@peerBEList,$text,@tokens);
+  my (%model_BEs,%peer_BEs);
+  my ($BEHit,$BEScore,$BEScoreBest);
+  my ($totalBEHit,$totalBECount);
+  my ($BEScoreP,$BEScoreF,$totalBECountP);
+  
+  #------------------------------------------------
+  # read model file and create model BE maps
+  $totalBEHit=0;
+  $totalBECount=0;
+  $BEScoreBest=-1;
+  $BEScoreP=0; # precision
+  $BEScoreF=0; # f-measure
+  $totalBECountP=0;
+  #------------------------------------------------
+  # read peer file and create model n-BE maps
+  %peer_BEs=();
+  @peerBEList=();
+  &readBE($peerPath,\@peerBEList,$inputFormat);
+  &createBE(\@peerBEList,\%peer_BEs,$BEMode);
+  if($debug) {
+    print "***P $peerPath\n";
+    if(scalar @peerBEList > 0) {
+#      print join("\n",@peerBEList);
+#      print "\n";
+      print join("#",%peer_BEs),"\n";
+    }
+    else {
+      print "---empty text---\n";
+    }
+  }
+  foreach $modelPath (@$modelPaths) {
+    %model_BEs=();
+    @modelBEList=();
+    &readBE($modelPath,\@modelBEList,$inputFormat);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=1;
+    }
+    &createBE(\@modelBEList,\%model_BEs,$BEMode);
+    if(defined($opt_M)) { # only apply stemming on models
+      $opt_m=undef;
+    }
+    if($debug) {
+      if(scalar @modelBEList > 0) {
+#	print join("\n",@modelBEList);
+#	print "\n";
+	print join("#",%model_BEs),"\n";
+      }
+      else {
+	print "---empty text---\n";
+      }
+    }
+    #------------------------------------------------
+    # compute BE score
+    &getBEScore(\%model_BEs,\%peer_BEs,\$BEHit,\$BEScore);
+    # collect hit and count for each models
+    # This will effectively clip hit for each model; therefore would not give extra
+    # credit to reducdant information contained in the peer summary.
+    if($scoreMode eq "A") {
+      $totalBEHit+=$BEHit;
+      $totalBECount+=$model_BEs{"_cn_"};
+      $totalBECountP+=$peer_BEs{"_cn_"};
+    }
+    elsif($scoreMode eq "B") {
+      if($BEScore>$BEScoreBest) {
+	# only take a better score (i.e. better match)
+	$BEScoreBest=$BEScore;
+	$totalBEHit=$BEHit;
+	$totalBECount=$model_BEs{"_cn_"};
+	$totalBECountP=$peer_BEs{"_cn_"};
+      }
+    }
+    else {
+      # use average mode
+      $totalBEHit+=$BEHit;
+      $totalBECount+=$model_BEs{"_cn_"};
+      $totalBECountP+=$peer_BEs{"_cn_"};
+    }
+    if($debug) {
+      print "***M $modelPath\n";
+    }
+  }
+  # prepare score result for return
+  # uniBE
+  push(@$results,$totalBECount); # total number of nbes in models
+  push(@$results,$totalBEHit);
+  if($totalBECount!=0) {
+    $BEScore=sprintf("%7.5f",$totalBEHit/$totalBECount);
+  }
+  else {
+    $BEScore=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScore);
+  push(@$results,$totalBECountP); # total number of nBEs in peers
+  if($totalBECountP!=0) {
+    $BEScoreP=sprintf("%7.5f",$totalBEHit/$totalBECountP);
+  }
+  else {
+    $BEScoreP=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScoreP);      # precision score
+  if((1-$alpha)*$BEScoreP+$alpha*$BEScore>0) {
+    $BEScoreF=sprintf("%7.5f",($BEScoreP*$BEScore)/((1-$alpha)*$BEScoreP+$alpha*$BEScore));
+  }
+  else {
+    $BEScoreF=sprintf("%7.5f",0);
+  }
+  push(@$results,$BEScoreF);      # f1-measure score
+  if($debug) {
+    print "total BE-$BEMode model count: $totalBECount\n";
+    print "total BE-$BEMode peer count: $totalBECountP\n";
+    print "total BE-$BEMode hit: $totalBEHit\n";
+    print "total ROUGE-BE-$BEMode\-R: $BEScore\n";
+    print "total ROUGE-BE-$BEMode\-P: $BEScoreP\n";
+    print "total ROUGE-BE-$BEMode\-F: $BEScoreF\n";
+  }
+}
+
+sub readTextOld {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$bsize,$wsize,@words,$done);
+  
+  $$tokenizedText=undef;
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a (size=\"[0-9]+\" )?name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$3;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      $line=~s/^\s+//;
+      $line=~s/\s+$//;
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(defined($$tokenizedText)) {
+    $$tokenizedText=~s/\-/ \- /g;
+    $$tokenizedText=~s/[^A-Za-z0-9\-]/ /g;
+    $$tokenizedText=~s/^\s+//;
+    $$tokenizedText=~s/\s+$//;
+    $$tokenizedText=~s/\s+/ /g;
+  }
+  else {
+    print STDERR "readText: $inPath -> empty text\n";
+  }
+  #    print "($$tokenizedText)\n\n";
+}
+
+# enforce length cutoff at the file level
+# convert different input format into SPL format then put them into
+# tokenizedText
+sub readText {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+####### modified by Benoit Favre
+	my $readText_signature = "$inPath $type $lengthLimit $byteLimit";
+	if(exists $readText_cache{$readText_signature}) {
+		$$tokenizedText = $readText_cache{$readText_signature};
+		return;
+	}
+####### end of modification
+  my ($text,$bsize,$wsize,@words,$done,@sntList);
+  
+  $$tokenizedText=undef;
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  @sntList=();
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a size=\"[0-9]+\" name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o||
+	 $line=~/^<a name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$2;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if($lengthLimit==0&&$byteLimit==0) {
+    $$tokenizedText=join(" ",@sntList);
+  }
+  elsif($lengthLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen,@tokens);
+      @tokens=split(/\s+/,$s);
+      $sLen=scalar @tokens;
+      if($tmpTextLen+$sLen<$lengthLimit) {
+	if($tmpTextLen!=0) {
+#MODIFIED 2008-06-05 favre@icsi.berkeley.edu
+	  $tmpText.=" | $s";
+#END MODIFIED
+	}
+	else {
+	  $tmpText.="$s";
+	}
+	$tmpTextLen+=$sLen;
+      }
+      else {
+	if($tmpTextLen>0) {
+	  $tmpText.=" ";
+	}
+	$tmpText.=join(" ",@tokens[0..$lengthLimit-$tmpTextLen-1]);
+	last;
+      }
+    }
+    if(length($tmpText)>0) {
+      $$tokenizedText=$tmpText;
+    }
+  }
+  elsif($byteLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen);
+      $sLen=length($s);
+      if($tmpTextLen+$sLen<$byteLimit) {
+	if($tmpTextLen!=0) {
+	  $tmpText.=" $s";
+	}
+	else {
+	  $tmpText.="$s";
+	}
+	$tmpTextLen+=$sLen;
+      }
+      else {
+	if($tmpTextLen>0) {
+	  $tmpText.=" ";
+	}
+	$tmpText.=substr($s,0,$byteLimit-$tmpTextLen);
+	last;
+      }
+    }
+    if(length($tmpText)>0) {
+      $$tokenizedText=$tmpText;
+    }
+  }
+  if(defined($$tokenizedText)) {
+    $$tokenizedText=~s/\-/ \- /g;
+#MODIFIED 2008-06-05 favre@icsi.berkeley.edu
+    $$tokenizedText=~s/[^A-Za-z0-9\|\-]/ /g;
+#END MODIFIED
+    $$tokenizedText=~s/^\s+//;
+    $$tokenizedText=~s/\s+$//;
+    $$tokenizedText=~s/\s+/ /g;
+  }
+  else {
+    print STDERR "readText: $inPath -> empty text\n";
+  }
+####### modified by Benoit Favre
+  $readText_cache{$readText_signature} = "$$tokenizedText";
+###### end of modification
+}
+
+sub readBE {
+  my $inPath=shift;
+  my $BEList=shift;
+  my $type=shift;
+  my ($line);
+  
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if(defined($opt_v)) {
+    print STDERR "$inPath\n";
+  }
+  if($type=~/^SIMPLE$/oi) {
+    while(defined($line=<TEXT>)) { # Simple BE triple format
+      chomp($line);
+      push(@{$BEList},$line);
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard BE format
+    while(defined($line=<TEXT>)) {
+      # place holder
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(scalar @{$BEList} ==0) {
+    print STDERR "readBE: $inPath -> empty text\n";
+  }
+}
+
+sub checkSummarySize {
+  my $tokenizedText=shift;
+  my $text=shift;
+  my $wsize=shift;
+  my $bsize=shift;
+  my $done=shift;
+  my $lenghtLimit=shift;
+  my $byteLimit=shift;
+  my (@words);
+  
+  @words=split(/\s+/,$$text);
+  if(($lengthLimit==0&&$byteLimit==0)||
+     ($lengthLimit!=0&&(scalar @words)+$$wsize<=$lengthLimit)||
+     ($byteLimit!=0&&length($$text)+$$bsize<=$byteLimit)) {
+    if(defined($$tokenizedText)) {
+      $$tokenizedText.=" $$text";
+    }
+    else {
+      $$tokenizedText=$$text;
+    }
+    $$bsize+=length($$text);
+    $$wsize+=(scalar @words);
+  }
+  elsif($lengthLimit!=0&&(scalar @words)+$$wsize>$lengthLimit) {
+    if($$done==0) {
+      if(defined($$tokenizedText)) {
+	$$tokenizedText.=" ";
+	$$tokenizedText.=join(" ",@words[0..$lengthLimit-$$wsize-1]);
+      }
+      else {
+	$$tokenizedText=join(" ",@words[0..$lengthLimit-$$wsize-1]);
+      }
+      $$done=1;
+    }
+  }
+  elsif($byteLimit!=0&&length($$text)+$$bsize>$byteLimit) {
+    if($$done==0) {
+      if(defined($$tokenizedText)) {
+	$$tokenizedText.=" ";
+	$$tokenizedText.=substr($$text,0,$byteLimit-$$bsize);
+      }
+      else {
+	$$tokenizedText=substr($$text,0,$byteLimit-$$bsize);
+	
+      }
+      $$done=1;
+    }
+  }
+}
+
+# LCS computing is based on unit and cannot lump all the text together
+# as in computing ngram co-occurrences
+sub readText_LCS {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$t,$bsize,$wsize,$done,@sntList);
+  
+  @{$tokenizedText}=();
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  @sntList=();
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a size=\"[0-9]+\" name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o||
+	 $line=~/^<a name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$2;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	push(@sntList,$text);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if($lengthLimit==0&&$byteLimit==0) {
+    @{$tokenizedText}=@sntList;
+  }
+  elsif($lengthLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen,@tokens);
+      @tokens=split(/\s+/,$s);
+      $sLen=scalar @tokens;
+      if($tmpTextLen+$sLen<$lengthLimit) {
+	$tmpTextLen+=$sLen;
+	push(@{$tokenizedText},$s);
+      }
+      else {
+	push(@{$tokenizedText},join(" ",@tokens[0..$lengthLimit-$tmpTextLen-1]));
+	last;
+      }
+    }
+  }
+  elsif($byteLimit!=0) {
+    my ($tmpText);
+    $tmpText="";
+    $tmpTextLen=0;
+    foreach $s (@sntList) {
+      my ($sLen);
+      $sLen=length($s);
+      if($tmpTextLen+$sLen<$byteLimit) {
+	push(@{$tokenizedText},$s);
+      }
+      else {
+	push(@{$tokenizedText},substr($s,0,$byteLimit-$tmpTextLen));
+	last;
+      }
+    }
+  }
+  if(defined(@{$tokenizedText}>0)) {
+    for($t=0;$t<@{$tokenizedText};$t++) {
+      $tokenizedText->[$t]=~s/\-/ \- /g;
+      $tokenizedText->[$t]=~s/[^A-Za-z0-9\-]/ /g;
+      $tokenizedText->[$t]=~s/^\s+//;
+      $tokenizedText->[$t]=~s/\s+$//;
+      $tokenizedText->[$t]=~s/\s+/ /g;
+    }
+  }
+  else {
+    print STDERR "readText_LCS: $inPath -> empty text\n";
+  }
+}
+
+# LCS computing is based on unit and cannot lump all the text together
+# as in computing ngram co-occurrences
+sub readText_LCS_old {
+  my $inPath=shift;
+  my $tokenizedText=shift;
+  my $type=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my ($text,$t,$bsize,$wsize,$done);
+  
+  @{$tokenizedText}=();
+  $bsize=0;
+  $wsize=0;
+  $done=0;
+  open(TEXT,$inPath)||die "Cannot open $inPath\n";
+  if($type=~/^SEE$/oi) {
+    while(defined($line=<TEXT>)) { # SEE abstract format
+      if($line=~/^<a (size=\"[0-9]+\" )?name=\"[0-9]+\">\[([0-9]+)\]<\/a>\s+<a href=\"\#[0-9]+\" id=[0-9]+>([^<]+)/o) {
+	$text=$3;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^ISI$/oi) { # ISI standard sentence by sentence format
+    while(defined($line=<TEXT>)) {
+      if($line=~/^<S SNTNO=\"[0-9a-z,]+\">([^<]+)<\/S>/o) {
+	$text=$1;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  elsif($type=~/^SPL$/oi) { # SPL one Sentence Per Line format
+    while(defined($line=<TEXT>)) {
+      chomp($line);
+      $line=~s/^\s+//;
+      $line=~s/\s+$//;
+      if(defined($line)&&length($line)>0) {
+	$text=$line;
+	$text=~tr/A-Z/a-z/;
+	&checkSummarySize_LCS($tokenizedText,\$text,\$wsize,\$bsize,\$done,$lengthLimit,$byteLimit);
+      }
+    }
+  }
+  else {
+    close(TEXT);
+    die "Unknown input format: $type\n";
+  }
+  close(TEXT);
+  if(defined(@{$tokenizedText}>0)) {
+    for($t=0;$t<@{$tokenizedText};$t++) {
+      $tokenizedText->[$t]=~s/\-/ \- /g;
+      $tokenizedText->[$t]=~s/[^A-Za-z0-9\-]/ /g;
+      $tokenizedText->[$t]=~s/^\s+//;
+      $tokenizedText->[$t]=~s/\s+$//;
+      $tokenizedText->[$t]=~s/\s+/ /g;
+    }
+  }
+  else {
+    print STDERR "readText_LCS: $inPath -> empty text\n";
+  }
+}
+
+sub checkSummarySize_LCS {
+  my $tokenizedText=shift;
+  my $text=shift;
+  my $wsize=shift;
+  my $bsize=shift;
+  my $done=shift;
+  my $lenghtLimit=shift;
+  my $byteLimit=shift;
+  my (@words);
+  
+  @words=split(/\s+/,$$text);
+  if(($lengthLimit==0&&$byteLimit==0)||
+     ($lengthLimit!=0&&(scalar @words)+$$wsize<=$lengthLimit)||
+     ($byteLimit!=0&&length($$text)+$$bsize<=$byteLimit)) {
+    push(@{$tokenizedText},$$text);
+    $$bsize+=length($$text);
+    $$wsize+=(scalar @words);
+  }
+  elsif($lengthLimit!=0&&(scalar @words)+$$wsize>$lengthLimit) {
+    if($$done==0) {
+      push(@{$tokenizedText},$$text);
+      $$done=1;
+    }
+  }
+  elsif($byteLimit!=0&&length($$text)+$$bsize>$byteLimit) {
+    if($$done==0) {
+      push(@{$tokenizedText},$$text);
+      $$done=1;
+    }
+  }
+}
+
+sub ngramScore {
+  my $model_grams=shift;
+  my $peer_grams=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$model_grams);
+  foreach $t (@tokens) {
+	  if($t ne "_cn_") {
+		  my $h;
+		  $h=0;
+		  if(exists($peer_grams->{$t})) {
+#MODIFIED 2008-06-05 favre@icsi.berkeley.edu
+			#$h=$peer_grams->{$t}<=$model_grams->{$t}?  $peer_grams->{$t}:$model_grams->{$t}; # clip
+			$h += $model_grams->{$t};
+#END MODIFIED
+			$$hit+=$h;
+		  }
+	  }
+  }
+  if($model_grams->{"_cn_"}!=0) {
+	  $$score=sprintf("%07.5f",$$hit/$model_grams->{"_cn_"});
+  }
+  else {
+# no instance of n-gram at this length
+	  $$score=0;
+#	die "model n-grams has zero instance\n";
+  }
+}
+
+sub skipBigramScore {
+  my $model_grams=shift;
+  my $peer_grams=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$model_grams);
+  foreach $t (@tokens) {
+    if($t ne "_cn_") {
+      my $h;
+      $h=0;
+      if(exists($peer_grams->{$t})) {
+	$h=$peer_grams->{$t}<=$model_grams->{$t}?
+	  $peer_grams->{$t}:$model_grams->{$t}; # clip
+	$$hit+=$h;
+      }
+    }
+  }
+  if($model_grams->{"_cn_"}!=0) {
+    $$score=sprintf("%07.5f",$$hit/$model_grams->{"_cn_"});
+  }
+  else {
+    # no instance of n-gram at this length
+    $$score=0;
+    #	die "model n-grams has zero instance\n";
+  }
+}
+
+sub lcs {
+  my $model=shift;
+  my $peer=shift;
+  my $hit=shift;
+  my $score=shift;
+  my $base=shift;
+  my $model_1grams=shift;
+  my $peer_1grams=shift;
+  my ($i,$j,@hitMask,@LCS);
+  
+  $$hit=0;
+  $$base=0;
+  # compute LCS length for each model/peer pair
+  for($i=0;$i<@{$model};$i++) {
+    # use @hitMask to make sure multiple peer hit won't be counted as multiple hits
+    @hitMask=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      push(@hitMask,0); # initialize hit mask
+    }
+    $$base+=scalar @{$model->[$i]}; # add model length
+    for($j=0;$j<@{$peer};$j++) {
+      &lcs_inner($model->[$i],$peer->[$j],\@hitMask);
+    }
+    @LCS=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      if($hitMask[$j]==1) {
+	if(exists($model_1grams->{$model->[$i][$j]})&&
+	   exists($peer_1grams->{$model->[$i][$j]})&&
+	   $model_1grams->{$model->[$i][$j]}>0&&
+	   $peer_1grams->{$model->[$i][$j]}>0) {
+	  $$hit++;
+	  #---------------------------------------------
+	  # bookkeeping to clip over counting
+	  # everytime a hit is found it is deducted
+	  # from both model and peer unigram count
+	  # if a unigram count already involve in
+	  # one LCS match then it will not be counted
+	  # if it match another token in the model
+	  # unit. This will make sure LCS score
+	  # is always lower than unigram score
+	  $model_1grams->{$model->[$i][$j]}--;
+	  $peer_1grams->{$model->[$i][$j]}--;
+	  push(@LCS,$model->[$i][$j]);
+	}
+      }
+    }
+    if($debug) {
+      print "LCS: ";
+      if(@LCS) {
+	print join(" ",@LCS),"\n";
+      }
+      else {
+	print "-\n";
+      }
+    }
+  }
+  if($$base>0) {
+    $$score=$$hit/$$base;
+  }
+  else {
+    $$score=0;
+  }
+}
+
+sub lcs_inner {
+  my $model=shift;
+  my $peer=shift;
+  my $hitMask=shift;
+  my $m=scalar @$model; # length of model
+  my $n=scalar @$peer; # length of peer
+  my ($i,$j);
+  my (@c,@b);
+  
+  if(@{$model}==0) {
+    return;
+  }
+  @c=();
+  @b=();
+  # initialize boundary condition and
+  # the DP array
+  for($i=0;$i<=$m;$i++) {
+    push(@c,[]);
+    push(@b,[]);
+    for($j=0;$j<=$n;$j++) {
+      push(@{$c[$i]},0);
+      push(@{$b[$i]},0);
+    }
+  }
+  for($i=1;$i<=$m;$i++) {
+    for($j=1;$j<=$n;$j++) {
+      if($model->[$i-1] eq $peer->[$j-1]) {
+	# recursively solve the i-1 subproblem
+	$c[$i][$j]=$c[$i-1][$j-1]+1;
+	$b[$i][$j]="\\"; # go diagonal
+      }
+      elsif($c[$i-1][$j]>=$c[$i][$j-1]) {
+	$c[$i][$j]=$c[$i-1][$j];
+	$b[$i][$j]="^"; # go up
+      }
+      else {
+	$c[$i][$j]=$c[$i][$j-1];
+	$b[$i][$j]="<"; # go left
+      }
+    }
+  }
+  &markLCS($hitMask,\@b,$m,$n);
+}
+
+sub wlcs {
+  my $model=shift;
+  my $peer=shift;
+  my $hit=shift;
+  my $score=shift;
+  my $base=shift;
+  my $weightFactor=shift;
+  my $model_1grams=shift;
+  my $peer_1grams=shift;
+  my ($i,$j,@hitMask,@LCS,$hitLen);
+  
+  $$hit=0;
+  $$base=0;
+  # compute LCS length for each model/peer pair
+  for($i=0;$i<@{$model};$i++) {
+    # use @hitMask to make sure multiple peer hit won't be counted as multiple hits
+    @hitMask=();
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      push(@hitMask,0); # initialize hit mask
+    }
+    $$base+=&wlcsWeight(scalar @{$model->[$i]},$weightFactor); # add model length
+    for($j=0;$j<@{$peer};$j++) {
+      &wlcs_inner($model->[$i],$peer->[$j],\@hitMask,$weightFactor);
+    }
+    @LCS=();
+    $hitLen=0;
+    for($j=0;$j<@{$model->[$i]};$j++) {
+      if($hitMask[$j]==1) {
+	if(exists($model_1grams->{$model->[$i][$j]})&&
+	   exists($peer_1grams->{$model->[$i][$j]})&&
+	   $model_1grams->{$model->[$i][$j]}>0&&
+	   $peer_1grams->{$model->[$i][$j]}>0) {
+	  $hitLen++;
+	  if($j+1<@{$model->[$i]}&&$hitMask[$j+1]==0) {
+	    $$hit+=&wlcsWeight($hitLen,$weightFactor);
+	    $hitLen=0; # reset hit length
+	  }
+	  elsif($j+1==@{$model->[$i]}) {
+	    # end of sentence
+	    $$hit+=&wlcsWeight($hitLen,$weightFactor);
+	    $hitLen=0; # reset hit length
+	  }
+	  #---------------------------------------------
+	  # bookkeeping to clip over counting
+	  # everytime a hit is found it is deducted
+	  # from both model and peer unigram count
+	  # if a unigram count already involve in
+	  # one LCS match then it will not be counted
+	  # if it match another token in the model
+	  # unit. This will make sure LCS score
+	  # is always lower than unigram score
+	  $model_1grams->{$model->[$i][$j]}--;
+	  $peer_1grams->{$model->[$i][$j]}--;
+	  push(@LCS,$model->[$i][$j]);
+	}
+      }
+    }
+    if($debug) {
+      print "ROUGE-W: ";
+      if(@LCS) {
+	print join(" ",@LCS),"\n";
+      }
+      else {
+	print "-\n";
+      }
+    }
+  }
+  $$score=wlcsWeightInverse($$hit/$$base,$weightFactor);
+}
+
+sub wlcsWeight {
+  my $r=shift;
+  my $power=shift;
+  
+  return $r**$power;
+}
+
+sub wlcsWeightInverse {
+  my $r=shift;
+  my $power=shift;
+  
+  return $r**(1/$power);
+}
+
+sub wlcs_inner {
+  my $model=shift;
+  my $peer=shift;
+  my $hitMask=shift;
+  my $weightFactor=shift;
+  my $m=scalar @$model; # length of model
+  my $n=scalar @$peer; # length of peer
+  my ($i,$j);
+  my (@c,@b,@l);
+  
+  if(@{$model}==0) {
+    return;
+  }
+  @c=();
+  @b=();
+  @l=(); # the length of consecutive matches so far
+  # initialize boundary condition and
+  # the DP array
+  for($i=0;$i<=$m;$i++) {
+    push(@c,[]);
+    push(@b,[]);
+    push(@l,[]);
+    for($j=0;$j<=$n;$j++) {
+      push(@{$c[$i]},0);
+      push(@{$b[$i]},0);
+      push(@{$l[$i]},0);
+    }
+  }
+  for($i=1;$i<=$m;$i++) {
+    for($j=1;$j<=$n;$j++) {
+      if($model->[$i-1] eq $peer->[$j-1]) {
+	# recursively solve the i-1 subproblem
+	$k=$l[$i-1][$j-1];
+	$c[$i][$j]=$c[$i-1][$j-1]+&wlcsWeight($k+1,$weightFactor)-&wlcsWeight($k,$weightFactor);
+	$b[$i][$j]="\\"; # go diagonal
+	$l[$i][$j]=$k+1; # extend the consecutive matching sequence
+      }
+      elsif($c[$i-1][$j]>=$c[$i][$j-1]) {
+	$c[$i][$j]=$c[$i-1][$j];
+	$b[$i][$j]="^"; # go up
+	$l[$i][$j]=0; # no match at this position
+      }
+      else {
+	$c[$i][$j]=$c[$i][$j-1];
+	$b[$i][$j]="<"; # go left
+	$l[$i][$j]=0; # no match at this position
+      }
+    }
+  }
+  &markLCS($hitMask,\@b,$m,$n);
+}
+
+sub markLCS {
+  my $hitMask=shift;
+  my $b=shift;
+  my $i=shift;
+  my $j=shift;
+  
+  while($i!=0&&$j!=0) {
+    if($b->[$i][$j] eq "\\") {
+      $i--;
+      $j--;
+      $hitMask->[$i]=1; # mark current model position as a hit
+    }
+    elsif($b->[$i][$j] eq "^") {
+      $i--;
+    }
+    elsif($b->[$i][$j] eq "<") {
+      $j--;
+    }
+    else {
+      die "Illegal move in markLCS: ($i,$j): \"$b->[$i][$j]\".\n";
+    }
+  }
+}
+
+# currently only support simple lexical matching
+sub getBEScore {
+  my $modelBEs=shift;
+  my $peerBEs=shift;
+  my $hit=shift;
+  my $score=shift;
+  my ($s,$t,@tokens);
+  
+  $$hit=0;
+  @tokens=keys (%$modelBEs);
+  foreach $t (@tokens) {
+    if($t ne "_cn_") {
+      my $h;
+      $h=0;
+      if(exists($peerBEs->{$t})) {
+	$h=$peerBEs->{$t}<=$modelBEs->{$t}?
+	  $peerBEs->{$t}:$modelBEs->{$t}; # clip
+	$$hit+=$h;
+	if(defined($opt_v)) {
+	  print "* Match: $t\n";
+	}
+      }
+    }
+  }
+  if($modelBEs->{"_cn_"}!=0) {
+    $$score=sprintf("%07.5f",$$hit/$modelBEs->{"_cn_"});
+  }
+  else {
+    # no instance of BE at this length
+    $$score=0;
+    #	die "model BE has zero instance\n";
+  }
+}
+
+sub MorphStem {
+  my $token=shift;
+  my ($os,$ltoken);
+  
+  if(!defined($token)||length($token)==0) {
+    return undef;
+  }
+  
+  $ltoken=$token;
+  $ltoken=~tr/A-Z/a-z/;
+  if(exists($exceptiondb{$ltoken})) {
+    return $exceptiondb{$ltoken};
+  }
+  $os=$ltoken;
+  return stem($os);
+}
+
+sub createNGram {
+  my $text=shift;
+  my $g=shift;
+  my $NSIZE=shift;
+####### modified by Benoit Favre
+	$createNGram_signature = "$text $NSIZE";
+	if(exists $createNGram_cache{$createNGram_signature}) {
+		%{$g} = %{$createNGram_cache{$createNGram_signature}};
+		return;
+	}
+####### end of modification
+  my @mx_tokens=();
+  my @m_tokens=();
+  my ($i,$j);
+  my ($gram);
+  my ($count);
+  my ($byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    $g->{"_cn_"}=0;
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  for($i=0;$i<=$#mx_tokens;$i++) {
+#MODIF 2008-06-05 favre@icsi.berkeley.edu
+	if($mx_tokens[$i] eq "|") {
+		push @m_tokens, "|";
+		next;
+	}
+#END MODIF
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@m_tokens,&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@m_tokens,$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@m_tokens,$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+  #-------------------------------------
+  # create ngram
+  $count=0;
+  for($i=0;$i<=$#m_tokens-$NSIZE+1;$i++) {
+    $gram=$m_tokens[$i];
+    for($j=$i+1;$j<=$i+$NSIZE-1;$j++) {
+      $gram.=" $m_tokens[$j]";
+    }
+	$gram =~ /\|/ and next;
+    $count++;
+    unless(exists($g->{$gram})) {
+      $g->{$gram}=1;
+    }
+    else {
+      $g->{$gram}++;
+    }
+  }
+  # save total number of tokens
+  $g->{"_cn_"}=$count;
+####### modified by Benoit Favre
+	$createNGram_cache{$createNGram_signature} = {%$g};
+####### end of modification
+}
+
+sub createSkipBigram {
+  my $text=shift;
+  my $g=shift;
+  my $skipDistance=shift;
+####### modified by Benoit Favre
+	my $createSkipBigram_signature = "$text $skipDistance";
+	if(exists $createSkipBigram_cache{$createSkipBigram_signature}) {
+		%{$g} = %{$createSkipBigram_cache{$createSkipBigram_signature}};
+		return;
+	}
+####### end of modification
+  my @mx_tokens=();
+  my @m_tokens=();
+  my ($i,$j);
+  my ($gram);
+  my ($count);
+  my ($byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    $g->{"_cn_"}=0;
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  for($i=0;$i<=$#mx_tokens;$i++) {
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@m_tokens,&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@m_tokens,$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@m_tokens,$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+  #-------------------------------------
+  # create ngram
+  $count=0;
+  for($i=0;$i<$#m_tokens;$i++) {
+    if(defined($opt_u)) {
+      # add unigram count
+      $gram=$m_tokens[$i];
+      $count++;
+      unless(exists($g->{$gram})) {
+	$g->{$gram}=1;
+      }
+      else {
+	$g->{$gram}++;
+      }
+    }
+    for($j=$i+1;
+	$j<=$#m_tokens&&($skipDistance<0||$j<=$i+$skipDistance+1);
+	$j++) {
+      $gram=$m_tokens[$i];
+      $gram.=" $m_tokens[$j]";
+      $count++;
+      unless(exists($g->{$gram})) {
+	$g->{$gram}=1;
+      }
+      else {
+	$g->{$gram}++;
+      }
+    }
+  }
+  # save total number of tokens
+  $g->{"_cn_"}=$count;
+####### modified by Benoit Favre
+	$createSkipBigram_cache{$createSkipBigram_signature} = {%$g};
+####### end of modification
+}
+
+sub createBE {
+  my $BEList=shift;
+  my $BEMap=shift;
+  my $BEMode=shift;
+  my ($i);
+  
+  $BEMap->{"_cn_"}=0;
+  unless(scalar @{$BEList} > 0) {
+    return;
+  }
+  for($i=0;$i<=$#{$BEList};$i++) {
+    my (@fds);
+    my ($be,$stemH,$stemM);
+    $be=$BEList->[$i];
+    $be=~tr/A-Z/a-z/;
+    @fds=split(/\|/,$be);
+    if(@fds!=3) {
+      print STDERR "Basic Element (BE) input file is invalid: *$be*\n";
+      print STDERR "A BE file has to be in this format per line: HEAD|MODIFIER|RELATION\n";
+      die "For more infomation about BE, go to: http://www.isi.edu/~cyl/BE\n";
+    }
+    $stemH=$fds[0];
+    $stemM=$fds[1];
+    if(defined($opt_m)) {
+      # use stemmer
+      # only consider words starting with these characters
+      # use Porter stemmer
+      if(length($stemH)>3) {
+	$stemH=&MorphStemMulti($stemH);
+      }
+      if($stemM ne "NIL"&&
+	 length($stemM)>3) {
+	$stemM=&MorphStemMulti($stemM);
+      }
+    }
+    if($BEMode eq "H"&&
+      $stemM eq "nil") {
+      unless(exists($BEMap->{$stemH})) {
+	$BEMap->{$stemH}=0;
+      }
+      $BEMap->{$stemH}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HM"&&
+	  $stemM ne "nil") {
+      my $pair="$stemH|$stemM";
+      unless(exists($BEMap->{$pair})) {
+	$BEMap->{$pair}=0;
+      }
+      $BEMap->{$pair}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR"&&
+	  $fds[2] ne "nil") {
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HM1") {
+      my $pair="$stemH|$stemM";
+      unless(exists($BEMap->{$pair})) {
+	$BEMap->{$pair}=0;
+      }
+      $BEMap->{$pair}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR1"&&
+	  $fds[1] ne "nil") { 
+      # relation can be "NIL" but modifier has to have value
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+    elsif($BEMode eq "HMR2") {
+      # modifier and relation can be "NIL"
+      my $triple="$stemH|$stemM|$fds[2]";
+      unless(exists($BEMap->{$triple})) {
+	$BEMap->{$triple}=0;
+      }
+      $BEMap->{$triple}++;
+      $BEMap->{"_cn_"}++;
+    }
+  }
+}
+
+sub MorphStemMulti {
+  my $string=shift;
+  my (@tokens,@stems,$t,$i);
+  
+  @tokens=split(/\s+/,$string);
+  foreach $t (@tokens) {
+    if($t=~/[A-Za-z0-9]/o&&
+       $t!~/(-LRB-|-RRB-|-LSB-|-RSB-|-LCB-|-RCB-)/o) {
+      my $s;
+      if(defined($s=&MorphStem($t))) {
+	$t=$s;
+      }
+      push(@stems,$t);
+    }
+    else {
+      push(@stems,$t);
+    }
+  }
+  return join(" ",@stems);
+}
+
+sub tokenizeText {
+  my $text=shift;
+  my $tokenizedText=shift;
+  my @mx_tokens=();
+  my ($i,$byteSize);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  unless(defined($text)) {
+    return;
+  }
+  @mx_tokens=split(/\s+/,$text);
+  $byteSize=0;
+  @{$tokenizedText}=();
+  for($i=0;$i<=$#mx_tokens;$i++) {
+    unless(exists($stopwords{$mx_tokens[$i]})) {
+      $byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+      if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	if(defined($opt_m)) {
+	  # use stemmer
+	  # only consider words starting with these characters
+	  # use Porter stemmer
+	  my $stem;
+	  $stem=$mx_tokens[$i];
+	  if(length($stem)>3) {
+	    push(@{$tokenizedText},&MorphStem($stem));
+	  }
+	  else { # no stemmer as default
+	    push(@{$tokenizedText},$mx_tokens[$i]);
+	  }
+	}
+	else { # no stemmer
+	  push(@{$tokenizedText},$mx_tokens[$i]);
+	}
+      }
+    }
+  }
+}
+
+sub tokenizeText_LCS {
+  my $text=shift;
+  my $tokenizedText=shift;
+  my $lengthLimit=shift;
+  my $byteLimit=shift;
+  my @mx_tokens=();
+  my ($i,$byteSize,$t,$done);
+  
+  # remove stopwords
+  if($useStopwords) {
+    %stopwords=(); # consider stop words
+  }
+  if(@{$text}==0) {
+    return;
+  }
+  $byteSize=0;
+  @{$tokenizedText}=();
+  $done=0;
+  for($t=0;$t<@{$text}&&$done==0;$t++) {
+    @mx_tokens=split(/\s+/,$text->[$t]);
+    # tokenized array for each separate unit (for example, sentence)
+    push(@{$tokenizedText},[]);
+    for($i=0;$i<=$#mx_tokens;$i++) {
+      unless(exists($stopwords{$mx_tokens[$i]})) {
+	$byteSize+=length($mx_tokens[$i])+1; # the length of words in bytes so far + 1 space 
+	if($mx_tokens[$i]=~/^[a-z0-9\$]/o) {
+	  if(defined($opt_m)) {
+	    # use stemmer
+	    # only consider words starting with these characters
+	    # use Porter stemmer
+	    my $stem;
+	    $stem=$mx_tokens[$i];
+	    if(length($stem)>3) {
+	      push(@{$tokenizedText->[$t]},&MorphStem($stem));
+	    }
+	    else { # no stemmer as default
+	      push(@{$tokenizedText->[$t]},$mx_tokens[$i]);
+	    }
+	  }
+	  else { # no stemmer
+	    push(@{$tokenizedText->[$t]},$mx_tokens[$i]);
+	  }
+	}
+      }
+    }
+  }
+}
+
+# Input file configuration is a list of peer/model pair for each evaluation
+# instance. Each evaluation pair is in a line separated by white spaces
+# characters.
+sub readFileList {
+  my ($ROUGEEvals)=shift;
+  my ($ROUGEEvalIDs)=shift;
+  my ($ROUGEPeerIDTable)=shift;
+  my ($doc)=shift;
+  my ($evalID,$pair);
+  my ($inputFormat,$peerFile,$modelFile,$peerID,$modelID);
+  my (@files);
+
+  $evalID=1;  # automatically generated evaluation ID starting from 1
+  $peerID=$systemID;
+  $modelID="M";
+  unless(exists($ROUGEPeerIDTable->{$peerID})) {
+    $ROUGEPeerIDTable->{$peerID}=1;
+  }
+  while(defined($pair=<$doc>)) {
+    my ($peerPath,$modelPath);
+    if($pair!~/^\#/o&&
+       $pair!~/^\s*$/o) { # Lines start with '#' is a comment line
+      chomp($pair);
+      $pair=~s/^\s+//;
+      $pair=~s/\s+$//;
+      @files=split(/\s+/,$pair);
+      if(scalar @files < 2) {
+	die "File list has to have at least 2 filenames per line (peer model1 model2 ... modelN)\n";
+      }
+      $peerFile=$files[0];
+      unless(exists($ROUGEEvals->{$evalID})) {
+	$ROUGEEvals->{$evalID}={};
+	push(@{$ROUGEEvalIDs},$evalID);
+	$ROUGEEvals->{$evalID}{"IF"}=$opt_z;
+      }
+      unless(exists($ROUGEPeerIDTable->{$peerID})) {
+	$ROUGEPeerIDTable->{$peerID}=1; # save peer ID for reference
+      }
+      if(exists($ROUGEEvals->{$evalID})) {
+	unless(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+	  $ROUGEEvals->{$evalID}{"Ps"}={};
+	  $ROUGEEvals->{$evalID}{"PIDList"}=[];
+	}
+	push(@{$ROUGEEvals->{$evalID}{"PIDList"}},$peerID); # save peer IDs
+      }
+      else {
+	die "(PEERS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+      }
+      # remove leading and trailing newlines and
+      # spaces
+      if(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+	$ROUGEEvals->{$evalID}{"Ps"}{$peerID}=$peerFile; # save peer filename
+      }
+      else {
+	die "(P) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+      }
+      for($mid=1;$mid<=$#files;$mid++) {
+	$modelFile=$files[$mid];
+	if(exists($ROUGEEvals->{$evalID})) {
+	  unless(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+	    $ROUGEEvals->{$evalID}{"Ms"}={};
+	    $ROUGEEvals->{$evalID}{"MIDList"}=[];
+	  }
+	  push(@{$ROUGEEvals->{$evalID}{"MIDList"}},"$modelID.$mid"); # save model IDs
+	}
+	else {
+	  die "(MODELS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	}
+	# remove leading and trailing newlines and
+	# spaces
+	if(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+	  $ROUGEEvals->{$evalID}{"Ms"}{"$modelID.$mid"}=$modelFile; # save peer filename
+	}
+	else {
+	  die "(M) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	}
+      }
+      $evalID++;
+    }
+  }
+}
+
+# read and parse ROUGE evaluation file
+sub readEvals {
+  my ($ROUGEEvals)=shift;
+  my ($ROUGEEvalIDs)=shift;
+  my ($ROUGEPeerIDTable)=shift;
+  my ($node)=shift;
+  my ($evalID)=shift;
+  my ($inputFormat,$peerRoot,$modelRoot,$peerFile,$modelFile,$peerID,$modelID);
+  
+  if(defined($opt_z)) {
+    # Input file configuration is a list of peer/model pair for each evaluation
+    # instance. Each evaluation pair is in a line separated by white spaces
+    # characters.
+    &readFileList($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$node);
+    return;
+  }
+  # Otherwise, the input file is the standard ROUGE XML evaluation configuration
+  # file.
+  if($node->getNodeType==ELEMENT_NODE||
+     $node->getNodeType==DOCUMENT_NODE) {
+    if($node->getNodeType==ELEMENT_NODE) {
+      $nodeName=$node->getNodeName;
+      if($nodeName=~/^EVAL$/oi) {
+	$evalID=$node->getAttributeNode("ID")->getValue;
+	unless(exists($ROUGEEvals->{$evalID})) {
+	  $ROUGEEvals->{$evalID}={};
+	  push(@{$ROUGEEvalIDs},$evalID);
+	}
+	foreach my $child ($node->getChildNodes()) {
+	  &readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+	}
+      }
+      elsif($nodeName=~/^INPUT-FORMAT$/oi) {
+	$inputFormat=$node->getAttributeNode("TYPE")->getValue;
+	if($inputFormat=~/^(SEE|ISI|SPL|SIMPLE)$/oi) { # SPL: one sentence per line
+	  if(exists($ROUGEEvals->{$evalID})) {
+	    $ROUGEEvals->{$evalID}{"IF"}=$inputFormat;
+	  }
+	  else {
+	    die "(INPUT-FORMAT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	  }
+	}
+	else {
+	  die "Unknown input type: $inputFormat\n";
+	}
+      }
+      elsif($nodeName=~/^PEER-ROOT$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==TEXT_NODE) {
+	    $peerRoot=$child->getData;
+	    # remove leading and trailing newlines and
+	    # spaces
+	    $peerRoot=~s/^[\n\s]+//;
+	    $peerRoot=~s/[\n\s]+$//;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      $ROUGEEvals->{$evalID}{"PR"}=$peerRoot;
+	    }
+	    else {
+	      die "(PEER-ROOT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^MODEL-ROOT$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==TEXT_NODE) {
+	    $modelRoot=$child->getData;
+	    # remove leading and trailing newlines and
+	    # spaces
+	    $modelRoot=~s/^[\n\s]+//;
+	    $modelRoot=~s/[\n\s]+$//;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      $ROUGEEvals->{$evalID}{"MR"}=$modelRoot;
+	    }
+	    else {
+	      die "(MODEL-ROOT) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^PEERS$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==ELEMENT_NODE&&
+	     $child->getNodeName=~/^P$/oi) {
+	    $peerID=$child->getAttributeNode("ID")->getValue;
+	    unless(exists($ROUGEPeerIDTable->{$peerID})) {
+	      $ROUGEPeerIDTable->{$peerID}=1; # save peer ID for reference
+	    }
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      unless(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+		$ROUGEEvals->{$evalID}{"Ps"}={};
+		$ROUGEEvals->{$evalID}{"PIDList"}=[];
+	      }
+	      push(@{$ROUGEEvals->{$evalID}{"PIDList"}},$peerID); # save peer IDs
+	    }
+	    else {
+	      die "(PEERS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	    foreach my $grandchild ($child->getChildNodes()) {
+	      if($grandchild->getNodeType==TEXT_NODE) {
+		$peerFile=$grandchild->getData;
+		# remove leading and trailing newlines and
+		# spaces
+		$peerFile=~s/^[\n\s]+//;
+		$peerFile=~s/[\n\s]+$//;
+		if(exists($ROUGEEvals->{$evalID}{"Ps"})) {
+		  $ROUGEEvals->{$evalID}{"Ps"}{$peerID}=$peerFile; # save peer filename
+		}
+		else {
+		  die "(P) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+		}
+	      }
+	    }
+	  }
+	}
+      }
+      elsif($nodeName=~/^MODELS$/oi) {
+	foreach my $child ($node->getChildNodes()) {
+	  if($child->getNodeType==ELEMENT_NODE&&
+	     $child->getNodeName=~/^M$/oi) {
+	    $modelID=$child->getAttributeNode("ID")->getValue;
+	    if(exists($ROUGEEvals->{$evalID})) {
+	      unless(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+		$ROUGEEvals->{$evalID}{"Ms"}={};
+		$ROUGEEvals->{$evalID}{"MIDList"}=[];
+	      }
+	      push(@{$ROUGEEvals->{$evalID}{"MIDList"}},$modelID); # save model IDs
+	    }
+	    else {
+	      die "(MODELS) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+	    }
+	    foreach my $grandchild ($child->getChildNodes()) {
+	      if($grandchild->getNodeType==TEXT_NODE) {
+		$modelFile=$grandchild->getData;
+		# remove leading and trailing newlines and
+		# spaces
+		$modelFile=~s/^[\n\s]+//;
+		$modelFile=~s/[\n\s]+$//;
+		if(exists($ROUGEEvals->{$evalID}{"Ms"})) {
+		  $ROUGEEvals->{$evalID}{"Ms"}{$modelID}=$modelFile; # save peer filename
+		}
+		else {
+		  die "(M) Evaluation database does not contain entry for this evaluation ID: $evalID\n";
+		}
+	      }
+	    }
+	  }
+	}
+      }
+      else {
+	foreach my $child ($node->getChildNodes()) {
+	  &readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+	}
+      }
+    }
+    else {
+      foreach my $child ($node->getChildNodes()) {
+	&readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+      }
+    }
+  }
+  else {
+    if(defined($node->getChildNodes())) {
+      foreach my $child ($node->getChildNodes()) {
+	&readEvals($ROUGEEvals,$ROUGEEvalIDs,$ROUGEPeerIDTable,$child,$evalID);
+      }
+    }
+  }
+}
+
+# Porter stemmer in Perl. Few comments, but it's easy to follow against the rules in the original
+# paper, in
+#
+#   Porter, 1980, An algorithm for suffix stripping, Program, Vol. 14,
+#   no. 3, pp 130-137,
+#
+# see also http://www.tartarus.org/~martin/PorterStemmer
+
+# Release 1
+
+local %step2list;
+local %step3list;
+local ($c, $v, $C, $V, $mgr0, $meq1, $mgr1, $_v);
+
+
+sub stem
+  {  my ($stem, $suffix, $firstch);
+     my $w = shift;
+     if (length($w) < 3) { return $w; } # length at least 3
+     # now map initial y to Y so that the patterns never treat it as vowel:
+     $w =~ /^./; $firstch = $&;
+     if ($firstch =~ /^y/) { $w = ucfirst $w; }
+     
+     # Step 1a
+     if ($w =~ /(ss|i)es$/) { $w=$`.$1; }
+     elsif ($w =~ /([^s])s$/) { $w=$`.$1; }
+     # Step 1b
+     if ($w =~ /eed$/) { if ($` =~ /$mgr0/o) { chop($w); } }
+     elsif ($w =~ /(ed|ing)$/)
+       {  $stem = $`;
+	  if ($stem =~ /$_v/o)
+	    {  $w = $stem;
+	       if ($w =~ /(at|bl|iz)$/) { $w .= "e"; }
+	       elsif ($w =~ /([^aeiouylsz])\1$/) { chop($w); }
+	       elsif ($w =~ /^${C}${v}[^aeiouwxy]$/o) { $w .= "e"; }
+   }
+}
+# Step 1c
+  if ($w =~ /y$/) { $stem = $`; if ($stem =~ /$_v/o) { $w = $stem."i"; } }
+
+# Step 2
+if ($w =~ /(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/)
+  { $stem = $`; $suffix = $1;
+    if ($stem =~ /$mgr0/o) { $w = $stem . $step2list{$suffix}; }
+  }
+
+# Step 3
+
+if ($w =~ /(icate|ative|alize|iciti|ical|ful|ness)$/)
+  { $stem = $`; $suffix = $1;
+    if ($stem =~ /$mgr0/o) { $w = $stem . $step3list{$suffix}; }
+  }
+
+# Step 4
+
+   # CYL: Modified 02/14/2004, a word ended in -ement will not try the rules "-ment" and "-ent"
+#   if ($w =~ /(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/)
+#   elsif ($w =~ /(s|t)(ion)$/)
+#   { $stem = $` . $1; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /(al|ance|ence|er|ic|able|ible|ant|ement|ou|ism|ate|iti|ous|ive|ize)$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /ment$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   if ($w =~ /ent$/)
+   { $stem = $`; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+   elsif ($w =~ /(s|t)(ion)$/)
+   { $stem = $` . $1; if ($stem =~ /$mgr1/o) { $w = $stem; } }
+
+#  Step 5
+
+if ($w =~ /e$/)
+  { $stem = $`;
+    if ($stem =~ /$mgr1/o or
+	($stem =~ /$meq1/o and not $stem =~ /^${C}${v}[^aeiouwxy]$/o))
+{ $w = $stem; }
+}
+if ($w =~ /ll$/ and $w =~ /$mgr1/o) { chop($w); }
+
+# and turn initial Y back to y
+if ($firstch =~ /^y/) { $w = lcfirst $w; }
+return $w;
+}
+
+  sub initialise {
+    
+    %step2list =
+      ( 'ational'=>'ate', 'tional'=>'tion', 'enci'=>'ence', 'anci'=>'ance', 'izer'=>'ize', 'bli'=>'ble',
+	'alli'=>'al', 'entli'=>'ent', 'eli'=>'e', 'ousli'=>'ous', 'ization'=>'ize', 'ation'=>'ate',
+	'ator'=>'ate', 'alism'=>'al', 'iveness'=>'ive', 'fulness'=>'ful', 'ousness'=>'ous', 'aliti'=>'al',
+	'iviti'=>'ive', 'biliti'=>'ble', 'logi'=>'log');
+    
+    %step3list =
+      ('icate'=>'ic', 'ative'=>'', 'alize'=>'al', 'iciti'=>'ic', 'ical'=>'ic', 'ful'=>'', 'ness'=>'');
+    
+    
+    $c =    "[^aeiou]";          # consonant
+    $v =    "[aeiouy]";          # vowel
+    $C =    "${c}[^aeiouy]*";    # consonant sequence
+    $V =    "${v}[aeiou]*";      # vowel sequence
+    
+    $mgr0 = "^(${C})?${V}${C}";               # [C]VC... is m>0
+    $meq1 = "^(${C})?${V}${C}(${V})?" . '$';  # [C]VC[V] is m=1
+   $mgr1 = "^(${C})?${V}${C}${V}${C}";       # [C]VCVC... is m>1
+   $_v   = "^(${C})?${v}";                   # vowel in stem
+
+}
+
diff -rupN RELEASE-1.5.5/XML/DOM.pm ROUGE-1.5.5/XML/DOM.pm
--- RELEASE-1.5.5/XML/DOM.pm	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/XML/DOM.pm	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,5128 @@
+################################################################################
+#
+# Perl module: XML::DOM
+#
+# By Enno Derksen
+#
+################################################################################
+#
+# To do:
+#
+# * optimize Attr if it only contains 1 Text node to hold the value
+# * fix setDocType!
+#
+# * BUG: setOwnerDocument - does not process default attr values correctly,
+#   they still point to the old doc.
+# * change Exception mechanism
+# * maybe: more checking of sysId etc.
+# * NoExpand mode (don't know what else is useful)
+# * various odds and ends: see comments starting with "??"
+# * normalize(1) could also expand CDataSections and EntityReferences
+# * parse a DocumentFragment?
+# * encoding support
+#
+######################################################################
+
+######################################################################
+package XML::DOM;
+######################################################################
+
+use strict;
+
+use vars qw( $VERSION @ISA @EXPORT
+	     $IgnoreReadOnly $SafeMode $TagStyle
+	     %DefaultEntities %DecodeDefaultEntity
+	   );
+use Carp;
+use XML::RegExp;
+
+BEGIN
+{
+    require XML::Parser;
+    $VERSION = '1.44';
+
+    my $needVersion = '2.28';
+    die "need at least XML::Parser version $needVersion (current=${XML::Parser::VERSION})"
+	unless $XML::Parser::VERSION >= $needVersion;
+
+    @ISA = qw( Exporter );
+
+    # Constants for XML::DOM Node types
+    @EXPORT = qw(
+	     UNKNOWN_NODE
+	     ELEMENT_NODE
+	     ATTRIBUTE_NODE
+	     TEXT_NODE
+	     CDATA_SECTION_NODE
+	     ENTITY_REFERENCE_NODE
+	     ENTITY_NODE
+	     PROCESSING_INSTRUCTION_NODE
+	     COMMENT_NODE
+	     DOCUMENT_NODE
+	     DOCUMENT_TYPE_NODE
+	     DOCUMENT_FRAGMENT_NODE
+	     NOTATION_NODE
+	     ELEMENT_DECL_NODE
+	     ATT_DEF_NODE
+	     XML_DECL_NODE
+	     ATTLIST_DECL_NODE
+	    );
+}
+
+#---- Constant definitions
+
+# Node types
+
+sub UNKNOWN_NODE                () { 0 }		# not in the DOM Spec
+
+sub ELEMENT_NODE                () { 1 }
+sub ATTRIBUTE_NODE              () { 2 }
+sub TEXT_NODE                   () { 3 }
+sub CDATA_SECTION_NODE          () { 4 }
+sub ENTITY_REFERENCE_NODE       () { 5 }
+sub ENTITY_NODE                 () { 6 }
+sub PROCESSING_INSTRUCTION_NODE () { 7 }
+sub COMMENT_NODE                () { 8 }
+sub DOCUMENT_NODE               () { 9 }
+sub DOCUMENT_TYPE_NODE          () { 10}
+sub DOCUMENT_FRAGMENT_NODE      () { 11}
+sub NOTATION_NODE               () { 12}
+
+sub ELEMENT_DECL_NODE		() { 13 }	# not in the DOM Spec
+sub ATT_DEF_NODE 		() { 14 }	# not in the DOM Spec
+sub XML_DECL_NODE 		() { 15 }	# not in the DOM Spec
+sub ATTLIST_DECL_NODE		() { 16 }	# not in the DOM Spec
+
+%DefaultEntities = 
+(
+ "quot"		=> '"',
+ "gt"		=> ">",
+ "lt"		=> "<",
+ "apos"		=> "'",
+ "amp"		=> "&"
+);
+
+%DecodeDefaultEntity =
+(
+ '"' => "&quot;",
+ ">" => "&gt;",
+ "<" => "&lt;",
+ "'" => "&apos;",
+ "&" => "&amp;"
+);
+
+#
+# If you don't want DOM warnings to use 'warn', override this method like this:
+#
+# { # start block scope
+#	local *XML::DOM::warning = \&my_warn;
+#	... your code here ...
+# } # end block scope (old XML::DOM::warning takes effect again)
+#
+sub warning	# static
+{
+    warn @_;
+}
+
+#
+# This method defines several things in the caller's package, so you can use named constants to
+# access the array that holds the member data, i.e. $self->[_Data]. It assumes the caller's package
+# defines a class that is implemented as a blessed array reference.
+# Note that this is very similar to using 'use fields' and 'use base'.
+#
+# E.g. if $fields eq "Name Model", $parent eq "XML::DOM::Node" and
+# XML::DOM::Node had "A B C" as fields and it was called from package "XML::DOM::ElementDecl",
+# then this code would basically do the following:
+#
+# package XML::DOM::ElementDecl;
+#
+# sub _Name  () { 3 }	# Note that parent class had three fields
+# sub _Model () { 4 }
+#
+# # Maps constant names (without '_') to constant (int) value
+# %HFIELDS = ( %XML::DOM::Node::HFIELDS, Name => _Name, Model => _Model );
+#
+# # Define XML:DOM::ElementDecl as a subclass of XML::DOM::Node
+# @ISA = qw{ XML::DOM::Node };
+#
+# # The following function names can be exported into the user's namespace.
+# @EXPORT_OK = qw{ _Name _Model };
+#
+# # The following function names can be exported into the user's namespace
+# # with: import XML::DOM::ElementDecl qw( :Fields );
+# %EXPORT_TAGS = ( Fields => qw{ _Name _Model } );
+#
+sub def_fields	# static
+{
+    my ($fields, $parent) = @_;
+
+    my ($pkg) = caller;
+
+    no strict 'refs';
+
+    my @f = split (/\s+/, $fields);
+    my $n = 0;
+
+    my %hfields;
+    if (defined $parent)
+    {
+	my %pf = %{"$parent\::HFIELDS"};
+	%hfields = %pf;
+
+	$n = scalar (keys %pf);
+	@{"$pkg\::ISA"} = ( $parent );
+    }
+
+    my $i = $n;
+    for (@f)
+    {
+	eval "sub $pkg\::_$_ () { $i }";
+	$hfields{$_} = $i;
+	$i++;
+    }
+    %{"$pkg\::HFIELDS"} = %hfields;
+    @{"$pkg\::EXPORT_OK"} = map { "_$_" } @f;
+    
+    ${"$pkg\::EXPORT_TAGS"}{Fields} = [ map { "_$_" } @f ];
+}
+
+# sub blesh
+# {
+#     my $hashref = shift;
+#     my $class = shift;
+#     no strict 'refs';
+#     my $self = bless [\%{"$class\::FIELDS"}], $class;
+#     if (defined $hashref)
+#     {
+# 	for (keys %$hashref)
+# 	{
+# 	    $self->{$_} = $hashref->{$_};
+# 	}
+#     }
+#     $self;
+# }
+
+# sub blesh2
+# {
+#     my $hashref = shift;
+#     my $class = shift;
+#     no strict 'refs';
+#     my $self = bless [\%{"$class\::FIELDS"}], $class;
+#     if (defined $hashref)
+#     {
+# 	for (keys %$hashref)
+# 	{
+# 	    eval { $self->{$_} = $hashref->{$_}; };
+# 	    croak "ERROR in field [$_] $@" if $@;
+# 	}
+#     }
+#     $self;
+#}
+
+#
+# CDATA section may not contain "]]>"
+#
+sub encodeCDATA
+{
+    my ($str) = shift;
+    $str =~ s/]]>/]]&gt;/go;
+    $str;
+}
+
+#
+# PI may not contain "?>"
+#
+sub encodeProcessingInstruction
+{
+    my ($str) = shift;
+    $str =~ s/\?>/?&gt;/go;
+    $str;
+}
+
+#
+#?? Not sure if this is right - must prevent double minus somehow...
+#
+sub encodeComment
+{
+    my ($str) = shift;
+    return undef unless defined $str;
+
+    $str =~ s/--/&#45;&#45;/go;
+    $str;
+}
+
+#
+# For debugging
+#
+sub toHex
+{
+    my $str = shift;
+    my $len = length($str);
+    my @a = unpack ("C$len", $str);
+    my $s = "";
+    for (@a)
+    {
+	$s .= sprintf ("%02x", $_);
+    }
+    $s;
+}
+
+#
+# 2nd parameter $default: list of Default Entity characters that need to be 
+# converted (e.g. "&<" for conversion to "&amp;" and "&lt;" resp.)
+#
+sub encodeText
+{
+    my ($str, $default) = @_;
+    return undef unless defined $str;
+
+    if ($] >= 5.006) {
+      $str =~ s/([$default])|(]]>)/
+        defined ($1) ? $DecodeDefaultEntity{$1} : "]]&gt;" /egs;
+    }
+    else {
+      $str =~ s/([\xC0-\xDF].|[\xE0-\xEF]..|[\xF0-\xFF]...)|([$default])|(]]>)/
+        defined($1) ? XmlUtf8Decode ($1) :
+        defined ($2) ? $DecodeDefaultEntity{$2} : "]]&gt;" /egs;
+    }
+
+#?? could there be references that should not be expanded?
+# e.g. should not replace &#nn; &#xAF; and &abc;
+#    $str =~ s/&(?!($ReName|#[0-9]+|#x[0-9a-fA-F]+);)/&amp;/go;
+
+    $str;
+}
+
+#
+# Used by AttDef - default value
+#
+sub encodeAttrValue
+{
+    encodeText (shift, '"&<>');
+}
+
+#
+# Converts an integer (Unicode - ISO/IEC 10646) to a UTF-8 encoded character 
+# sequence.
+# Used when converting e.g. &#123; or &#x3ff; to a string value.
+#
+# Algorithm borrowed from expat/xmltok.c/XmlUtf8Encode()
+#
+# not checking for bad characters: < 0, x00-x08, x0B-x0C, x0E-x1F, xFFFE-xFFFF
+#
+sub XmlUtf8Encode
+{
+    my $n = shift;
+    if ($n < 0x80)
+    {
+	return chr ($n);
+    }
+    elsif ($n < 0x800)
+    {
+	return pack ("CC", (($n >> 6) | 0xc0), (($n & 0x3f) | 0x80));
+    }
+    elsif ($n < 0x10000)
+    {
+	return pack ("CCC", (($n >> 12) | 0xe0), ((($n >> 6) & 0x3f) | 0x80),
+		     (($n & 0x3f) | 0x80));
+    }
+    elsif ($n < 0x110000)
+    {
+	return pack ("CCCC", (($n >> 18) | 0xf0), ((($n >> 12) & 0x3f) | 0x80),
+		     ((($n >> 6) & 0x3f) | 0x80), (($n & 0x3f) | 0x80));
+    }
+    croak "number is too large for Unicode [$n] in &XmlUtf8Encode";
+}
+
+#
+# Opposite of XmlUtf8Decode plus it adds prefix "&#" or "&#x" and suffix ";"
+# The 2nd parameter ($hex) indicates whether the result is hex encoded or not.
+#
+sub XmlUtf8Decode
+{
+    my ($str, $hex) = @_;
+    my $len = length ($str);
+    my $n;
+
+    if ($len == 2)
+    {
+	my @n = unpack "C2", $str;
+	$n = (($n[0] & 0x3f) << 6) + ($n[1] & 0x3f);
+    }
+    elsif ($len == 3)
+    {
+	my @n = unpack "C3", $str;
+	$n = (($n[0] & 0x1f) << 12) + (($n[1] & 0x3f) << 6) + 
+		($n[2] & 0x3f);
+    }
+    elsif ($len == 4)
+    {
+	my @n = unpack "C4", $str;
+	$n = (($n[0] & 0x0f) << 18) + (($n[1] & 0x3f) << 12) + 
+		(($n[2] & 0x3f) << 6) + ($n[3] & 0x3f);
+    }
+    elsif ($len == 1)	# just to be complete...
+    {
+	$n = ord ($str);
+    }
+    else
+    {
+	croak "bad value [$str] for XmlUtf8Decode";
+    }
+    $hex ? sprintf ("&#x%x;", $n) : "&#$n;";
+}
+
+$IgnoreReadOnly = 0;
+$SafeMode = 1;
+
+sub getIgnoreReadOnly
+{
+    $IgnoreReadOnly;
+}
+
+#
+# The global flag $IgnoreReadOnly is set to the specified value and the old 
+# value of $IgnoreReadOnly is returned.
+#
+# To temporarily disable read-only related exceptions (i.e. when parsing
+# XML or temporarily), do the following:
+#
+# my $oldIgnore = XML::DOM::ignoreReadOnly (1);
+# ... do whatever you want ...
+# XML::DOM::ignoreReadOnly ($oldIgnore);
+#
+sub ignoreReadOnly
+{
+    my $i = $IgnoreReadOnly;
+    $IgnoreReadOnly = $_[0];
+    return $i;
+}
+
+#
+# XML spec seems to break its own rules... (see ENTITY xmlpio)
+#
+sub forgiving_isValidName
+{
+    use bytes;  # XML::RegExp expressed in terms encoded UTF8
+    $_[0] =~ /^$XML::RegExp::Name$/o;
+}
+
+#
+# Don't allow names starting with xml (either case)
+#
+sub picky_isValidName
+{
+    use bytes;  # XML::RegExp expressed in terms encoded UTF8
+    $_[0] =~ /^$XML::RegExp::Name$/o and $_[0] !~ /^xml/i;
+}
+
+# Be forgiving by default, 
+*isValidName = \&forgiving_isValidName;
+
+sub allowReservedNames		# static
+{
+    *isValidName = ($_[0] ? \&forgiving_isValidName : \&picky_isValidName);
+}
+
+sub getAllowReservedNames	# static
+{
+    *isValidName == \&forgiving_isValidName;
+}
+
+#
+# Always compress empty tags by default
+# This is used by Element::print.
+#
+$TagStyle = sub { 0 };
+
+sub setTagCompression
+{
+    $TagStyle = shift;
+}
+
+######################################################################
+package XML::DOM::PrintToFileHandle;
+######################################################################
+
+#
+# Used by XML::DOM::Node::printToFileHandle
+#
+
+sub new
+{
+    my($class, $fn) = @_;
+    bless $fn, $class;
+}
+
+sub print
+{
+    my ($self, $str) = @_;
+    print $self $str;
+}
+
+######################################################################
+package XML::DOM::PrintToString;
+######################################################################
+
+use vars qw{ $Singleton };
+
+#
+# Used by XML::DOM::Node::toString to concatenate strings
+#
+
+sub new
+{
+    my($class) = @_;
+    my $str = "";
+    bless \$str, $class;
+}
+
+sub print
+{
+    my ($self, $str) = @_;
+    $$self .= $str;
+}
+
+sub toString
+{
+    my $self = shift;
+    $$self;
+}
+
+sub reset
+{
+    ${$_[0]} = "";
+}
+
+$Singleton = new XML::DOM::PrintToString;
+
+######################################################################
+package XML::DOM::DOMImplementation;
+######################################################################
+ 
+$XML::DOM::DOMImplementation::Singleton =
+  bless \$XML::DOM::DOMImplementation::Singleton, 'XML::DOM::DOMImplementation';
+ 
+sub hasFeature 
+{
+    my ($self, $feature, $version) = @_;
+ 
+    uc($feature) eq 'XML' and ($version eq '1.0' || $version eq '');
+}
+
+
+######################################################################
+package XML::XQL::Node;		# forward declaration
+######################################################################
+
+######################################################################
+package XML::DOM::Node;
+######################################################################
+
+use vars qw( @NodeNames @EXPORT @ISA %HFIELDS @EXPORT_OK @EXPORT_TAGS );
+
+BEGIN 
+{
+  use XML::DOM::DOMException;
+  import Carp;
+
+  require FileHandle;
+
+  @ISA = qw( Exporter XML::XQL::Node );
+
+  # NOTE: SortKey is used in XML::XQL::Node. 
+  #       UserData is reserved for users (Hang your data here!)
+  XML::DOM::def_fields ("C A Doc Parent ReadOnly UsedIn Hidden SortKey UserData");
+
+  push (@EXPORT, qw(
+		    UNKNOWN_NODE
+		    ELEMENT_NODE
+		    ATTRIBUTE_NODE
+		    TEXT_NODE
+		    CDATA_SECTION_NODE
+		    ENTITY_REFERENCE_NODE
+		    ENTITY_NODE
+		    PROCESSING_INSTRUCTION_NODE
+		    COMMENT_NODE
+		    DOCUMENT_NODE
+		    DOCUMENT_TYPE_NODE
+		    DOCUMENT_FRAGMENT_NODE
+		    NOTATION_NODE
+		    ELEMENT_DECL_NODE
+		    ATT_DEF_NODE
+		    XML_DECL_NODE
+		    ATTLIST_DECL_NODE
+		   ));
+}
+
+#---- Constant definitions
+
+# Node types
+
+sub UNKNOWN_NODE                () {0;}		# not in the DOM Spec
+
+sub ELEMENT_NODE                () {1;}
+sub ATTRIBUTE_NODE              () {2;}
+sub TEXT_NODE                   () {3;}
+sub CDATA_SECTION_NODE          () {4;}
+sub ENTITY_REFERENCE_NODE       () {5;}
+sub ENTITY_NODE                 () {6;}
+sub PROCESSING_INSTRUCTION_NODE () {7;}
+sub COMMENT_NODE                () {8;}
+sub DOCUMENT_NODE               () {9;}
+sub DOCUMENT_TYPE_NODE          () {10;}
+sub DOCUMENT_FRAGMENT_NODE      () {11;}
+sub NOTATION_NODE               () {12;}
+
+sub ELEMENT_DECL_NODE		() {13;}	# not in the DOM Spec
+sub ATT_DEF_NODE 		() {14;}	# not in the DOM Spec
+sub XML_DECL_NODE 		() {15;}	# not in the DOM Spec
+sub ATTLIST_DECL_NODE		() {16;}	# not in the DOM Spec
+
+@NodeNames = (
+	      "UNKNOWN_NODE",	# not in the DOM Spec!
+
+	      "ELEMENT_NODE",
+	      "ATTRIBUTE_NODE",
+	      "TEXT_NODE",
+	      "CDATA_SECTION_NODE",
+	      "ENTITY_REFERENCE_NODE",
+	      "ENTITY_NODE",
+	      "PROCESSING_INSTRUCTION_NODE",
+	      "COMMENT_NODE",
+	      "DOCUMENT_NODE",
+	      "DOCUMENT_TYPE_NODE",
+	      "DOCUMENT_FRAGMENT_NODE",
+	      "NOTATION_NODE",
+
+	      "ELEMENT_DECL_NODE",
+	      "ATT_DEF_NODE",
+	      "XML_DECL_NODE",
+	      "ATTLIST_DECL_NODE"
+	     );
+
+sub decoupleUsedIn
+{
+    my $self = shift;
+    undef $self->[_UsedIn]; # was delete
+}
+
+sub getParentNode
+{
+    $_[0]->[_Parent];
+}
+
+sub appendChild
+{
+    my ($self, $node) = @_;
+
+    # REC 7473
+    if ($XML::DOM::SafeMode)
+    {
+	croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+					  "node is ReadOnly")
+	    if $self->isReadOnly;
+    }
+
+    my $doc = $self->[_Doc];
+
+    if ($node->isDocumentFragmentNode)
+    {
+	if ($XML::DOM::SafeMode)
+	{
+	    for my $n (@{$node->[_C]})
+	    {
+		croak new XML::DOM::DOMException (WRONG_DOCUMENT_ERR,
+						  "nodes belong to different documents")
+		    if $doc != $n->[_Doc];
+		
+		croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+						  "node is ancestor of parent node")
+		    if $n->isAncestor ($self);
+		
+		croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+						  "bad node type")
+		    if $self->rejectChild ($n);
+	    }
+	}
+
+	my @list = @{$node->[_C]};	# don't try to compress this
+	for my $n (@list)
+	{
+	    $n->setParentNode ($self);
+	}
+	push @{$self->[_C]}, @list;
+    }
+    else
+    {
+	if ($XML::DOM::SafeMode)
+	{
+	    croak new XML::DOM::DOMException (WRONG_DOCUMENT_ERR,
+						  "nodes belong to different documents")
+		if $doc != $node->[_Doc];
+		
+	    croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+						  "node is ancestor of parent node")
+		if $node->isAncestor ($self);
+		
+	    croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+						  "bad node type")
+		if $self->rejectChild ($node);
+	}
+	$node->setParentNode ($self);
+	push @{$self->[_C]}, $node;
+    }
+    $node;
+}
+
+sub getChildNodes
+{
+    # NOTE: if node can't have children, $self->[_C] is undef.
+    my $kids = $_[0]->[_C];
+
+    # Return a list if called in list context.
+    wantarray ? (defined ($kids) ? @{ $kids } : ()) :
+	        (defined ($kids) ? $kids : $XML::DOM::NodeList::EMPTY);
+}
+
+sub hasChildNodes
+{
+    my $kids = $_[0]->[_C];
+    defined ($kids) && @$kids > 0;
+}
+
+# This method is overriden in Document
+sub getOwnerDocument
+{
+    $_[0]->[_Doc];
+}
+
+sub getFirstChild
+{
+    my $kids = $_[0]->[_C];
+    defined $kids ? $kids->[0] : undef; 
+}
+
+sub getLastChild
+{
+    my $kids = $_[0]->[_C];
+    defined $kids ? $kids->[-1] : undef; 
+}
+
+sub getPreviousSibling
+{
+    my $self = shift;
+
+    my $pa = $self->[_Parent];
+    return undef unless $pa;
+    my $index = $pa->getChildIndex ($self);
+    return undef unless $index;
+
+    $pa->getChildAtIndex ($index - 1);
+}
+
+sub getNextSibling
+{
+    my $self = shift;
+
+    my $pa = $self->[_Parent];
+    return undef unless $pa;
+
+    $pa->getChildAtIndex ($pa->getChildIndex ($self) + 1);
+}
+
+sub insertBefore
+{
+    my ($self, $node, $refNode) = @_;
+
+    return $self->appendChild ($node) unless $refNode;	# append at the end
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my @nodes = ($node);
+    @nodes = @{$node->[_C]}
+	if $node->getNodeType == DOCUMENT_FRAGMENT_NODE;
+
+    my $doc = $self->[_Doc];
+
+    for my $n (@nodes)
+    {
+	croak new XML::DOM::DOMException (WRONG_DOCUMENT_ERR,
+					  "nodes belong to different documents")
+	    if $doc != $n->[_Doc];
+	
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "node is ancestor of parent node")
+	    if $n->isAncestor ($self);
+
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "bad node type")
+	    if $self->rejectChild ($n);
+    }
+    my $index = $self->getChildIndex ($refNode);
+
+    croak new XML::DOM::DOMException (NOT_FOUND_ERR,
+				      "reference node not found")
+	if $index == -1;
+
+    for my $n (@nodes)
+    {
+	$n->setParentNode ($self);
+    }
+
+    splice (@{$self->[_C]}, $index, 0, @nodes);
+    $node;
+}
+
+sub replaceChild
+{
+    my ($self, $node, $refNode) = @_;
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my @nodes = ($node);
+    @nodes = @{$node->[_C]}
+	if $node->getNodeType == DOCUMENT_FRAGMENT_NODE;
+
+    for my $n (@nodes)
+    {
+	croak new XML::DOM::DOMException (WRONG_DOCUMENT_ERR,
+					  "nodes belong to different documents")
+	    if $self->[_Doc] != $n->[_Doc];
+
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "node is ancestor of parent node")
+	    if $n->isAncestor ($self);
+
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "bad node type")
+	    if $self->rejectChild ($n);
+    }
+
+    my $index = $self->getChildIndex ($refNode);
+    croak new XML::DOM::DOMException (NOT_FOUND_ERR,
+				      "reference node not found")
+	if $index == -1;
+
+    for my $n (@nodes)
+    {
+	$n->setParentNode ($self);
+    }
+    splice (@{$self->[_C]}, $index, 1, @nodes);
+
+    $refNode->removeChildHoodMemories;
+    $refNode;
+}
+
+sub removeChild
+{
+    my ($self, $node) = @_;
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my $index = $self->getChildIndex ($node);
+
+    croak new XML::DOM::DOMException (NOT_FOUND_ERR,
+				      "reference node not found")
+	if $index == -1;
+
+    splice (@{$self->[_C]}, $index, 1, ());
+
+    $node->removeChildHoodMemories;
+    $node;
+}
+
+# Merge all subsequent Text nodes in this subtree
+sub normalize
+{
+    my ($self) = shift;
+    my $prev = undef;	# previous Text node
+
+    return unless defined $self->[_C];
+
+    my @nodes = @{$self->[_C]};
+    my $i = 0;
+    my $n = @nodes;
+    while ($i < $n)
+    {
+	my $node = $self->getChildAtIndex($i);
+	my $type = $node->getNodeType;
+
+	if (defined $prev)
+	{
+	    # It should not merge CDATASections. Dom Spec says:
+	    #  Adjacent CDATASections nodes are not merged by use
+	    #  of the Element.normalize() method.
+	    if ($type == TEXT_NODE)
+	    {
+		$prev->appendData ($node->getData);
+		$self->removeChild ($node);
+		$i--;
+		$n--;
+	    }
+	    else
+	    {
+		$prev = undef;
+		if ($type == ELEMENT_NODE)
+		{
+		    $node->normalize;
+		    if (defined $node->[_A])
+		    {
+			for my $attr (@{$node->[_A]->getValues})
+			{
+			    $attr->normalize;
+			}
+		    }
+		}
+	    }
+	}
+	else
+	{
+	    if ($type == TEXT_NODE)
+	    {
+		$prev = $node;
+	    }
+	    elsif ($type == ELEMENT_NODE)
+	    {
+		$node->normalize;
+		if (defined $node->[_A])
+		{
+		    for my $attr (@{$node->[_A]->getValues})
+		    {
+			$attr->normalize;
+		    }
+		}
+	    }
+	}
+	$i++;
+    }
+}
+
+#
+# Return all Element nodes in the subtree that have the specified tagName.
+# If tagName is "*", all Element nodes are returned.
+# NOTE: the DOM Spec does not specify a 3rd or 4th parameter
+#
+sub getElementsByTagName
+{
+    my ($self, $tagName, $recurse, $list) = @_;
+    $recurse = 1 unless defined $recurse;
+    $list = (wantarray ? [] : new XML::DOM::NodeList) unless defined $list;
+
+    return unless defined $self->[_C];
+
+    # preorder traversal: check parent node first
+    for my $kid (@{$self->[_C]})
+    {
+	if ($kid->isElementNode)
+	{
+	    if ($tagName eq "*" || $tagName eq $kid->getTagName)
+	    {
+		push @{$list}, $kid;
+	    }
+	    $kid->getElementsByTagName ($tagName, $recurse, $list) if $recurse;
+	}
+    }
+    wantarray ? @{ $list } : $list;
+}
+
+sub getNodeValue
+{
+    undef;
+}
+
+sub setNodeValue
+{
+    # no-op
+}
+
+#
+# Redefined by XML::DOM::Element
+#
+sub getAttributes
+{
+    undef;
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub setOwnerDocument
+{
+    my ($self, $doc) = @_;
+    $self->[_Doc] = $doc;
+
+    return unless defined $self->[_C];
+
+    for my $kid (@{$self->[_C]})
+    {
+	$kid->setOwnerDocument ($doc);
+    }
+}
+
+sub cloneChildren
+{
+    my ($self, $node, $deep) = @_;
+    return unless $deep;
+    
+    return unless defined $self->[_C];
+
+    local $XML::DOM::IgnoreReadOnly = 1;
+
+    for my $kid (@{$node->[_C]})
+    {
+	my $newNode = $kid->cloneNode ($deep);
+	push @{$self->[_C]}, $newNode;
+	$newNode->setParentNode ($self);
+    }
+}
+
+#
+# For internal use only!
+#
+sub removeChildHoodMemories
+{
+    my ($self) = @_;
+
+    undef $self->[_Parent]; # was delete
+}
+
+#
+# Remove circular dependencies. The Node and its children should
+# not be used afterwards.
+#
+sub dispose
+{
+    my $self = shift;
+
+    $self->removeChildHoodMemories;
+
+    if (defined $self->[_C])
+    {
+	$self->[_C]->dispose;
+	undef $self->[_C]; # was delete
+    }
+    undef $self->[_Doc]; # was delete
+}
+
+#
+# For internal use only!
+#
+sub setParentNode
+{
+    my ($self, $parent) = @_;
+
+    # REC 7473
+    my $oldParent = $self->[_Parent];
+    if (defined $oldParent)
+    {
+	# remove from current parent
+	my $index = $oldParent->getChildIndex ($self);
+
+	# NOTE: we don't have to check if [_C] is defined,
+	# because were removing a child here!
+	splice (@{$oldParent->[_C]}, $index, 1, ());
+
+	$self->removeChildHoodMemories;
+    }
+    $self->[_Parent] = $parent;
+}
+
+#
+# This function can return 3 values:
+# 1: always readOnly
+# 0: never readOnly
+# undef: depends on parent node 
+#
+# Returns 1 for DocumentType, Notation, Entity, EntityReference, Attlist, 
+# ElementDecl, AttDef. 
+# The first 4 are readOnly according to the DOM Spec, the others are always 
+# children of DocumentType. (Naturally, children of a readOnly node have to be
+# readOnly as well...)
+# These nodes are always readOnly regardless of who their ancestors are.
+# Other nodes, e.g. Comment, are readOnly only if their parent is readOnly,
+# which basically means that one of its ancestors has to be one of the
+# aforementioned node types.
+# Document and DocumentFragment return 0 for obvious reasons.
+# Attr, Element, CDATASection, Text return 0. The DOM spec says that they can 
+# be children of an Entity, but I don't think that that's possible
+# with the current XML::Parser.
+# Attr uses a {ReadOnly} property, which is only set if it's part of a AttDef.
+# Always returns 0 if ignoreReadOnly is set.
+#
+sub isReadOnly
+{
+    # default implementation for Nodes that are always readOnly
+    ! $XML::DOM::IgnoreReadOnly;
+}
+
+sub rejectChild
+{
+    1;
+}
+
+sub getNodeTypeName
+{
+    $NodeNames[$_[0]->getNodeType];
+}
+
+sub getChildIndex
+{
+    my ($self, $node) = @_;
+    my $i = 0;
+
+    return -1 unless defined $self->[_C];
+
+    for my $kid (@{$self->[_C]})
+    {
+	return $i if $kid == $node;
+	$i++;
+    }
+    -1;
+}
+
+sub getChildAtIndex
+{
+    my $kids = $_[0]->[_C];
+    defined ($kids) ? $kids->[$_[1]] : undef;
+}
+
+sub isAncestor
+{
+    my ($self, $node) = @_;
+
+    do
+    {
+	return 1 if $self == $node;
+	$node = $node->[_Parent];
+    }
+    while (defined $node);
+
+    0;
+}
+
+#
+# Added for optimization. Overriden in XML::DOM::Text
+#
+sub isTextNode
+{
+    0;
+}
+
+#
+# Added for optimization. Overriden in XML::DOM::DocumentFragment
+#
+sub isDocumentFragmentNode
+{
+    0;
+}
+
+#
+# Added for optimization. Overriden in XML::DOM::Element
+#
+sub isElementNode
+{
+    0;
+}
+
+#
+# Add a Text node with the specified value or append the text to the
+# previous Node if it is a Text node.
+#
+sub addText
+{
+    # REC 9456 (if it was called)
+    my ($self, $str) = @_;
+
+    my $node = ${$self->[_C]}[-1];	# $self->getLastChild
+
+    if (defined ($node) && $node->isTextNode)
+    {
+	# REC 5475 (if it was called)
+	$node->appendData ($str);
+    }
+    else
+    {
+	$node = $self->[_Doc]->createTextNode ($str);
+	$self->appendChild ($node);
+    }
+    $node;
+}
+
+#
+# Add a CDATASection node with the specified value or append the text to the
+# previous Node if it is a CDATASection node.
+#
+sub addCDATA
+{
+    my ($self, $str) = @_;
+
+    my $node = ${$self->[_C]}[-1];	# $self->getLastChild
+
+    if (defined ($node) && $node->getNodeType == CDATA_SECTION_NODE)
+    {
+	$node->appendData ($str);
+    }
+    else
+    {
+	$node = $self->[_Doc]->createCDATASection ($str);
+	$self->appendChild ($node);
+    }
+}
+
+sub removeChildNodes
+{
+    my $self = shift;
+
+    my $cref = $self->[_C];
+    return unless defined $cref;
+
+    my $kid;
+    while ($kid = pop @{$cref})
+    {
+	undef $kid->[_Parent]; # was delete
+    }
+}
+
+sub toString
+{
+    my $self = shift;
+    my $pr = $XML::DOM::PrintToString::Singleton;
+    $pr->reset;
+    $self->print ($pr);
+    $pr->toString;
+}
+
+sub to_sax
+{
+    my $self = shift;
+    unshift @_, 'Handler' if (@_ == 1);
+    my %h = @_;
+
+    my $doch = exists ($h{DocumentHandler}) ? $h{DocumentHandler} 
+					    : $h{Handler};
+    my $dtdh = exists ($h{DTDHandler}) ? $h{DTDHandler} 
+				       : $h{Handler};
+    my $enth = exists ($h{EntityResolver}) ? $h{EntityResolver} 
+					   : $h{Handler};
+
+    $self->_to_sax ($doch, $dtdh, $enth);
+}
+
+sub printToFile
+{
+    my ($self, $fileName) = @_;
+    my $fh = new FileHandle ($fileName, "w") || 
+	croak "printToFile - can't open output file $fileName";
+    
+    $self->print ($fh);
+    $fh->close;
+}
+
+#
+# Use print to print to a FileHandle object (see printToFile code)
+#
+sub printToFileHandle
+{
+    my ($self, $FH) = @_;
+    my $pr = new XML::DOM::PrintToFileHandle ($FH);
+    $self->print ($pr);
+}
+
+#
+# Used by AttDef::setDefault to convert unexpanded default attribute value
+#
+sub expandEntityRefs
+{
+    my ($self, $str) = @_;
+    my $doctype = $self->[_Doc]->getDoctype;
+
+    use bytes;  # XML::RegExp expressed in terms encoded UTF8
+    $str =~ s/&($XML::RegExp::Name|(#([0-9]+)|#x([0-9a-fA-F]+)));/
+	defined($2) ? XML::DOM::XmlUtf8Encode ($3 || hex ($4)) 
+		    : expandEntityRef ($1, $doctype)/ego;
+    $str;
+}
+
+sub expandEntityRef
+{
+    my ($entity, $doctype) = @_;
+
+    my $expanded = $XML::DOM::DefaultEntities{$entity};
+    return $expanded if defined $expanded;
+
+    $expanded = $doctype->getEntity ($entity);
+    return $expanded->getValue if (defined $expanded);
+
+#?? is this an error?
+    croak "Could not expand entity reference of [$entity]\n";
+#    return "&$entity;";	# entity not found
+}
+
+sub isHidden
+{
+    $_[0]->[_Hidden];
+}
+
+######################################################################
+package XML::DOM::Attr;
+######################################################################
+
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Name Specified", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $name, $value, $specified) = @_;
+
+    if ($XML::DOM::SafeMode)
+    {
+	croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR,
+					  "bad Attr name [$name]")
+	    unless XML::DOM::isValidName ($name);
+    }
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_C] = new XML::DOM::NodeList;
+    $self->[_Name] = $name;
+    
+    if (defined $value)
+    {
+	$self->setValue ($value);
+	$self->[_Specified] = (defined $specified) ? $specified : 1;
+    }
+    else
+    {
+	$self->[_Specified] = 0;
+    }
+    $self;
+}
+
+sub getNodeType
+{
+    ATTRIBUTE_NODE;
+}
+
+sub isSpecified
+{
+    $_[0]->[_Specified];
+}
+
+sub getName
+{
+    $_[0]->[_Name];
+}
+
+sub getValue
+{
+    my $self = shift;
+    my $value = "";
+
+    for my $kid (@{$self->[_C]})
+    {
+	$value .= $kid->getData if defined $kid->getData;
+    }
+    $value;
+}
+
+sub setValue
+{
+    my ($self, $value) = @_;
+
+    # REC 1147
+    $self->removeChildNodes;
+    $self->appendChild ($self->[_Doc]->createTextNode ($value));
+    $self->[_Specified] = 1;
+}
+
+sub getNodeName
+{
+    $_[0]->getName;
+}
+
+sub getNodeValue
+{
+    $_[0]->getValue;
+}
+
+sub setNodeValue
+{
+    $_[0]->setValue ($_[1]);
+}
+
+sub cloneNode
+{
+    my ($self) = @_;	# parameter deep is ignored
+
+    my $node = $self->[_Doc]->createAttribute ($self->getName);
+    $node->[_Specified] = $self->[_Specified];
+    $node->[_ReadOnly] = 1 if $self->[_ReadOnly];
+
+    $node->cloneChildren ($self, 1);
+    $node;
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+#
+
+sub isReadOnly
+{
+    # ReadOnly property is set if it's part of a AttDef
+    ! $XML::DOM::IgnoreReadOnly && defined ($_[0]->[_ReadOnly]);
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_Name];
+
+    $FILE->print ("$name=\"");
+    for my $kid (@{$self->[_C]})
+    {
+	if ($kid->getNodeType == TEXT_NODE)
+	{
+	    $FILE->print (XML::DOM::encodeAttrValue ($kid->getData));
+	}
+	else	# ENTITY_REFERENCE_NODE
+	{
+	    $kid->print ($FILE);
+	}
+    }
+    $FILE->print ("\"");
+}
+
+sub rejectChild
+{
+    my $t = $_[1]->getNodeType;
+
+    $t != TEXT_NODE 
+    && $t != ENTITY_REFERENCE_NODE;
+}
+
+######################################################################
+package XML::DOM::ProcessingInstruction;
+######################################################################
+
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Target Data", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $target, $data, $hidden) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR,
+			      "bad ProcessingInstruction Target [$target]")
+	unless (XML::DOM::isValidName ($target) && $target !~ /^xml$/io);
+
+    my $self = bless [], $class;
+  
+    $self->[_Doc] = $doc;
+    $self->[_Target] = $target;
+    $self->[_Data] = $data;
+    $self->[_Hidden] = $hidden;
+    $self;
+}
+
+sub getNodeType
+{
+    PROCESSING_INSTRUCTION_NODE;
+}
+
+sub getTarget
+{
+    $_[0]->[_Target];
+}
+
+sub getData
+{
+    $_[0]->[_Data];
+}
+
+sub setData
+{
+    my ($self, $data) = @_;
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    $self->[_Data] = $data;
+}
+
+sub getNodeName
+{
+    $_[0]->[_Target];
+}
+
+#
+# Same as getData
+#
+sub getNodeValue
+{
+    $_[0]->[_Data];
+}
+
+sub setNodeValue
+{
+    $_[0]->setData ($_[1]);
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createProcessingInstruction ($self->getTarget, 
+						$self->getData,
+						$self->isHidden);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    return 0 if $XML::DOM::IgnoreReadOnly;
+
+    my $pa = $_[0]->[_Parent];
+    defined ($pa) ? $pa->isReadOnly : 0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    $FILE->print ("<?");
+    $FILE->print ($self->[_Target]);
+    $FILE->print (" ");
+    $FILE->print (XML::DOM::encodeProcessingInstruction ($self->[_Data]));
+    $FILE->print ("?>");
+}
+
+sub _to_sax {
+    my ($self, $doch) = @_;
+    $doch->processing_instruction({Target => $self->getTarget, Data => $self->getData});
+}
+
+######################################################################
+package XML::DOM::Notation;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Name Base SysId PubId", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $name, $base, $sysId, $pubId, $hidden) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+				      "bad Notation Name [$name]")
+	unless XML::DOM::isValidName ($name);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_Name] = $name;
+    $self->[_Base] = $base;
+    $self->[_SysId] = $sysId;
+    $self->[_PubId] = $pubId;
+    $self->[_Hidden] = $hidden;
+    $self;
+}
+
+sub getNodeType
+{
+    NOTATION_NODE;
+}
+
+sub getPubId
+{
+    $_[0]->[_PubId];
+}
+
+sub setPubId
+{
+    $_[0]->[_PubId] = $_[1];
+}
+
+sub getSysId
+{
+    $_[0]->[_SysId];
+}
+
+sub setSysId
+{
+    $_[0]->[_SysId] = $_[1];
+}
+
+sub getName
+{
+    $_[0]->[_Name];
+}
+
+sub setName
+{
+    $_[0]->[_Name] = $_[1];
+}
+
+sub getBase
+{
+    $_[0]->[_Base];
+}
+
+sub getNodeName
+{
+    $_[0]->[_Name];
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_Name];
+    my $sysId = $self->[_SysId];
+    my $pubId = $self->[_PubId];
+
+    $FILE->print ("<!NOTATION $name ");
+
+    if (defined $pubId)
+    {
+	$FILE->print (" PUBLIC \"$pubId\"");	
+    }
+    if (defined $sysId)
+    {
+	$FILE->print (" SYSTEM \"$sysId\"");	
+    }
+    $FILE->print (">");
+}
+
+sub cloneNode
+{
+    my ($self) = @_;
+    $self->[_Doc]->createNotation ($self->[_Name], $self->[_Base], 
+				   $self->[_SysId], $self->[_PubId],
+				   $self->[_Hidden]);
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->Notation ($self->getName, $self->getBase, 
+		     $self->getSysId, $self->getPubId);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $dtdh->notation_decl ( { Name => $self->getName, 
+			     Base => $self->getBase, 
+			     SystemId => $self->getSysId, 
+			     PublicId => $self->getPubId });
+}
+
+######################################################################
+package XML::DOM::Entity;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("NotationName Parameter Value Ndata SysId PubId", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $notationName, $value, $sysId, $pubId, $ndata, $isParam, $hidden) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+				      "bad Entity Name [$notationName]")
+	unless XML::DOM::isValidName ($notationName);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_NotationName] = $notationName;
+    $self->[_Parameter] = $isParam;
+    $self->[_Value] = $value;
+    $self->[_Ndata] = $ndata;
+    $self->[_SysId] = $sysId;
+    $self->[_PubId] = $pubId;
+    $self->[_Hidden] = $hidden;
+    $self;
+#?? maybe Value should be a Text node
+}
+
+sub getNodeType
+{
+    ENTITY_NODE;
+}
+
+sub getPubId
+{
+    $_[0]->[_PubId];
+}
+
+sub getSysId
+{
+    $_[0]->[_SysId];
+}
+
+# Dom Spec says: 
+#  For unparsed entities, the name of the notation for the
+#  entity. For parsed entities, this is null.
+
+#?? do we have unparsed entities?
+sub getNotationName
+{
+    $_[0]->[_NotationName];
+}
+
+sub getNodeName
+{
+    $_[0]->[_NotationName];
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createEntity ($self->[_NotationName], $self->[_Value], 
+				 $self->[_SysId], $self->[_PubId], 
+				 $self->[_Ndata], $self->[_Parameter], $self->[_Hidden]);
+}
+
+sub rejectChild
+{
+    return 1;
+#?? if value is split over subnodes, recode this section
+# also add:				   C => new XML::DOM::NodeList,
+
+    my $t = $_[1];
+
+    return $t == TEXT_NODE
+	|| $t == ENTITY_REFERENCE_NODE 
+	|| $t == PROCESSING_INSTRUCTION_NODE
+	|| $t == COMMENT_NODE
+	|| $t == CDATA_SECTION_NODE
+	|| $t == ELEMENT_NODE;
+}
+
+sub getValue
+{
+    $_[0]->[_Value];
+}
+
+sub isParameterEntity
+{
+    $_[0]->[_Parameter];
+}
+
+sub getNdata
+{
+    $_[0]->[_Ndata];
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_NotationName];
+
+    my $par = $self->isParameterEntity ? "% " : "";
+
+    $FILE->print ("<!ENTITY $par$name");
+
+    my $value = $self->[_Value];
+    my $sysId = $self->[_SysId];
+    my $pubId = $self->[_PubId];
+    my $ndata = $self->[_Ndata];
+
+    if (defined $value)
+    {
+#?? Not sure what to do if it contains both single and double quote
+	$value = ($value =~ /\"/) ? "'$value'" : "\"$value\"";
+	$FILE->print (" $value");
+    }
+    if (defined $pubId)
+    {
+	$FILE->print (" PUBLIC \"$pubId\"");	
+    }
+    elsif (defined $sysId)
+    {
+	$FILE->print (" SYSTEM");
+    }
+
+    if (defined $sysId)
+    {
+	$FILE->print (" \"$sysId\"");
+    }
+    $FILE->print (" NDATA $ndata") if defined $ndata;
+    $FILE->print (">");
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    my $name = ($self->isParameterEntity ? '%' : "") . $self->getNotationName; 
+    $iter->Entity ($name,
+		   $self->getValue, $self->getSysId, $self->getPubId, 
+		   $self->getNdata);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    my $name = ($self->isParameterEntity ? '%' : "") . $self->getNotationName; 
+    $dtdh->entity_decl ( { Name => $name, 
+			   Value => $self->getValue, 
+			   SystemId => $self->getSysId, 
+			   PublicId => $self->getPubId, 
+			   Notation => $self->getNdata } );
+}
+
+######################################################################
+package XML::DOM::EntityReference;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("EntityName Parameter NoExpand", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $name, $parameter, $noExpand) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+		      "bad Entity Name [$name] in EntityReference")
+	unless XML::DOM::isValidName ($name);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_EntityName] = $name;
+    $self->[_Parameter] = ($parameter || 0);
+    $self->[_NoExpand] = ($noExpand || 0);
+
+    $self;
+}
+
+sub getNodeType
+{
+    ENTITY_REFERENCE_NODE;
+}
+
+sub getNodeName
+{
+    $_[0]->[_EntityName];
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub getEntityName
+{
+    $_[0]->[_EntityName];
+}
+
+sub isParameterEntity
+{
+    $_[0]->[_Parameter];
+}
+
+sub getData
+{
+    my $self = shift;
+    my $name = $self->[_EntityName];
+    my $parameter = $self->[_Parameter];
+
+    my $data;
+    if ($self->[_NoExpand]) {
+      $data = "&$name;" if $name;
+    } else {
+      $data = $self->[_Doc]->expandEntity ($name, $parameter);
+    }
+
+    unless (defined $data)
+    {
+#?? this is probably an error, but perhaps requires check to NoExpand
+# will fix it?
+	my $pc = $parameter ? "%" : "&";
+	$data = "$pc$name;";
+    }
+    $data;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_EntityName];
+
+#?? or do we expand the entities?
+
+    my $pc = $self->[_Parameter] ? "%" : "&";
+    $FILE->print ("$pc$name;");
+}
+
+# Dom Spec says:
+#     [...] but if such an Entity exists, then
+#     the child list of the EntityReference node is the same as that of the
+#     Entity node. 
+#
+#     The resolution of the children of the EntityReference (the replacement
+#     value of the referenced Entity) may be lazily evaluated; actions by the
+#     user (such as calling the childNodes method on the EntityReference
+#     node) are assumed to trigger the evaluation.
+sub getChildNodes
+{
+    my $self = shift;
+    my $entity = $self->[_Doc]->getEntity ($self->[_EntityName]);
+    defined ($entity) ? $entity->getChildNodes : new XML::DOM::NodeList;
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createEntityReference ($self->[_EntityName], 
+                                         $self->[_Parameter],
+                                         $self->[_NoExpand],
+                                          );
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->EntityRef ($self->getEntityName, $self->isParameterEntity);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    my @par = $self->isParameterEntity ? (Parameter => 1) : ();
+#?? not supported by PerlSAX: $self->isParameterEntity
+
+    $doch->entity_reference ( { Name => $self->getEntityName, @par } );
+}
+
+# NOTE: an EntityReference can't really have children, so rejectChild
+# is not reimplemented (i.e. it always returns 0.)
+
+######################################################################
+package XML::DOM::AttDef;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Name Type Fixed Default Required Implied Quote", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+#------------------------------------------------------------
+# Extra method implementations
+
+# AttDef is not part of DOM Spec
+sub new
+{
+    my ($class, $doc, $name, $attrType, $default, $fixed, $hidden) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR,
+				      "bad Attr name in AttDef [$name]")
+	unless XML::DOM::isValidName ($name);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_Name] = $name;
+    $self->[_Type] = $attrType;
+
+    if (defined $default)
+    {
+	if ($default eq "#REQUIRED")
+	{
+	    $self->[_Required] = 1;
+	}
+	elsif ($default eq "#IMPLIED")
+	{
+	    $self->[_Implied] = 1;
+	}
+	else
+	{
+	    # strip off quotes - see Attlist handler in XML::Parser
+            # this regexp doesn't work with 5.8.0 unicode
+#	    $default =~ m#^(["'])(.*)['"]$#;
+#	    $self->[_Quote] = $1;	# keep track of the quote character
+#	    $self->[_Default] = $self->setDefault ($2);
+
+          # workaround for 5.8.0 unicode
+          $default =~ s!^(["'])!!;
+          $self->[_Quote] = $1;
+          $default =~ s!(["'])$!!;
+          $self->[_Default] = $self->setDefault ($default);
+	    	    
+#?? should default value be decoded - what if it contains e.g. "&amp;"
+	}
+    }
+    $self->[_Fixed] = $fixed if defined $fixed;
+    $self->[_Hidden] = $hidden if defined $hidden;
+
+    $self;
+}
+
+sub getNodeType
+{
+    ATT_DEF_NODE;
+}
+
+sub getName
+{
+    $_[0]->[_Name];
+}
+
+# So it can be added to a NamedNodeMap
+sub getNodeName
+{
+    $_[0]->[_Name];
+}
+
+sub getType
+{
+    $_[0]->[_Type];
+}
+
+sub setType
+{
+    $_[0]->[_Type] = $_[1];
+}
+
+sub getDefault
+{
+    $_[0]->[_Default];
+}
+
+sub setDefault
+{
+    my ($self, $value) = @_;
+
+    # specified=0, it's the default !
+    my $attr = $self->[_Doc]->createAttribute ($self->[_Name], undef, 0);
+    $attr->[_ReadOnly] = 1;
+
+#?? this should be split over Text and EntityReference nodes, just like other
+# Attr nodes - just expand the text for now
+    $value = $self->expandEntityRefs ($value);
+    $attr->addText ($value);
+#?? reimplement in NoExpand mode!
+
+    $attr;
+}
+
+sub isFixed
+{
+    $_[0]->[_Fixed] || 0;
+}
+
+sub isRequired
+{
+    $_[0]->[_Required] || 0;
+}
+
+sub isImplied
+{
+    $_[0]->[_Implied] || 0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_Name];
+    my $type = $self->[_Type];
+    my $fixed = $self->[_Fixed];
+    my $default = $self->[_Default];
+
+#    $FILE->print ("$name $type");
+    # replaced line above with the two lines below
+    # seems to be a bug in perl 5.6.0 that causes
+    # test 3 of dom_jp_attr.t to fail?
+    $FILE->print ($name);
+    $FILE->print (" $type");
+
+    $FILE->print (" #FIXED") if defined $fixed;
+
+    if ($self->[_Required])
+    {
+	$FILE->print (" #REQUIRED");
+    }
+    elsif ($self->[_Implied])
+    {
+	$FILE->print (" #IMPLIED");
+    }
+    elsif (defined ($default))
+    {
+	my $quote = $self->[_Quote];
+	$FILE->print (" $quote");
+	for my $kid (@{$default->[_C]})
+	{
+	    $kid->print ($FILE);
+	}
+	$FILE->print ($quote);	
+    }
+}
+
+sub getDefaultString
+{
+    my $self = shift;
+    my $default;
+
+    if ($self->[_Required])
+    {
+	return "#REQUIRED";
+    }
+    elsif ($self->[_Implied])
+    {
+	return "#IMPLIED";
+    }
+    elsif (defined ($default = $self->[_Default]))
+    {
+	my $quote = $self->[_Quote];
+	$default = $default->toString;
+	return "$quote$default$quote";
+    }
+    undef;
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    my $node = new XML::DOM::AttDef ($self->[_Doc], $self->[_Name], $self->[_Type],
+				     undef, $self->[_Fixed]);
+
+    $node->[_Required] = 1 if $self->[_Required];
+    $node->[_Implied] = 1 if $self->[_Implied];
+    $node->[_Fixed] = $self->[_Fixed] if defined $self->[_Fixed];
+    $node->[_Hidden] = $self->[_Hidden] if defined $self->[_Hidden];
+
+    if (defined $self->[_Default])
+    {
+	$node->[_Default] = $self->[_Default]->cloneNode(1);
+    }
+    $node->[_Quote] = $self->[_Quote];
+
+    $node;
+}
+
+sub setOwnerDocument
+{
+    my ($self, $doc) = @_;
+    $self->SUPER::setOwnerDocument ($doc);
+
+    if (defined $self->[_Default])
+    {
+	$self->[_Default]->setOwnerDocument ($doc);
+    }
+}
+
+######################################################################
+package XML::DOM::AttlistDecl;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    import XML::DOM::AttDef qw{ :Fields };
+
+    XML::DOM::def_fields ("ElementName", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+#------------------------------------------------------------
+# Extra method implementations
+
+# AttlistDecl is not part of the DOM Spec
+sub new
+{
+    my ($class, $doc, $name) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+			      "bad Element TagName [$name] in AttlistDecl")
+	unless XML::DOM::isValidName ($name);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_C] = new XML::DOM::NodeList;
+    $self->[_ReadOnly] = 1;
+    $self->[_ElementName] = $name;
+
+    $self->[_A] = new XML::DOM::NamedNodeMap (Doc	=> $doc,
+					      ReadOnly	=> 1,
+					      Parent	=> $self);
+
+    $self;
+}
+
+sub getNodeType
+{
+    ATTLIST_DECL_NODE;
+}
+
+sub getName
+{
+    $_[0]->[_ElementName];
+}
+
+sub getNodeName
+{
+    $_[0]->[_ElementName];
+}
+
+sub getAttDef
+{
+    my ($self, $attrName) = @_;
+    $self->[_A]->getNamedItem ($attrName);
+}
+
+sub addAttDef
+{
+    my ($self, $attrName, $type, $default, $fixed, $hidden) = @_;
+    my $node = $self->getAttDef ($attrName);
+
+    if (defined $node)
+    {
+	# data will be ignored if already defined
+	my $elemName = $self->getName;
+	XML::DOM::warning ("multiple definitions of attribute $attrName for element $elemName, only first one is recognized");
+    }
+    else
+    {
+	$node = new XML::DOM::AttDef ($self->[_Doc], $attrName, $type, 
+				      $default, $fixed, $hidden);
+	$self->[_A]->setNamedItem ($node);
+    }
+    $node;
+}
+
+sub getDefaultAttrValue
+{
+    my ($self, $attr) = @_;
+    my $attrNode = $self->getAttDef ($attr);
+    (defined $attrNode) ? $attrNode->getDefault : undef;
+}
+
+sub cloneNode
+{
+    my ($self, $deep) = @_;
+    my $node = $self->[_Doc]->createAttlistDecl ($self->[_ElementName]);
+    
+    $node->[_A] = $self->[_A]->cloneNode ($deep);
+    $node;
+}
+
+sub setOwnerDocument
+{
+    my ($self, $doc) = @_;
+    $self->SUPER::setOwnerDocument ($doc);
+
+    $self->[_A]->setOwnerDocument ($doc);
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->getName;
+    my @attlist = @{$self->[_A]->getValues};
+
+    my $hidden = 1;
+    for my $att (@attlist)
+    {
+	unless ($att->[_Hidden])
+	{
+	    $hidden = 0;
+	    last;
+	}
+    }
+
+    unless ($hidden)
+    {
+	$FILE->print ("<!ATTLIST $name");
+
+	if (@attlist == 1)
+	{
+	    $FILE->print (" ");
+	    $attlist[0]->print ($FILE);	    
+	}
+	else
+	{
+	    for my $attr (@attlist)
+	    {
+		next if $attr->[_Hidden];
+
+		$FILE->print ("\x0A  ");
+		$attr->print ($FILE);
+	    }
+	}
+	$FILE->print (">");
+    }
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    my $tag = $self->getName;
+    for my $a ($self->[_A]->getValues)
+    {
+	my $default = $a->isImplied ? '#IMPLIED' :
+	    ($a->isRequired ? '#REQUIRED' : 
+	     ($a->[_Quote] . $a->getDefault->getValue . $a->[_Quote]));
+
+	$iter->Attlist ($tag, $a->getName, $a->getType, $default, $a->isFixed); 
+    }
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    my $tag = $self->getName;
+    for my $a ($self->[_A]->getValues)
+    {
+	my $default = $a->isImplied ? '#IMPLIED' :
+	    ($a->isRequired ? '#REQUIRED' : 
+	     ($a->[_Quote] . $a->getDefault->getValue . $a->[_Quote]));
+
+	$dtdh->attlist_decl ({ ElementName => $tag, 
+			       AttributeName => $a->getName, 
+			       Type => $a->[_Type], 
+			       Default => $default, 
+			       Fixed => $a->isFixed }); 
+    }
+}
+
+######################################################################
+package XML::DOM::ElementDecl;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Name Model", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+
+#------------------------------------------------------------
+# Extra method implementations
+
+# ElementDecl is not part of the DOM Spec
+sub new
+{
+    my ($class, $doc, $name, $model, $hidden) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+			      "bad Element TagName [$name] in ElementDecl")
+	unless XML::DOM::isValidName ($name);
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_Name] = $name;
+    $self->[_ReadOnly] = 1;
+    $self->[_Model] = $model;
+    $self->[_Hidden] = $hidden;
+    $self;
+}
+
+sub getNodeType
+{
+    ELEMENT_DECL_NODE;
+}
+
+sub getName
+{
+    $_[0]->[_Name];
+}
+
+sub getNodeName
+{
+    $_[0]->[_Name];
+}
+
+sub getModel
+{
+    $_[0]->[_Model];
+}
+
+sub setModel
+{
+    my ($self, $model) = @_;
+
+    $self->[_Model] = $model;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_Name];
+    my $model = $self->[_Model];
+
+    $FILE->print ("<!ELEMENT $name $model>")
+	unless $self->[_Hidden];
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createElementDecl ($self->[_Name], $self->[_Model], 
+				      $self->[_Hidden]);
+}
+
+sub to_expat
+{
+#?? add support for Hidden?? (allover, also in _to_sax!!)
+
+    my ($self, $iter) = @_;
+    $iter->Element ($self->getName, $self->getModel);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $dtdh->element_decl ( { Name => $self->getName, 
+			    Model => $self->getModel } );
+}
+
+######################################################################
+package XML::DOM::Element;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("TagName", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use XML::DOM::NamedNodeMap;
+use Carp;
+
+sub new
+{
+    my ($class, $doc, $tagName) = @_;
+
+    if ($XML::DOM::SafeMode)
+    {
+	croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+				      "bad Element TagName [$tagName]")
+	    unless XML::DOM::isValidName ($tagName);
+    }
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_C] = new XML::DOM::NodeList;
+    $self->[_TagName] = $tagName;
+
+# Now we're creating the NamedNodeMap only when needed (REC 2313 => 1147)    
+#    $self->[_A] = new XML::DOM::NamedNodeMap (Doc	=> $doc,
+#					     Parent	=> $self);
+
+    $self;
+}
+
+sub getNodeType
+{
+    ELEMENT_NODE;
+}
+
+sub getTagName
+{
+    $_[0]->[_TagName];
+}
+
+sub getNodeName
+{
+    $_[0]->[_TagName];
+}
+
+sub getAttributeNode
+{
+    my ($self, $name) = @_;
+    return undef unless defined $self->[_A];
+
+    $self->getAttributes->{$name};
+}
+
+sub getAttribute
+{
+    my ($self, $name) = @_;
+    my $attr = $self->getAttributeNode ($name);
+    (defined $attr) ? $attr->getValue : "";
+}
+
+sub setAttribute
+{
+    my ($self, $name, $val) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR,
+				      "bad Attr Name [$name]")
+	unless XML::DOM::isValidName ($name);
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my $node = $self->getAttributes->{$name};
+    if (defined $node)
+    {
+	$node->setValue ($val);
+    }
+    else
+    {
+	$node = $self->[_Doc]->createAttribute ($name, $val);
+	$self->[_A]->setNamedItem ($node);
+    }
+}
+
+sub setAttributeNode
+{
+    my ($self, $node) = @_;
+    my $attr = $self->getAttributes;
+    my $name = $node->getNodeName;
+
+    # REC 1147
+    if ($XML::DOM::SafeMode)
+    {
+	croak new XML::DOM::DOMException (WRONG_DOCUMENT_ERR,
+					  "nodes belong to different documents")
+	    if $self->[_Doc] != $node->[_Doc];
+
+	croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+					  "node is ReadOnly")
+	    if $self->isReadOnly;
+
+	my $attrParent = $node->[_UsedIn];
+	croak new XML::DOM::DOMException (INUSE_ATTRIBUTE_ERR,
+					  "Attr is already used by another Element")
+	    if (defined ($attrParent) && $attrParent != $attr);
+    }
+
+    my $other = $attr->{$name};
+    $attr->removeNamedItem ($name) if defined $other;
+
+    $attr->setNamedItem ($node);
+
+    $other;
+}
+
+sub removeAttributeNode
+{
+    my ($self, $node) = @_;
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my $attr = $self->[_A];
+    unless (defined $attr)
+    {
+	croak new XML::DOM::DOMException (NOT_FOUND_ERR);
+	return undef;
+    }
+
+    my $name = $node->getNodeName;
+    my $attrNode = $attr->getNamedItem ($name);
+
+#?? should it croak if it's the default value?
+    croak new XML::DOM::DOMException (NOT_FOUND_ERR)
+	unless $node == $attrNode;
+
+    # Not removing anything if it's the default value already
+    return undef unless $node->isSpecified;
+
+    $attr->removeNamedItem ($name);
+
+    # Substitute with default value if it's defined
+    my $default = $self->getDefaultAttrValue ($name);
+    if (defined $default)
+    {
+	local $XML::DOM::IgnoreReadOnly = 1;
+
+	$default = $default->cloneNode (1);
+	$attr->setNamedItem ($default);
+    }
+    $node;
+}
+
+sub removeAttribute
+{
+    my ($self, $name) = @_;
+    my $attr = $self->[_A];
+    unless (defined $attr)
+    {
+	croak new XML::DOM::DOMException (NOT_FOUND_ERR);
+	return;
+    }
+    
+    my $node = $attr->getNamedItem ($name);
+    if (defined $node)
+    {
+#?? could use dispose() to remove circular references for gc, but what if
+#?? somebody is referencing it?
+	$self->removeAttributeNode ($node);
+    }
+}
+
+sub cloneNode
+{
+    my ($self, $deep) = @_;
+    my $node = $self->[_Doc]->createElement ($self->getTagName);
+
+    # Always clone the Attr nodes, even if $deep == 0
+    if (defined $self->[_A])
+    {
+	$node->[_A] = $self->[_A]->cloneNode (1);	# deep=1
+	$node->[_A]->setParentNode ($node);
+    }
+
+    $node->cloneChildren ($self, $deep);
+    $node;
+}
+
+sub getAttributes
+{
+    $_[0]->[_A] ||= XML::DOM::NamedNodeMap->new (Doc	=> $_[0]->[_Doc],
+						 Parent	=> $_[0]);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+# Added for convenience
+sub setTagName
+{
+    my ($self, $tagName) = @_;
+
+    croak new XML::DOM::DOMException (INVALID_CHARACTER_ERR, 
+				      "bad Element TagName [$tagName]")
+        unless XML::DOM::isValidName ($tagName);
+
+    $self->[_TagName] = $tagName;
+}
+
+sub isReadOnly
+{
+    0;
+}
+
+# Added for optimization.
+sub isElementNode
+{
+    1;
+}
+
+sub rejectChild
+{
+    my $t = $_[1]->getNodeType;
+
+    $t != TEXT_NODE
+    && $t != ENTITY_REFERENCE_NODE 
+    && $t != PROCESSING_INSTRUCTION_NODE
+    && $t != COMMENT_NODE
+    && $t != CDATA_SECTION_NODE
+    && $t != ELEMENT_NODE;
+}
+
+sub getDefaultAttrValue
+{
+    my ($self, $attr) = @_;
+    $self->[_Doc]->getDefaultAttrValue ($self->[_TagName], $attr);
+}
+
+sub dispose
+{
+    my $self = shift;
+
+    $self->[_A]->dispose if defined $self->[_A];
+    $self->SUPER::dispose;
+}
+
+sub setOwnerDocument
+{
+    my ($self, $doc) = @_;
+    $self->SUPER::setOwnerDocument ($doc);
+
+    $self->[_A]->setOwnerDocument ($doc) if defined $self->[_A];
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;    
+
+    my $name = $self->[_TagName];
+
+    $FILE->print ("<$name");
+
+    if (defined $self->[_A])
+    {
+	for my $att (@{$self->[_A]->getValues})
+	{
+	    # skip un-specified (default) Attr nodes
+	    if ($att->isSpecified)
+	    {
+		$FILE->print (" ");
+		$att->print ($FILE);
+	    }
+	}
+    }
+
+    my @kids = @{$self->[_C]};
+    if (@kids > 0)
+    {
+	$FILE->print (">");
+	for my $kid (@kids)
+	{
+	    $kid->print ($FILE);
+	}
+	$FILE->print ("</$name>");
+    }
+    else
+    {
+	my $style = &$XML::DOM::TagStyle ($name, $self);
+	if ($style == 0)
+	{
+	    $FILE->print ("/>");
+	}
+	elsif ($style == 1)
+	{
+	    $FILE->print ("></$name>");
+	}
+	else
+	{
+	    $FILE->print (" />");
+	}
+    }
+}
+
+sub check
+{
+    my ($self, $checker) = @_;
+    die "Usage: \$xml_dom_elem->check (\$checker)" unless $checker; 
+
+    $checker->InitDomElem;
+    $self->to_expat ($checker);
+    $checker->FinalDomElem;
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+
+    my $tag = $self->getTagName;
+    $iter->Start ($tag);
+
+    if (defined $self->[_A])
+    {
+	for my $attr ($self->[_A]->getValues)
+	{
+	    $iter->Attr ($tag, $attr->getName, $attr->getValue, $attr->isSpecified);
+	}
+    }
+
+    $iter->EndAttr;
+
+    for my $kid ($self->getChildNodes)
+    {
+	$kid->to_expat ($iter);
+    }
+
+    $iter->End;
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+
+    my $tag = $self->getTagName;
+
+    my @attr = ();
+    my $attrOrder;
+    my $attrDefaulted;
+
+    if (defined $self->[_A])
+    {
+	my @spec = ();		# names of specified attributes
+	my @unspec = ();	# names of defaulted attributes
+
+	for my $attr ($self->[_A]->getValues) 
+	{
+	    my $attrName = $attr->getName;
+	    push @attr, $attrName, $attr->getValue;
+	    if ($attr->isSpecified)
+	    {
+		push @spec, $attrName;
+	    }
+	    else
+	    {
+		push @unspec, $attrName;
+	    }
+	}
+	$attrOrder = [ @spec, @unspec ];
+	$attrDefaulted = @spec;
+    }
+    $doch->start_element (defined $attrOrder ? 
+			  { Name => $tag, 
+			    Attributes => { @attr },
+			    AttributeOrder => $attrOrder,
+			    Defaulted => $attrDefaulted
+			  } :
+			  { Name => $tag, 
+			    Attributes => { @attr } 
+			  }
+			 );
+
+    for my $kid ($self->getChildNodes)
+    {
+	$kid->_to_sax ($doch, $dtdh, $enth);
+    }
+
+    $doch->end_element ( { Name => $tag } );
+}
+
+######################################################################
+package XML::DOM::CharacterData;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Data", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+
+#
+# CharacterData nodes should never be created directly, only subclassed!
+#
+sub new
+{
+    my ($class, $doc, $data) = @_;
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_Data] = $data;
+    $self;
+}
+
+sub appendData
+{
+    my ($self, $data) = @_;
+
+    if ($XML::DOM::SafeMode)
+    {
+	croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+					  "node is ReadOnly")
+	    if $self->isReadOnly;
+    }
+    $self->[_Data] .= $data;
+}
+
+sub deleteData
+{
+    my ($self, $offset, $count) = @_;
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "bad offset [$offset]")
+	if ($offset < 0 || $offset >= length ($self->[_Data]));
+#?? DOM Spec says >, but >= makes more sense!
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "negative count [$count]")
+	if $count < 0;
+ 
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    substr ($self->[_Data], $offset, $count) = "";
+}
+
+sub getData
+{
+    $_[0]->[_Data];
+}
+
+sub getLength
+{
+    length $_[0]->[_Data];
+}
+
+sub insertData
+{
+    my ($self, $offset, $data) = @_;
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "bad offset [$offset]")
+	if ($offset < 0 || $offset >= length ($self->[_Data]));
+#?? DOM Spec says >, but >= makes more sense!
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    substr ($self->[_Data], $offset, 0) = $data;
+}
+
+sub replaceData
+{
+    my ($self, $offset, $count, $data) = @_;
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "bad offset [$offset]")
+	if ($offset < 0 || $offset >= length ($self->[_Data]));
+#?? DOM Spec says >, but >= makes more sense!
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "negative count [$count]")
+	if $count < 0;
+ 
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    substr ($self->[_Data], $offset, $count) = $data;
+}
+
+sub setData
+{
+    my ($self, $data) = @_;
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    $self->[_Data] = $data;
+}
+
+sub substringData
+{
+    my ($self, $offset, $count) = @_;
+    my $data = $self->[_Data];
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "bad offset [$offset]")
+	if ($offset < 0 || $offset >= length ($data));
+#?? DOM Spec says >, but >= makes more sense!
+
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "negative count [$count]")
+	if $count < 0;
+    
+    substr ($data, $offset, $count);
+}
+
+sub getNodeValue
+{
+    $_[0]->getData;
+}
+
+sub setNodeValue
+{
+    $_[0]->setData ($_[1]);
+}
+
+######################################################################
+package XML::DOM::CDATASection;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::CharacterData qw( :DEFAULT :Fields );
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("", "XML::DOM::CharacterData");
+}
+
+use XML::DOM::DOMException;
+
+sub getNodeName
+{
+    "#cdata-section";
+}
+
+sub getNodeType
+{
+    CDATA_SECTION_NODE;
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createCDATASection ($self->getData);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+    $FILE->print ("<![CDATA[");
+    $FILE->print (XML::DOM::encodeCDATA ($self->getData));
+    $FILE->print ("]]>");
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->CData ($self->getData);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $doch->start_cdata;
+    $doch->characters ( { Data => $self->getData } );
+    $doch->end_cdata;
+}
+
+######################################################################
+package XML::DOM::Comment;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::CharacterData qw( :DEFAULT :Fields );
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("", "XML::DOM::CharacterData");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+#?? setData - could check comment for double minus
+
+sub getNodeType
+{
+    COMMENT_NODE;
+}
+
+sub getNodeName
+{
+    "#comment";
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createComment ($self->getData);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    return 0 if $XML::DOM::IgnoreReadOnly;
+
+    my $pa = $_[0]->[_Parent];
+    defined ($pa) ? $pa->isReadOnly : 0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+    my $comment = XML::DOM::encodeComment ($self->[_Data]);
+
+    $FILE->print ("<!--$comment-->");
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->Comment ($self->getData);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $doch->comment ( { Data => $self->getData });
+}
+
+######################################################################
+package XML::DOM::Text;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::CharacterData qw( :DEFAULT :Fields );
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("", "XML::DOM::CharacterData");
+}
+
+use XML::DOM::DOMException;
+use Carp;
+
+sub getNodeType
+{
+    TEXT_NODE;
+}
+
+sub getNodeName
+{
+    "#text";
+}
+
+sub splitText
+{
+    my ($self, $offset) = @_;
+
+    my $data = $self->getData;
+    croak new XML::DOM::DOMException (INDEX_SIZE_ERR,
+				      "bad offset [$offset]")
+	if ($offset < 0 || $offset >= length ($data));
+#?? DOM Spec says >, but >= makes more sense!
+
+    croak new XML::DOM::DOMException (NO_MODIFICATION_ALLOWED_ERR,
+				      "node is ReadOnly")
+	if $self->isReadOnly;
+
+    my $rest = substr ($data, $offset);
+
+    $self->setData (substr ($data, 0, $offset));
+    my $node = $self->[_Doc]->createTextNode ($rest);
+
+    # insert new node after this node
+    $self->[_Parent]->insertBefore ($node, $self->getNextSibling);
+
+    $node;
+}
+
+sub cloneNode
+{
+    my $self = shift;
+    $self->[_Doc]->createTextNode ($self->getData);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+    $FILE->print (XML::DOM::encodeText ($self->getData, '<&>"'));
+}
+
+sub isTextNode
+{
+    1;
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->Char ($self->getData);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $doch->characters ( { Data => $self->getData } );
+}
+
+######################################################################
+package XML::DOM::XMLDecl;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Version Encoding Standalone", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+
+
+#------------------------------------------------------------
+# Extra method implementations
+
+# XMLDecl is not part of the DOM Spec
+sub new
+{
+    my ($class, $doc, $version, $encoding, $standalone) = @_;
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_Version] = $version if defined $version;
+    $self->[_Encoding] = $encoding if defined $encoding;
+    $self->[_Standalone] = $standalone if defined $standalone;
+
+    $self;
+}
+
+sub setVersion
+{
+    if (defined $_[1])
+    {
+	$_[0]->[_Version] = $_[1];
+    }
+    else
+    {
+	undef $_[0]->[_Version]; # was delete
+    }
+}
+
+sub getVersion
+{
+    $_[0]->[_Version];
+}
+
+sub setEncoding
+{
+    if (defined $_[1])
+    {
+	$_[0]->[_Encoding] = $_[1];
+    }
+    else
+    {
+	undef $_[0]->[_Encoding]; # was delete
+    }
+}
+
+sub getEncoding
+{
+    $_[0]->[_Encoding];
+}
+
+sub setStandalone
+{
+    if (defined $_[1])
+    {
+	$_[0]->[_Standalone] = $_[1];
+    }
+    else
+    {
+	undef $_[0]->[_Standalone]; # was delete
+    }
+}
+
+sub getStandalone
+{
+    $_[0]->[_Standalone];
+}
+
+sub getNodeType
+{
+    XML_DECL_NODE;
+}
+
+sub cloneNode
+{
+    my $self = shift;
+
+    new XML::DOM::XMLDecl ($self->[_Doc], $self->[_Version], 
+			   $self->[_Encoding], $self->[_Standalone]);
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+
+    my $version = $self->[_Version];
+    my $encoding = $self->[_Encoding];
+    my $standalone = $self->[_Standalone];
+    $standalone = ($standalone ? "yes" : "no") if defined $standalone;
+
+    $FILE->print ("<?xml");
+    $FILE->print (" version=\"$version\"")	 if defined $version;    
+    $FILE->print (" encoding=\"$encoding\"")	 if defined $encoding;
+    $FILE->print (" standalone=\"$standalone\"") if defined $standalone;
+    $FILE->print ("?>");
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+    $iter->XMLDecl ($self->getVersion, $self->getEncoding, $self->getStandalone);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+    $dtdh->xml_decl ( { Version => $self->getVersion, 
+			Encoding => $self->getEncoding, 
+			Standalone => $self->getStandalone } );
+}
+
+######################################################################
+package XML::DOM::DocumentFragment;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+
+sub new
+{
+    my ($class, $doc) = @_;
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_C] = new XML::DOM::NodeList;
+    $self;
+}
+
+sub getNodeType
+{
+    DOCUMENT_FRAGMENT_NODE;
+}
+
+sub getNodeName
+{
+    "#document-fragment";
+}
+
+sub cloneNode
+{
+    my ($self, $deep) = @_;
+    my $node = $self->[_Doc]->createDocumentFragment;
+
+    $node->cloneChildren ($self, $deep);
+    $node;
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+
+    for my $node (@{$self->[_C]})
+    {
+	$node->print ($FILE);
+    }
+}
+
+sub rejectChild
+{
+    my $t = $_[1]->getNodeType;
+
+    $t != TEXT_NODE
+	&& $t != ENTITY_REFERENCE_NODE 
+	&& $t != PROCESSING_INSTRUCTION_NODE
+	&& $t != COMMENT_NODE
+	&& $t != CDATA_SECTION_NODE
+	&& $t != ELEMENT_NODE;
+}
+
+sub isDocumentFragmentNode
+{
+    1;
+}
+
+######################################################################
+package XML::DOM::DocumentType;		# forward declaration
+######################################################################
+
+######################################################################
+package XML::DOM::Document;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    XML::DOM::def_fields ("Doctype XmlDecl", "XML::DOM::Node");
+}
+
+use Carp;
+use XML::DOM::NodeList;
+use XML::DOM::DOMException;
+
+sub new
+{
+    my ($class) = @_;
+    my $self = bless [], $class;
+
+    # keep Doc pointer, even though getOwnerDocument returns undef
+    $self->[_Doc] = $self;
+    $self->[_C] = new XML::DOM::NodeList;
+    $self;
+}
+
+sub getNodeType
+{
+    DOCUMENT_NODE;
+}
+
+sub getNodeName
+{
+    "#document";
+}
+
+#?? not sure about keeping a fixed order of these nodes....
+sub getDoctype
+{
+    $_[0]->[_Doctype];
+}
+
+sub getDocumentElement
+{
+    my ($self) = @_;
+    for my $kid (@{$self->[_C]})
+    {
+	return $kid if $kid->isElementNode;
+    }
+    undef;
+}
+
+sub getOwnerDocument
+{
+    undef;
+}
+
+sub getImplementation 
+{
+    $XML::DOM::DOMImplementation::Singleton;
+}
+
+#
+# Added extra parameters ($val, $specified) that are passed straight to the
+# Attr constructor
+# 
+sub createAttribute
+{
+    new XML::DOM::Attr (@_);
+}
+
+sub createCDATASection
+{
+    new XML::DOM::CDATASection (@_);
+}
+
+sub createComment
+{
+    new XML::DOM::Comment (@_);
+
+}
+
+sub createElement
+{
+    new XML::DOM::Element (@_);
+}
+
+sub createTextNode
+{
+    new XML::DOM::Text (@_);
+}
+
+sub createProcessingInstruction
+{
+    new XML::DOM::ProcessingInstruction (@_);
+}
+
+sub createEntityReference
+{
+    new XML::DOM::EntityReference (@_);
+}
+
+sub createDocumentFragment
+{
+    new XML::DOM::DocumentFragment (@_);
+}
+
+sub createDocumentType
+{
+    new XML::DOM::DocumentType (@_);
+}
+
+sub cloneNode
+{
+    my ($self, $deep) = @_;
+    my $node = new XML::DOM::Document;
+
+    $node->cloneChildren ($self, $deep);
+
+    my $xmlDecl = $self->[_XmlDecl];
+    $node->[_XmlDecl] = $xmlDecl->cloneNode ($deep) if defined $xmlDecl;
+
+    $node;
+}
+
+sub appendChild
+{
+    my ($self, $node) = @_;
+
+    # Extra check: make sure we don't end up with more than one Element.
+    # Don't worry about multiple DocType nodes, because DocumentFragment
+    # can't contain DocType nodes.
+
+    my @nodes = ($node);
+    @nodes = @{$node->[_C]}
+        if $node->getNodeType == DOCUMENT_FRAGMENT_NODE;
+    
+    my $elem = 0;
+    for my $n (@nodes)
+    {
+	$elem++ if $n->isElementNode;
+    }
+    
+    if ($elem > 0 && defined ($self->getDocumentElement))
+    {
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "document can have only one Element");
+    }
+    $self->SUPER::appendChild ($node);
+}
+
+sub insertBefore
+{
+    my ($self, $node, $refNode) = @_;
+
+    # Extra check: make sure sure we don't end up with more than 1 Elements.
+    # Don't worry about multiple DocType nodes, because DocumentFragment
+    # can't contain DocType nodes.
+
+    my @nodes = ($node);
+    @nodes = @{$node->[_C]}
+	if $node->getNodeType == DOCUMENT_FRAGMENT_NODE;
+    
+    my $elem = 0;
+    for my $n (@nodes)
+    {
+	$elem++ if $n->isElementNode;
+    }
+    
+    if ($elem > 0 && defined ($self->getDocumentElement))
+    {
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "document can have only one Element");
+    }
+    $self->SUPER::insertBefore ($node, $refNode);
+}
+
+sub replaceChild
+{
+    my ($self, $node, $refNode) = @_;
+
+    # Extra check: make sure sure we don't end up with more than 1 Elements.
+    # Don't worry about multiple DocType nodes, because DocumentFragment
+    # can't contain DocType nodes.
+
+    my @nodes = ($node);
+    @nodes = @{$node->[_C]}
+	if $node->getNodeType == DOCUMENT_FRAGMENT_NODE;
+    
+    my $elem = 0;
+    $elem-- if $refNode->isElementNode;
+
+    for my $n (@nodes)
+    {
+	$elem++ if $n->isElementNode;
+    }
+    
+    if ($elem > 0 && defined ($self->getDocumentElement))
+    {
+	croak new XML::DOM::DOMException (HIERARCHY_REQUEST_ERR,
+					  "document can have only one Element");
+    }
+    $self->SUPER::replaceChild ($node, $refNode);
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub isReadOnly
+{
+    0;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+
+    my $xmlDecl = $self->getXMLDecl;
+    if (defined $xmlDecl)
+    {
+	$xmlDecl->print ($FILE);
+	$FILE->print ("\x0A");
+    }
+
+    for my $node (@{$self->[_C]})
+    {
+	$node->print ($FILE);
+	$FILE->print ("\x0A");
+    }
+}
+
+sub setDoctype
+{
+    my ($self, $doctype) = @_;
+    my $oldDoctype = $self->[_Doctype];
+    if (defined $oldDoctype)
+    {
+	$self->replaceChild ($doctype, $oldDoctype);
+    }
+    else
+    {
+#?? before root element, but after XmlDecl !
+	$self->appendChild ($doctype);
+    }
+    $_[0]->[_Doctype] = $_[1];
+}
+
+sub removeDoctype
+{
+    my $self = shift;
+    my $doctype = $self->removeChild ($self->[_Doctype]);
+
+    undef $self->[_Doctype]; # was delete
+    $doctype;
+}
+
+sub rejectChild
+{
+    my $t = $_[1]->getNodeType;
+    $t != ELEMENT_NODE
+	&& $t != PROCESSING_INSTRUCTION_NODE
+	&& $t != COMMENT_NODE
+	&& $t != DOCUMENT_TYPE_NODE;
+}
+
+sub expandEntity
+{
+    my ($self, $ent, $param) = @_;
+    my $doctype = $self->getDoctype;
+
+    (defined $doctype) ? $doctype->expandEntity ($ent, $param) : undef;
+}
+
+sub getDefaultAttrValue
+{
+    my ($self, $elem, $attr) = @_;
+    
+    my $doctype = $self->getDoctype;
+
+    (defined $doctype) ? $doctype->getDefaultAttrValue ($elem, $attr) : undef;
+}
+
+sub getEntity
+{
+    my ($self, $entity) = @_;
+    
+    my $doctype = $self->getDoctype;
+
+    (defined $doctype) ? $doctype->getEntity ($entity) : undef;
+}
+
+sub dispose
+{
+    my $self = shift;
+
+    $self->[_XmlDecl]->dispose if defined $self->[_XmlDecl];
+    undef $self->[_XmlDecl]; # was delete
+    undef $self->[_Doctype]; # was delete
+    $self->SUPER::dispose;
+}
+
+sub setOwnerDocument
+{
+    # Do nothing, you can't change the owner document!
+#?? could throw exception...
+}
+
+sub getXMLDecl
+{
+    $_[0]->[_XmlDecl];
+}
+
+sub setXMLDecl
+{
+    $_[0]->[_XmlDecl] = $_[1];
+}
+
+sub createXMLDecl
+{
+    new XML::DOM::XMLDecl (@_);
+}
+
+sub createNotation
+{
+    new XML::DOM::Notation (@_);
+}
+
+sub createElementDecl
+{
+    new XML::DOM::ElementDecl (@_);
+}
+
+sub createAttlistDecl
+{
+    new XML::DOM::AttlistDecl (@_);
+}
+
+sub createEntity
+{
+    new XML::DOM::Entity (@_);
+}
+
+sub createChecker
+{
+    my $self = shift;
+    my $checker = XML::Checker->new;
+
+    $checker->Init;
+    my $doctype = $self->getDoctype;
+    $doctype->to_expat ($checker) if $doctype;
+    $checker->Final;
+
+    $checker;
+}
+
+sub check
+{
+    my ($self, $checker) = @_;
+    $checker ||= XML::Checker->new;
+
+    $self->to_expat ($checker);
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+
+    $iter->Init;
+
+    for my $kid ($self->getChildNodes)
+    {
+	$kid->to_expat ($iter);
+    }
+    $iter->Final;
+}
+
+sub check_sax
+{
+    my ($self, $checker) = @_;
+    $checker ||= XML::Checker->new;
+
+    $self->to_sax (Handler => $checker);
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+
+    $doch->start_document;
+
+    for my $kid ($self->getChildNodes)
+    {
+	$kid->_to_sax ($doch, $dtdh, $enth);
+    }
+    $doch->end_document;
+}
+
+######################################################################
+package XML::DOM::DocumentType;
+######################################################################
+use vars qw{ @ISA @EXPORT_OK %EXPORT_TAGS %HFIELDS };
+
+BEGIN
+{
+    import XML::DOM::Node qw( :DEFAULT :Fields );
+    import XML::DOM::Document qw( :Fields );
+    XML::DOM::def_fields ("Entities Notations Name SysId PubId Internal", "XML::DOM::Node");
+}
+
+use XML::DOM::DOMException;
+use XML::DOM::NamedNodeMap;
+
+sub new
+{
+    my $class = shift;
+    my $doc = shift;
+
+    my $self = bless [], $class;
+
+    $self->[_Doc] = $doc;
+    $self->[_ReadOnly] = 1;
+    $self->[_C] = new XML::DOM::NodeList;
+
+    $self->[_Entities] =  new XML::DOM::NamedNodeMap (Doc	=> $doc,
+						      Parent	=> $self,
+						      ReadOnly	=> 1);
+    $self->[_Notations] = new XML::DOM::NamedNodeMap (Doc	=> $doc,
+						      Parent	=> $self,
+						      ReadOnly	=> 1);
+    $self->setParams (@_);
+    $self;
+}
+
+sub getNodeType
+{
+    DOCUMENT_TYPE_NODE;
+}
+
+sub getNodeName
+{
+    $_[0]->[_Name];
+}
+
+sub getName
+{
+    $_[0]->[_Name];
+}
+
+sub getEntities
+{
+    $_[0]->[_Entities];
+}
+
+sub getNotations
+{
+    $_[0]->[_Notations];
+}
+
+sub setParentNode
+{
+    my ($self, $parent) = @_;
+    $self->SUPER::setParentNode ($parent);
+
+    $parent->[_Doctype] = $self 
+	if $parent->getNodeType == DOCUMENT_NODE;
+}
+
+sub cloneNode
+{
+    my ($self, $deep) = @_;
+
+    my $node = new XML::DOM::DocumentType ($self->[_Doc], $self->[_Name], 
+					   $self->[_SysId], $self->[_PubId], 
+					   $self->[_Internal]);
+
+#?? does it make sense to make a shallow copy?
+
+    # clone the NamedNodeMaps
+    $node->[_Entities] = $self->[_Entities]->cloneNode ($deep);
+
+    $node->[_Notations] = $self->[_Notations]->cloneNode ($deep);
+
+    $node->cloneChildren ($self, $deep);
+
+    $node;
+}
+
+#------------------------------------------------------------
+# Extra method implementations
+
+sub getSysId
+{
+    $_[0]->[_SysId];
+}
+
+sub getPubId
+{
+    $_[0]->[_PubId];
+}
+
+sub getInternal
+{
+    $_[0]->[_Internal];
+}
+
+sub setSysId
+{
+    $_[0]->[_SysId] = $_[1];
+}
+
+sub setPubId
+{
+    $_[0]->[_PubId] = $_[1];
+}
+
+sub setInternal
+{
+    $_[0]->[_Internal] = $_[1];
+}
+
+sub setName
+{
+    $_[0]->[_Name] = $_[1];
+}
+
+sub removeChildHoodMemories
+{
+    my ($self, $dontWipeReadOnly) = @_;
+
+    my $parent = $self->[_Parent];
+    if (defined $parent && $parent->getNodeType == DOCUMENT_NODE)
+    {
+	undef $parent->[_Doctype]; # was delete
+    }
+    $self->SUPER::removeChildHoodMemories;
+}
+
+sub dispose
+{
+    my $self = shift;
+
+    $self->[_Entities]->dispose;
+    $self->[_Notations]->dispose;
+    $self->SUPER::dispose;
+}
+
+sub setOwnerDocument
+{
+    my ($self, $doc) = @_;
+    $self->SUPER::setOwnerDocument ($doc);
+
+    $self->[_Entities]->setOwnerDocument ($doc);
+    $self->[_Notations]->setOwnerDocument ($doc);
+}
+
+sub expandEntity
+{
+    my ($self, $ent, $param) = @_;
+
+    my $kid = $self->[_Entities]->getNamedItem ($ent);
+    return $kid->getValue
+	if (defined ($kid) && $param == $kid->isParameterEntity);
+
+    undef;	# entity not found
+}
+
+sub getAttlistDecl
+{
+    my ($self, $elemName) = @_;
+    for my $kid (@{$_[0]->[_C]})
+    {
+	return $kid if ($kid->getNodeType == ATTLIST_DECL_NODE &&
+			$kid->getName eq $elemName);
+    }
+    undef;	# not found
+}
+
+sub getElementDecl
+{
+    my ($self, $elemName) = @_;
+    for my $kid (@{$_[0]->[_C]})
+    {
+	return $kid if ($kid->getNodeType == ELEMENT_DECL_NODE &&
+			$kid->getName eq $elemName);
+    }
+    undef;	# not found
+}
+
+sub addElementDecl
+{
+    my ($self, $name, $model, $hidden) = @_;
+    my $node = $self->getElementDecl ($name);
+
+#?? could warn
+    unless (defined $node)
+    {
+	$node = $self->[_Doc]->createElementDecl ($name, $model, $hidden);
+	$self->appendChild ($node);
+    }
+    $node;
+}
+
+sub addAttlistDecl
+{
+    my ($self, $name) = @_;
+    my $node = $self->getAttlistDecl ($name);
+
+    unless (defined $node)
+    {
+	$node = $self->[_Doc]->createAttlistDecl ($name);
+	$self->appendChild ($node);
+    }
+    $node;
+}
+
+sub addNotation
+{
+    my $self = shift;
+    my $node = $self->[_Doc]->createNotation (@_);
+    $self->[_Notations]->setNamedItem ($node);
+    $node;
+}
+
+sub addEntity
+{
+    my $self = shift;
+    my $node = $self->[_Doc]->createEntity (@_);
+
+    $self->[_Entities]->setNamedItem ($node);
+    $node;
+}
+
+# All AttDefs for a certain Element are merged into a single ATTLIST
+sub addAttDef
+{
+    my $self = shift;
+    my $elemName = shift;
+
+    # create the AttlistDecl if it doesn't exist yet
+    my $attListDecl = $self->addAttlistDecl ($elemName);
+    $attListDecl->addAttDef (@_);
+}
+
+sub getDefaultAttrValue
+{
+    my ($self, $elem, $attr) = @_;
+    my $elemNode = $self->getAttlistDecl ($elem);
+    (defined $elemNode) ? $elemNode->getDefaultAttrValue ($attr) : undef;
+}
+
+sub getEntity
+{
+    my ($self, $entity) = @_;
+    $self->[_Entities]->getNamedItem ($entity);
+}
+
+sub setParams
+{
+    my ($self, $name, $sysid, $pubid, $internal) = @_;
+
+    $self->[_Name] = $name;
+
+#?? not sure if we need to hold on to these...
+    $self->[_SysId] = $sysid if defined $sysid;
+    $self->[_PubId] = $pubid if defined $pubid;
+    $self->[_Internal] = $internal if defined $internal;
+
+    $self;
+}
+
+sub rejectChild
+{
+    # DOM Spec says: DocumentType -- no children
+    not $XML::DOM::IgnoreReadOnly;
+}
+
+sub print
+{
+    my ($self, $FILE) = @_;
+
+    my $name = $self->[_Name];
+
+    my $sysId = $self->[_SysId];
+    my $pubId = $self->[_PubId];
+
+    $FILE->print ("<!DOCTYPE $name");
+    if (defined $pubId)
+    {
+	$FILE->print (" PUBLIC \"$pubId\" \"$sysId\"");
+    }
+    elsif (defined $sysId)
+    {
+	$FILE->print (" SYSTEM \"$sysId\"");
+    }
+
+    my @entities = @{$self->[_Entities]->getValues};
+    my @notations = @{$self->[_Notations]->getValues};
+    my @kids = @{$self->[_C]};
+
+    if (@entities || @notations || @kids)
+    {
+	$FILE->print (" [\x0A");
+
+	for my $kid (@entities)
+	{
+	    next if $kid->[_Hidden];
+
+	    $FILE->print (" ");
+	    $kid->print ($FILE);
+	    $FILE->print ("\x0A");
+	}
+
+	for my $kid (@notations)
+	{
+	    next if $kid->[_Hidden];
+
+	    $FILE->print (" ");
+	    $kid->print ($FILE);
+	    $FILE->print ("\x0A");
+	}
+
+	for my $kid (@kids)
+	{
+	    next if $kid->[_Hidden];
+
+	    $FILE->print (" ");
+	    $kid->print ($FILE);
+	    $FILE->print ("\x0A");
+	}
+	$FILE->print ("]");
+    }
+    $FILE->print (">");
+}
+
+sub to_expat
+{
+    my ($self, $iter) = @_;
+
+    $iter->Doctype ($self->getName, $self->getSysId, $self->getPubId, $self->getInternal);
+
+    for my $ent ($self->getEntities->getValues)
+    {
+	next if $ent->[_Hidden];
+	$ent->to_expat ($iter);
+    }
+
+    for my $nota ($self->getNotations->getValues)
+    {
+	next if $nota->[_Hidden];
+	$nota->to_expat ($iter);
+    }
+
+    for my $kid ($self->getChildNodes)
+    {
+	next if $kid->[_Hidden];
+	$kid->to_expat ($iter);
+    }
+}
+
+sub _to_sax
+{
+    my ($self, $doch, $dtdh, $enth) = @_;
+
+    $dtdh->doctype_decl ( { Name => $self->getName, 
+			    SystemId => $self->getSysId, 
+			    PublicId => $self->getPubId, 
+			    Internal => $self->getInternal });
+
+    for my $ent ($self->getEntities->getValues)
+    {
+	next if $ent->[_Hidden];
+	$ent->_to_sax ($doch, $dtdh, $enth);
+    }
+
+    for my $nota ($self->getNotations->getValues)
+    {
+	next if $nota->[_Hidden];
+	$nota->_to_sax ($doch, $dtdh, $enth);
+    }
+
+    for my $kid ($self->getChildNodes)
+    {
+	next if $kid->[_Hidden];
+	$kid->_to_sax ($doch, $dtdh, $enth);
+    }
+}
+
+######################################################################
+package XML::DOM::Parser;
+######################################################################
+use vars qw ( @ISA );
+@ISA = qw( XML::Parser );
+
+sub new
+{
+    my ($class, %args) = @_;
+
+    $args{Style} = 'XML::Parser::Dom';
+    $class->SUPER::new (%args);
+}
+
+# This method needed to be overriden so we can restore some global 
+# variables when an exception is thrown
+sub parse
+{
+    my $self = shift;
+
+    local $XML::Parser::Dom::_DP_doc;
+    local $XML::Parser::Dom::_DP_elem;
+    local $XML::Parser::Dom::_DP_doctype;
+    local $XML::Parser::Dom::_DP_in_prolog;
+    local $XML::Parser::Dom::_DP_end_doc;
+    local $XML::Parser::Dom::_DP_saw_doctype;
+    local $XML::Parser::Dom::_DP_in_CDATA;
+    local $XML::Parser::Dom::_DP_keep_CDATA;
+    local $XML::Parser::Dom::_DP_last_text;
+
+
+    # Temporarily disable checks that Expat already does (for performance)
+    local $XML::DOM::SafeMode = 0;
+    # Temporarily disable ReadOnly checks
+    local $XML::DOM::IgnoreReadOnly = 1;
+
+    my $ret;
+    eval {
+	$ret = $self->SUPER::parse (@_);
+    };
+    my $err = $@;
+
+    if ($err)
+    {
+	my $doc = $XML::Parser::Dom::_DP_doc;
+	if ($doc)
+	{
+	    $doc->dispose;
+	}
+	die $err;
+    }
+
+    $ret;
+}
+
+my $LWP_USER_AGENT;
+sub set_LWP_UserAgent
+{
+    $LWP_USER_AGENT = shift;
+}
+
+sub parsefile
+{
+    my $self = shift;
+    my $url = shift;
+
+    # Any other URL schemes?
+    if ($url =~ /^(https?|ftp|wais|gopher|file):/)
+    {
+	# Read the file from the web with LWP.
+	#
+	# Note that we read in the entire file, which may not be ideal
+	# for large files. LWP::UserAgent also provides a callback style
+	# request, which we could convert to a stream with a fork()...
+
+	my $result;
+	eval
+	{
+	    use LWP::UserAgent;
+
+	    my $ua = $self->{LWP_UserAgent};
+	    unless (defined $ua)
+	    {
+		unless (defined $LWP_USER_AGENT)
+		{
+		    $LWP_USER_AGENT = LWP::UserAgent->new;
+
+		    # Load proxy settings from environment variables, i.e.:
+		    # http_proxy, ftp_proxy, no_proxy etc. (see LWP::UserAgent(3))
+		    # You need these to go thru firewalls.
+		    $LWP_USER_AGENT->env_proxy;
+		}
+		$ua = $LWP_USER_AGENT;
+	    }
+	    my $req = new HTTP::Request 'GET', $url;
+	    my $response = $ua->request ($req);
+
+	    # Parse the result of the HTTP request
+	    $result = $self->parse ($response->content, @_);
+	};
+	if ($@)
+	{
+	    die "Couldn't parsefile [$url] with LWP: $@";
+	}
+	return $result;
+    }
+    else
+    {
+	return $self->SUPER::parsefile ($url, @_);
+    }
+}
+
+######################################################################
+package XML::Parser::Dom;
+######################################################################
+
+BEGIN
+{
+    import XML::DOM::Node qw( :Fields );
+    import XML::DOM::CharacterData qw( :Fields );
+}
+
+use vars qw( $_DP_doc
+	     $_DP_elem
+	     $_DP_doctype
+	     $_DP_in_prolog
+	     $_DP_end_doc
+	     $_DP_saw_doctype
+	     $_DP_in_CDATA
+	     $_DP_keep_CDATA
+	     $_DP_last_text
+	     $_DP_level
+	     $_DP_expand_pent
+	   );
+
+# This adds a new Style to the XML::Parser class.
+# From now on you can say: $parser = new XML::Parser ('Style' => 'Dom' );
+# but that is *NOT* how a regular user should use it!
+$XML::Parser::Built_In_Styles{Dom} = 1;
+
+sub Init
+{
+    $_DP_elem = $_DP_doc = new XML::DOM::Document();
+    $_DP_doctype = new XML::DOM::DocumentType ($_DP_doc);
+    $_DP_doc->setDoctype ($_DP_doctype);
+    $_DP_keep_CDATA = $_[0]->{KeepCDATA};
+
+    # Prepare for document prolog
+    $_DP_in_prolog = 1;
+
+    # We haven't passed the root element yet
+    $_DP_end_doc = 0;
+
+    # Expand parameter entities in the DTD by default
+
+    $_DP_expand_pent = defined $_[0]->{ExpandParamEnt} ? 
+					$_[0]->{ExpandParamEnt} : 1;
+    if ($_DP_expand_pent)
+    {
+	$_[0]->{DOM_Entity} = {};
+    }
+
+    $_DP_level = 0;
+
+    undef $_DP_last_text;
+}
+
+sub Final
+{
+    unless ($_DP_saw_doctype)
+    {
+	my $doctype = $_DP_doc->removeDoctype;
+	$doctype->dispose;
+    }
+    $_DP_doc;
+}
+
+sub Char
+{
+    my $str = $_[1];
+
+    if ($_DP_in_CDATA && $_DP_keep_CDATA)
+    {
+	undef $_DP_last_text;
+	# Merge text with previous node if possible
+	$_DP_elem->addCDATA ($str);
+    }
+    else
+    {
+	# Merge text with previous node if possible
+	# Used to be:	$expat->{DOM_Element}->addText ($str);
+	if ($_DP_last_text)
+	{
+	    $_DP_last_text->[_Data] .= $str;
+	}
+	else
+	{
+	    $_DP_last_text = $_DP_doc->createTextNode ($str);
+	    $_DP_last_text->[_Parent] = $_DP_elem;
+	    push @{$_DP_elem->[_C]}, $_DP_last_text;
+	}
+    }
+}
+
+sub Start
+{
+    my ($expat, $elem, @attr) = @_;
+    my $parent = $_DP_elem;
+    my $doc = $_DP_doc;
+    
+    if ($parent == $doc)
+    {
+	# End of document prolog, i.e. start of first Element
+	$_DP_in_prolog = 0;
+    }
+    
+    undef $_DP_last_text;
+    my $node = $doc->createElement ($elem);
+    $_DP_elem = $node;
+    $parent->appendChild ($node);
+    
+    my $n = @attr;
+    return unless $n;
+
+    # Add attributes
+    my $first_default = $expat->specified_attr;
+    my $i = 0;
+    while ($i < $n)
+    {
+	my $specified = $i < $first_default;
+	my $name = $attr[$i++];
+	undef $_DP_last_text;
+	my $attr = $doc->createAttribute ($name, $attr[$i++], $specified);
+	$node->setAttributeNode ($attr);
+    }
+}
+
+sub End
+{
+    $_DP_elem = $_DP_elem->[_Parent];
+    undef $_DP_last_text;
+
+    # Check for end of root element
+    $_DP_end_doc = 1 if ($_DP_elem == $_DP_doc);
+}
+
+# Called at end of file, i.e. whitespace following last closing tag
+# Also for Entity references
+# May also be called at other times...
+sub Default
+{
+    my ($expat, $str) = @_;
+
+#    shift; deb ("Default", @_);
+
+    if ($_DP_in_prolog)	# still processing Document prolog...
+    {
+#?? could try to store this text later
+#?? I've only seen whitespace here so far
+    }
+    elsif (!$_DP_end_doc)	# ignore whitespace at end of Document
+    {
+#	if ($expat->{NoExpand})
+#	{
+	    # Got a TextDecl (<?xml ...?>) from an external entity here once
+
+	    # create non-parameter entity reference, correct?
+            return unless $str =~ s!^&!!;
+            return unless $str =~ s!;$!!;
+	    $_DP_elem->appendChild (
+		   $_DP_doc->createEntityReference ($str,0,$expat->{NoExpand}));
+	    undef $_DP_last_text;
+#	}
+#	else
+#	{
+#	    $expat->{DOM_Element}->addText ($str);
+#	}
+    }
+}
+
+# XML::Parser 2.19 added support for CdataStart and CdataEnd handlers
+# If they are not defined, the Default handler is called instead
+# with the text "<![CDATA[" and "]]"
+sub CdataStart
+{
+    $_DP_in_CDATA = 1;
+}
+
+sub CdataEnd
+{
+    $_DP_in_CDATA = 0;
+}
+
+my $START_MARKER = "__DOM__START__ENTITY__";
+my $END_MARKER = "__DOM__END__ENTITY__";
+
+sub Comment
+{
+    undef $_DP_last_text;
+
+    # These comments were inserted by ExternEnt handler
+    if ($_[1] =~ /(?:($START_MARKER)|($END_MARKER))/)
+    {
+	if ($1)	 # START
+	{
+	    $_DP_level++;
+	}
+	else
+	{
+	    $_DP_level--;
+	}
+    }
+    else
+    {
+	my $comment = $_DP_doc->createComment ($_[1]);
+	$_DP_elem->appendChild ($comment);
+    }
+}
+
+sub deb
+{
+#    return;
+
+    my $name = shift;
+    print "$name (" . join(",", map {defined($_)?$_ : "(undef)"} @_) . ")\n";
+}
+
+sub Doctype
+{
+    my $expat = shift;
+#    deb ("Doctype", @_);
+
+    $_DP_doctype->setParams (@_);
+    $_DP_saw_doctype = 1;
+}
+
+sub Attlist
+{
+    my $expat = shift;
+#    deb ("Attlist", @_);
+
+    $_[5] = "Hidden" unless $_DP_expand_pent || $_DP_level == 0;
+    $_DP_doctype->addAttDef (@_);
+}
+
+sub XMLDecl
+{
+    my $expat = shift;
+#    deb ("XMLDecl", @_);
+
+    undef $_DP_last_text;
+    $_DP_doc->setXMLDecl (new XML::DOM::XMLDecl ($_DP_doc, @_));
+}
+
+sub Entity
+{
+    my $expat = shift;
+#    deb ("Entity", @_);
+    
+    # check to see if Parameter Entity
+    if ($_[5])
+    {
+
+	if (defined $_[2])	# was sysid specified?
+	{
+	    # Store the Entity mapping for use in ExternEnt
+	    if (exists $expat->{DOM_Entity}->{$_[2]})
+	    {
+		# If this ever happens, the name of entity may be the wrong one
+		# when writing out the Document.
+		XML::DOM::warning ("Entity $_[2] is known as %$_[0] and %" .
+				   $expat->{DOM_Entity}->{$_[2]});
+	    }
+	    else
+	    {
+		$expat->{DOM_Entity}->{$_[2]} = $_[0];
+	    }
+	    #?? remove this block when XML::Parser has better support
+	}
+    }
+
+    # no value on things with sysId
+    if (defined $_[2] && defined $_[1])
+    {
+        # print STDERR "XML::DOM Warning $_[0] had both value($_[1]) And SYSId ($_[2]), removing value.\n";
+        $_[1] = undef;
+    }
+
+    undef $_DP_last_text;
+
+    $_[6] = "Hidden" unless $_DP_expand_pent || $_DP_level == 0;
+    $_DP_doctype->addEntity (@_);
+}
+
+#
+# Unparsed is called when it encounters e.g:
+#
+#   <!ENTITY logo SYSTEM "http://server/logo.gif" NDATA gif>
+#
+sub Unparsed
+{
+    Entity (@_);	# same as regular ENTITY, as far as DOM is concerned
+}
+
+sub Element
+{
+    shift;
+#    deb ("Element", @_);
+
+    # put in to convert XML::Parser::ContentModel object to string
+    # ($_[1] used to be a string in XML::Parser 2.27 and
+    # dom_attr.t fails if we don't stringify here)
+    $_[1] = "$_[1]";
+
+    undef $_DP_last_text;
+    push @_, "Hidden" unless $_DP_expand_pent || $_DP_level == 0;
+    $_DP_doctype->addElementDecl (@_);
+}
+
+sub Notation
+{
+    shift;
+#    deb ("Notation", @_);
+
+    undef $_DP_last_text;
+    $_[4] = "Hidden" unless $_DP_expand_pent || $_DP_level == 0;
+    $_DP_doctype->addNotation (@_);
+}
+
+sub Proc
+{
+    shift;
+#    deb ("Proc", @_);
+
+    undef $_DP_last_text;
+    push @_, "Hidden" unless $_DP_expand_pent || $_DP_level == 0;
+    $_DP_elem->appendChild ($_DP_doc->createProcessingInstruction (@_));
+}
+
+#
+# ExternEnt is called when an external entity, such as:
+#
+#	<!ENTITY externalEntity PUBLIC "-//Enno//TEXT Enno's description//EN" 
+#	                        "http://server/descr.txt">
+#
+# is referenced in the document, e.g. with: &externalEntity;
+# If ExternEnt is not specified, the entity reference is passed to the Default
+# handler as e.g. "&externalEntity;", where an EntityReference object is added.
+#
+# Also for %externalEntity; references in the DTD itself.
+#
+# It can also be called when XML::Parser parses the DOCTYPE header
+# (just before calling the DocType handler), when it contains a
+# reference like "docbook.dtd" below:
+#
+#    <!DOCTYPE book PUBLIC "-//Norman Walsh//DTD DocBk XML V3.1.3//EN" 
+#	"docbook.dtd" [
+#     ... rest of DTD ...
+#
+sub ExternEnt
+{
+    my ($expat, $base, $sysid, $pubid) = @_;
+#    deb ("ExternEnt", @_);
+
+    # ?? (tjmather) i think there is a problem here
+    # with XML::Parser > 2.27 since file_ext_ent_handler
+    # now returns a IO::File object instead of a content string
+
+    # Invoke XML::Parser's default ExternEnt handler
+    my $content;
+    if ($XML::Parser::have_LWP)
+    {
+	$content = XML::Parser::lwp_ext_ent_handler (@_);
+    }
+    else
+    {
+	$content = XML::Parser::file_ext_ent_handler (@_);
+    }
+
+    if ($_DP_expand_pent)
+    {
+	return $content;
+    }
+    else
+    {
+	my $entname = $expat->{DOM_Entity}->{$sysid};
+	if (defined $entname)
+	{
+	    $_DP_doctype->appendChild ($_DP_doc->createEntityReference ($entname, 1, $expat->{NoExpand}));
+            # Wrap the contents in special comments, so we know when we reach the
+	    # end of parsing the entity. This way we can omit the contents from
+	    # the DTD, when ExpandParamEnt is set to 0.
+     
+	    return "<!-- $START_MARKER sysid=[$sysid] -->" .
+		$content . "<!-- $END_MARKER sysid=[$sysid] -->";
+	}
+	else
+	{
+	    # We either read the entity ref'd by the system id in the 
+	    # <!DOCTYPE> header, or the entity was undefined.
+	    # In either case, don't bother with maintaining the entity
+	    # reference, just expand the contents.
+	    return "<!-- $START_MARKER sysid=[DTD] -->" .
+		$content . "<!-- $END_MARKER sysid=[DTD] -->";
+	}
+    }
+}
+
+1; # module return code
+
+__END__
+
+=head1 NAME
+
+XML::DOM - A perl module for building DOM Level 1 compliant document structures
+
+=head1 SYNOPSIS
+
+ use XML::DOM;
+
+ my $parser = new XML::DOM::Parser;
+ my $doc = $parser->parsefile ("file.xml");
+
+ # print all HREF attributes of all CODEBASE elements
+ my $nodes = $doc->getElementsByTagName ("CODEBASE");
+ my $n = $nodes->getLength;
+
+ for (my $i = 0; $i < $n; $i++)
+ {
+     my $node = $nodes->item ($i);
+     my $href = $node->getAttributeNode ("HREF");
+     print $href->getValue . "\n";
+ }
+
+ # Print doc file
+ $doc->printToFile ("out.xml");
+
+ # Print to string
+ print $doc->toString;
+
+ # Avoid memory leaks - cleanup circular references for garbage collection
+ $doc->dispose;
+
+=head1 DESCRIPTION
+
+This module extends the XML::Parser module by Clark Cooper. 
+The XML::Parser module is built on top of XML::Parser::Expat, 
+which is a lower level interface to James Clark's expat library.
+
+XML::DOM::Parser is derived from XML::Parser. It parses XML strings or files
+and builds a data structure that conforms to the API of the Document Object 
+Model as described at http://www.w3.org/TR/REC-DOM-Level-1.
+See the XML::Parser manpage for other available features of the 
+XML::DOM::Parser class. 
+Note that the 'Style' property should not be used (it is set internally.)
+
+The XML::Parser I<NoExpand> option is more or less supported, in that it will
+generate EntityReference objects whenever an entity reference is encountered
+in character data. I'm not sure how useful this is. Any comments are welcome.
+
+As described in the synopsis, when you create an XML::DOM::Parser object, 
+the parse and parsefile methods create an I<XML::DOM::Document> object
+from the specified input. This Document object can then be examined, modified and
+written back out to a file or converted to a string.
+
+When using XML::DOM with XML::Parser version 2.19 and up, setting the 
+XML::DOM::Parser option I<KeepCDATA> to 1 will store CDATASections in
+CDATASection nodes, instead of converting them to Text nodes.
+Subsequent CDATASection nodes will be merged into one. Let me know if this
+is a problem.
+
+When using XML::Parser 2.27 and above, you can suppress expansion of
+parameter entity references (e.g. %pent;) in the DTD, by setting I<ParseParamEnt>
+to 1 and I<ExpandParamEnt> to 0. See L<Hidden Nodes|/_Hidden_Nodes_> for details.
+
+A Document has a tree structure consisting of I<Node> objects. A Node may contain
+other nodes, depending on its type.
+A Document may have Element, Text, Comment, and CDATASection nodes. 
+Element nodes may have Attr, Element, Text, Comment, and CDATASection nodes. 
+The other nodes may not have any child nodes. 
+
+This module adds several node types that are not part of the DOM spec (yet.)
+These are: ElementDecl (for <!ELEMENT ...> declarations), AttlistDecl (for
+<!ATTLIST ...> declarations), XMLDecl (for <?xml ...?> declarations) and AttDef
+(for attribute definitions in an AttlistDecl.)
+
+=head1 XML::DOM Classes
+
+The XML::DOM module stores XML documents in a tree structure with a root node
+of type XML::DOM::Document. Different nodes in tree represent different
+parts of the XML file. The DOM Level 1 Specification defines the following
+node types:
+
+=over 4
+
+=item * L<XML::DOM::Node> - Super class of all node types
+
+=item * L<XML::DOM::Document> - The root of the XML document
+
+=item * L<XML::DOM::DocumentType> - Describes the document structure: <!DOCTYPE root [ ... ]>
+
+=item * L<XML::DOM::Element> - An XML element: <elem attr="val"> ... </elem>
+
+=item * L<XML::DOM::Attr> - An XML element attribute: name="value"
+
+=item * L<XML::DOM::CharacterData> - Super class of Text, Comment and CDATASection
+
+=item * L<XML::DOM::Text> - Text in an XML element
+
+=item * L<XML::DOM::CDATASection> - Escaped block of text: <![CDATA[ text ]]>
+
+=item * L<XML::DOM::Comment> - An XML comment: <!-- comment -->
+
+=item * L<XML::DOM::EntityReference> - Refers to an ENTITY: &ent; or %ent;
+
+=item * L<XML::DOM::Entity> - An ENTITY definition: <!ENTITY ...>
+
+=item * L<XML::DOM::ProcessingInstruction> - <?PI target>
+
+=item * L<XML::DOM::DocumentFragment> - Lightweight node for cut & paste
+
+=item * L<XML::DOM::Notation> - An NOTATION definition: <!NOTATION ...>
+
+=back
+
+In addition, the XML::DOM module contains the following nodes that are not part 
+of the DOM Level 1 Specification:
+
+=over 4
+
+=item * L<XML::DOM::ElementDecl> - Defines an element: <!ELEMENT ...>
+
+=item * L<XML::DOM::AttlistDecl> - Defines one or more attributes in an <!ATTLIST ...>
+
+=item * L<XML::DOM::AttDef> - Defines one attribute in an <!ATTLIST ...>
+
+=item * L<XML::DOM::XMLDecl> - An XML declaration: <?xml version="1.0" ...>
+
+=back
+
+Other classes that are part of the DOM Level 1 Spec:
+
+=over 4
+
+=item * L<XML::DOM::Implementation> - Provides information about this implementation. Currently it doesn't do much.
+
+=item * L<XML::DOM::NodeList> - Used internally to store a node's child nodes. Also returned by getElementsByTagName.
+
+=item * L<XML::DOM::NamedNodeMap> - Used internally to store an element's attributes.
+
+=back
+
+Other classes that are not part of the DOM Level 1 Spec:
+
+=over 4
+
+=item * L<XML::DOM::Parser> - An non-validating XML parser that creates XML::DOM::Documents
+
+=item * L<XML::DOM::ValParser> - A validating XML parser that creates XML::DOM::Documents. It uses L<XML::Checker> to check against the DocumentType (DTD)
+
+=item * L<XML::Handler::BuildDOM> - A PerlSAX handler that creates XML::DOM::Documents.
+
+=back
+
+=head1 XML::DOM package
+
+=over 4
+
+=item Constant definitions
+
+The following predefined constants indicate which type of node it is.
+
+=back
+
+ UNKNOWN_NODE (0)                The node type is unknown (not part of DOM)
+
+ ELEMENT_NODE (1)                The node is an Element.
+ ATTRIBUTE_NODE (2)              The node is an Attr.
+ TEXT_NODE (3)                   The node is a Text node.
+ CDATA_SECTION_NODE (4)          The node is a CDATASection.
+ ENTITY_REFERENCE_NODE (5)       The node is an EntityReference.
+ ENTITY_NODE (6)                 The node is an Entity.
+ PROCESSING_INSTRUCTION_NODE (7) The node is a ProcessingInstruction.
+ COMMENT_NODE (8)                The node is a Comment.
+ DOCUMENT_NODE (9)               The node is a Document.
+ DOCUMENT_TYPE_NODE (10)         The node is a DocumentType.
+ DOCUMENT_FRAGMENT_NODE (11)     The node is a DocumentFragment.
+ NOTATION_NODE (12)              The node is a Notation.
+
+ ELEMENT_DECL_NODE (13)		 The node is an ElementDecl (not part of DOM)
+ ATT_DEF_NODE (14)		 The node is an AttDef (not part of DOM)
+ XML_DECL_NODE (15)		 The node is an XMLDecl (not part of DOM)
+ ATTLIST_DECL_NODE (16)		 The node is an AttlistDecl (not part of DOM)
+
+ Usage:
+
+   if ($node->getNodeType == ELEMENT_NODE)
+   {
+       print "It's an Element";
+   }
+
+B<Not In DOM Spec>: The DOM Spec does not mention UNKNOWN_NODE and, 
+quite frankly, you should never encounter it. The last 4 node types were added
+to support the 4 added node classes.
+
+=head2 Global Variables
+
+=over 4
+
+=item $VERSION
+
+The variable $XML::DOM::VERSION contains the version number of this 
+implementation, e.g. "1.43".
+
+=back
+
+=head2 METHODS
+
+These methods are not part of the DOM Level 1 Specification.
+
+=over 4
+
+=item getIgnoreReadOnly and ignoreReadOnly (readOnly)
+
+The DOM Level 1 Spec does not allow you to edit certain sections of the document,
+e.g. the DocumentType, so by default this implementation throws DOMExceptions
+(i.e. NO_MODIFICATION_ALLOWED_ERR) when you try to edit a readonly node. 
+These readonly checks can be disabled by (temporarily) setting the global 
+IgnoreReadOnly flag.
+
+The ignoreReadOnly method sets the global IgnoreReadOnly flag and returns its
+previous value. The getIgnoreReadOnly method simply returns its current value.
+
+ my $oldIgnore = XML::DOM::ignoreReadOnly (1);
+ eval {
+ ... do whatever you want, catching any other exceptions ...
+ };
+ XML::DOM::ignoreReadOnly ($oldIgnore);     # restore previous value
+
+Another way to do it, using a local variable:
+
+ { # start new scope
+    local $XML::DOM::IgnoreReadOnly = 1;
+    ... do whatever you want, don't worry about exceptions ...
+ } # end of scope ($IgnoreReadOnly is set back to its previous value)
+    
+
+=item isValidName (name)
+
+Whether the specified name is a valid "Name" as specified in the XML spec.
+Characters with Unicode values > 127 are now also supported.
+
+=item getAllowReservedNames and allowReservedNames (boolean)
+
+The first method returns whether reserved names are allowed. 
+The second takes a boolean argument and sets whether reserved names are allowed.
+The initial value is 1 (i.e. allow reserved names.)
+
+The XML spec states that "Names" starting with (X|x)(M|m)(L|l)
+are reserved for future use. (Amusingly enough, the XML version of the XML spec
+(REC-xml-19980210.xml) breaks that very rule by defining an ENTITY with the name 
+'xmlpio'.)
+A "Name" in this context means the Name token as found in the BNF rules in the
+XML spec.
+
+XML::DOM only checks for errors when you modify the DOM tree, not when the
+DOM tree is built by the XML::DOM::Parser.
+
+=item setTagCompression (funcref)
+
+There are 3 possible styles for printing empty Element tags:
+
+=over 4
+
+=item Style 0
+
+ <empty/> or <empty attr="val"/>
+
+XML::DOM uses this style by default for all Elements.
+
+=item Style 1
+
+  <empty></empty> or <empty attr="val"></empty>
+
+=item Style 2
+
+  <empty /> or <empty attr="val" />
+
+This style is sometimes desired when using XHTML. 
+(Note the extra space before the slash "/")
+See L<http://www.w3.org/TR/xhtml1> Appendix C for more details.
+
+=back
+
+By default XML::DOM compresses all empty Element tags (style 0.)
+You can control which style is used for a particular Element by calling
+XML::DOM::setTagCompression with a reference to a function that takes
+2 arguments. The first is the tag name of the Element, the second is the
+XML::DOM::Element that is being printed. 
+The function should return 0, 1 or 2 to indicate which style should be used to
+print the empty tag. E.g.
+
+ XML::DOM::setTagCompression (\&my_tag_compression);
+
+ sub my_tag_compression
+ {
+    my ($tag, $elem) = @_;
+
+    # Print empty br, hr and img tags like this: <br />
+    return 2 if $tag =~ /^(br|hr|img)$/;
+
+    # Print other empty tags like this: <empty></empty>
+    return 1;
+ }
+
+=back
+
+=head1 IMPLEMENTATION DETAILS
+
+=over 4
+
+=item * Perl Mappings
+
+The value undef was used when the DOM Spec said null.
+
+The DOM Spec says: Applications must encode DOMString using UTF-16 (defined in 
+Appendix C.3 of [UNICODE] and Amendment 1 of [ISO-10646]).
+In this implementation we use plain old Perl strings encoded in UTF-8 instead of
+UTF-16.
+
+=item * Text and CDATASection nodes
+
+The Expat parser expands EntityReferences and CDataSection sections to 
+raw strings and does not indicate where it was found. 
+This implementation does therefore convert both to Text nodes at parse time.
+CDATASection and EntityReference nodes that are added to an existing Document 
+(by the user) will be preserved.
+
+Also, subsequent Text nodes are always merged at parse time. Text nodes that are 
+added later can be merged with the normalize method. Consider using the addText
+method when adding Text nodes.
+
+=item * Printing and toString
+
+When printing (and converting an XML Document to a string) the strings have to 
+encoded differently depending on where they occur. E.g. in a CDATASection all 
+substrings are allowed except for "]]>". In regular text, certain characters are
+not allowed, e.g. ">" has to be converted to "&gt;". 
+These routines should be verified by someone who knows the details.
+
+=item * Quotes
+
+Certain sections in XML are quoted, like attribute values in an Element.
+XML::Parser strips these quotes and the print methods in this implementation 
+always uses double quotes, so when parsing and printing a document, single quotes
+may be converted to double quotes. The default value of an attribute definition
+(AttDef) in an AttlistDecl, however, will maintain its quotes.
+
+=item * AttlistDecl
+
+Attribute declarations for a certain Element are always merged into a single
+AttlistDecl object.
+
+=item * Comments
+
+Comments in the DOCTYPE section are not kept in the right place. They will become
+child nodes of the Document.
+
+=item * Hidden Nodes
+
+Previous versions of XML::DOM would expand parameter entity references
+(like B<%pent;>), so when printing the DTD, it would print the contents
+of the external entity, instead of the parameter entity reference.
+With this release (1.27), you can prevent this by setting the XML::DOM::Parser
+options ParseParamEnt => 1 and ExpandParamEnt => 0.
+
+When it is parsing the contents of the external entities, it *DOES* still add
+the nodes to the DocumentType, but it marks these nodes by setting
+the 'Hidden' property. In addition, it adds an EntityReference node to the
+DocumentType node.
+
+When printing the DocumentType node (or when using to_expat() or to_sax()), 
+the 'Hidden' nodes are suppressed, so you will see the parameter entity
+reference instead of the contents of the external entities. See test case
+t/dom_extent.t for an example.
+
+The reason for adding the 'Hidden' nodes to the DocumentType node, is that
+the nodes may contain <!ENTITY> definitions that are referenced further
+in the document. (Simply not adding the nodes to the DocumentType could
+cause such entity references to be expanded incorrectly.)
+
+Note that you need XML::Parser 2.27 or higher for this to work correctly.
+
+=back
+
+=head1 SEE ALSO
+
+L<XML::DOM::XPath>
+
+The Japanese version of this document by Takanori Kawai (Hippo2000)
+at L<http://member.nifty.ne.jp/hippo2000/perltips/xml/dom.htm>
+
+The DOM Level 1 specification at L<http://www.w3.org/TR/REC-DOM-Level-1>
+
+The XML spec (Extensible Markup Language 1.0) at L<http://www.w3.org/TR/REC-xml>
+
+The L<XML::Parser> and L<XML::Parser::Expat> manual pages.
+
+L<XML::LibXML> also provides a DOM Parser, and is significantly faster
+than XML::DOM, and is under active development.  It requires that you 
+download the Gnome libxml library.
+
+L<XML::GDOME> will provide the DOM Level 2 Core API, and should be
+as fast as XML::LibXML, but more robust, since it uses the memory
+management functions of libgdome.  For more details see
+L<http://tjmather.com/xml-gdome/>
+
+=head1 CAVEATS
+
+The method getElementsByTagName() does not return a "live" NodeList.
+Whether this is an actual caveat is debatable, but a few people on the 
+www-dom mailing list seemed to think so. I haven't decided yet. It's a pain
+to implement, it slows things down and the benefits seem marginal.
+Let me know what you think. 
+
+=head1 AUTHOR
+
+Enno Derksen is the original author.
+
+Send patches to T.J. Mather at <F<tjmather@maxmind.com>>.
+
+Paid support is available from directly from the maintainers of this package.
+Please see L<http://www.maxmind.com/app/opensourceservices> for more details.
+
+Thanks to Clark Cooper for his help with the initial version.
+
+=cut
diff -rupN RELEASE-1.5.5/XML/Expat.pm ROUGE-1.5.5/XML/Expat.pm
--- RELEASE-1.5.5/XML/Expat.pm	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/XML/Expat.pm	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,1230 @@
+package XML::Parser::Expat;
+
+require 5.004;
+
+use strict;
+use vars qw($VERSION @ISA %Handler_Setters %Encoding_Table @Encoding_Path
+            $have_File_Spec);
+use Carp;
+
+require DynaLoader;
+
+@ISA = qw(DynaLoader);
+$VERSION = "2.36" ;
+
+$have_File_Spec = $INC{'File/Spec.pm'} || do 'File/Spec.pm';
+
+%Encoding_Table = ();
+if ($have_File_Spec) {
+  @Encoding_Path = (grep(-d $_,
+                         map(File::Spec->catdir($_, qw(XML Parser Encodings)),
+                             @INC)),
+                    File::Spec->curdir);
+}
+else {
+  @Encoding_Path = (grep(-d $_, map($_ . '/XML/Parser/Encodings', @INC)), '.');
+}
+  
+
+bootstrap XML::Parser::Expat $VERSION;
+
+%Handler_Setters = (
+                    Start => \&SetStartElementHandler,
+                    End   => \&SetEndElementHandler,
+                    Char  => \&SetCharacterDataHandler,
+                    Proc  => \&SetProcessingInstructionHandler,
+                    Comment => \&SetCommentHandler,
+                    CdataStart => \&SetStartCdataHandler,
+                    CdataEnd   => \&SetEndCdataHandler,
+                    Default => \&SetDefaultHandler,
+                    Unparsed => \&SetUnparsedEntityDeclHandler,
+                    Notation => \&SetNotationDeclHandler,
+                    ExternEnt => \&SetExternalEntityRefHandler,
+                    ExternEntFin => \&SetExtEntFinishHandler,
+                    Entity => \&SetEntityDeclHandler,
+                    Element => \&SetElementDeclHandler,
+                    Attlist => \&SetAttListDeclHandler,
+                    Doctype => \&SetDoctypeHandler,
+                    DoctypeFin => \&SetEndDoctypeHandler,
+                    XMLDecl => \&SetXMLDeclHandler
+                    );
+
+sub new {
+  my ($class, %args) = @_;
+  my $self = bless \%args, $_[0];
+  $args{_State_} = 0;
+  $args{Context} = [];
+  $args{Namespaces} ||= 0;
+  $args{ErrorMessage} ||= '';
+  if ($args{Namespaces}) {
+    $args{Namespace_Table} = {};
+    $args{Namespace_List} = [undef];
+    $args{Prefix_Table} = {};
+    $args{New_Prefixes} = [];
+  }
+  $args{_Setters} = \%Handler_Setters;
+  $args{Parser} = ParserCreate($self, $args{ProtocolEncoding},
+                               $args{Namespaces});
+  $self;
+}
+
+sub load_encoding {
+  my ($file) = @_;
+
+  $file =~ s!([^/]+)$!\L$1\E!;
+  $file .= '.enc' unless $file =~ /\.enc$/;
+  unless ($file =~ m!^/!) {
+    foreach (@Encoding_Path) {
+      my $tmp = ($have_File_Spec
+                 ? File::Spec->catfile($_, $file)
+                 : "$_/$file");
+      if (-e $tmp) {
+        $file = $tmp;
+        last;
+      }
+    }
+  }
+
+  local(*ENC);
+  open(ENC, $file) or croak("Couldn't open encmap $file:\n$!\n");
+  binmode(ENC);
+  my $data;
+  my $br = sysread(ENC, $data, -s $file);
+  croak("Trouble reading $file:\n$!\n")
+    unless defined($br);
+  close(ENC);
+
+  my $name = LoadEncoding($data, $br);
+  croak("$file isn't an encmap file")
+    unless defined($name);
+
+  $name;
+}  # End load_encoding
+
+sub setHandlers {
+  my ($self, @handler_pairs) = @_;
+
+  croak("Uneven number of arguments to setHandlers method")
+    if (int(@handler_pairs) & 1);
+
+  my @ret;
+
+  while (@handler_pairs) {
+    my $type = shift @handler_pairs;
+    my $handler = shift @handler_pairs;
+    croak "Handler for $type not a Code ref"
+      unless (! defined($handler) or ! $handler or ref($handler) eq 'CODE');
+
+    my $hndl = $self->{_Setters}->{$type};
+
+    unless (defined($hndl)) {
+      my @types = sort keys %{$self->{_Setters}};
+      croak("Unknown Expat handler type: $type\n Valid types: @types");
+    }
+
+    my $old = &$hndl($self->{Parser}, $handler);
+    push (@ret, $type, $old);
+  }
+
+  return @ret;
+}
+
+sub xpcroak
+ {
+  my ($self, $message) = @_;
+
+  my $eclines = $self->{ErrorContext};
+  my $line = GetCurrentLineNumber($_[0]->{Parser});
+  $message .= " at line $line";
+  $message .= ":\n" . $self->position_in_context($eclines)
+    if defined($eclines);
+  croak $message;
+}
+
+sub xpcarp {
+  my ($self, $message) = @_;
+
+  my $eclines = $self->{ErrorContext};
+  my $line = GetCurrentLineNumber($_[0]->{Parser});
+  $message .= " at line $line";
+  $message .= ":\n" . $self->position_in_context($eclines)
+    if defined($eclines);
+  carp $message;
+}
+
+sub default_current {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return DefaultCurrent($self->{Parser});
+  }
+}
+
+sub recognized_string {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return RecognizedString($self->{Parser});
+  }
+}
+
+sub original_string {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return OriginalString($self->{Parser});
+  }
+}
+
+sub current_line {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentLineNumber($self->{Parser});
+  }
+}
+
+sub current_column {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentColumnNumber($self->{Parser});
+  }
+}
+
+sub current_byte {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentByteIndex($self->{Parser});
+  }
+}
+
+sub base {
+  my ($self, $newbase) = @_;
+  my $p = $self->{Parser};
+  my $oldbase = GetBase($p);
+  SetBase($p, $newbase) if @_ > 1;
+  return $oldbase;
+}
+
+sub context {
+  my $ctx = $_[0]->{Context};
+  @$ctx;
+}
+
+sub current_element {
+  my ($self) = @_;
+  @{$self->{Context}} ? $self->{Context}->[-1] : undef;
+}
+
+sub in_element {
+  my ($self, $element) = @_;
+  @{$self->{Context}} ? $self->eq_name($self->{Context}->[-1], $element)
+    : undef;
+}
+
+sub within_element {
+  my ($self, $element) = @_;
+  my $cnt = 0;
+  foreach (@{$self->{Context}}) {
+    $cnt++ if $self->eq_name($_, $element);
+  }
+  return $cnt;
+}
+
+sub depth {
+  my ($self) = @_;
+  int(@{$self->{Context}});
+}
+
+sub element_index {
+  my ($self) = @_;
+
+  if ($self->{_State_} == 1) {
+    return ElementIndex($self->{Parser});
+  }
+}
+
+################
+# Namespace methods
+
+sub namespace {
+  my ($self, $name) = @_;
+  local($^W) = 0;
+  $self->{Namespace_List}->[int($name)];
+}
+
+sub eq_name {
+  my ($self, $nm1, $nm2) = @_;
+  local($^W) = 0;
+
+  int($nm1) == int($nm2) and $nm1 eq $nm2;
+}
+
+sub generate_ns_name {
+  my ($self, $name, $namespace) = @_;
+
+  $namespace ?
+    GenerateNSName($name, $namespace, $self->{Namespace_Table},
+                   $self->{Namespace_List})
+      : $name;
+}
+
+sub new_ns_prefixes {
+  my ($self) = @_;
+  if ($self->{Namespaces}) {
+    return @{$self->{New_Prefixes}};
+  }
+  return ();
+}
+
+sub expand_ns_prefix {
+  my ($self, $prefix) = @_;
+
+  if ($self->{Namespaces}) {
+    my $stack = $self->{Prefix_Table}->{$prefix};
+    return (defined($stack) and @$stack) ? $stack->[-1] : undef;
+  }
+
+  return undef;
+}
+
+sub current_ns_prefixes {
+  my ($self) = @_;
+
+  if ($self->{Namespaces}) {
+    my %set = %{$self->{Prefix_Table}};
+
+    if (exists $set{'#default'} and not defined($set{'#default'}->[-1])) {
+      delete $set{'#default'};
+    }
+
+    return keys %set;
+  }
+
+  return ();
+}
+
+
+################################################################
+# Namespace declaration handlers
+#
+
+sub NamespaceStart {
+  my ($self, $prefix, $uri) = @_;
+
+  $prefix = '#default' unless defined $prefix;
+  my $stack = $self->{Prefix_Table}->{$prefix}; 
+
+  if (defined $stack) {
+    push(@$stack, $uri);
+  }
+  else {
+    $self->{Prefix_Table}->{$prefix} = [$uri];
+  }
+
+  # The New_Prefixes list gets emptied at end of startElement function
+  # in Expat.xs
+
+  push(@{$self->{New_Prefixes}}, $prefix);
+}
+
+sub NamespaceEnd {
+  my ($self, $prefix) = @_;
+
+  $prefix = '#default' unless defined $prefix;
+
+  my $stack = $self->{Prefix_Table}->{$prefix};
+  if (@$stack > 1) {
+    pop(@$stack);
+  }
+  else {
+    delete $self->{Prefix_Table}->{$prefix};
+  }
+}
+
+################
+
+sub specified_attr {
+  my $self = shift;
+  
+  if ($self->{_State_} == 1) {
+    return GetSpecifiedAttributeCount($self->{Parser});
+  }
+}
+
+sub finish {
+  my ($self) = @_;
+  if ($self->{_State_} == 1) {
+    my $parser = $self->{Parser};
+    UnsetAllHandlers($parser);
+  }
+}
+
+sub position_in_context {
+  my ($self, $lines) = @_;
+  if ($self->{_State_} == 1) {
+    my $parser = $self->{Parser};
+    my ($string, $linepos) = PositionContext($parser, $lines);
+
+    return '' unless defined($string);
+
+    my $col = GetCurrentColumnNumber($parser);
+    my $ptr = ('=' x ($col - 1)) . '^' . "\n";
+    my $ret;
+    my $dosplit = $linepos < length($string);
+  
+    $string .= "\n" unless $string =~ /\n$/;
+  
+    if ($dosplit) {
+      $ret = substr($string, 0, $linepos) . $ptr
+        . substr($string, $linepos);
+    } else {
+      $ret = $string . $ptr;
+    }
+  
+    return $ret;
+  }
+}
+
+sub xml_escape {
+  my $self = shift;
+  my $text = shift;
+
+  study $text;
+  $text =~ s/\&/\&amp;/g;
+  $text =~ s/</\&lt;/g;
+  foreach (@_) {
+    croak "xml_escape: '$_' isn't a single character" if length($_) > 1;
+
+    if ($_ eq '>') {
+      $text =~ s/>/\&gt;/g;
+    }
+    elsif ($_ eq '"') {
+      $text =~ s/\"/\&quot;/;
+    }
+    elsif ($_ eq "'") {
+      $text =~ s/\'/\&apos;/;
+    }
+    else {
+      my $rep = '&#' . sprintf('x%X', ord($_)) . ';';
+      if (/\W/) {
+        my $ptrn = "\\$_";
+        $text =~ s/$ptrn/$rep/g;
+      }
+      else {
+        $text =~ s/$_/$rep/g;
+      }
+    }
+  }
+  $text;
+}
+
+sub skip_until {
+  my $self = shift;
+  if ($self->{_State_} <= 1) {
+    SkipUntil($self->{Parser}, $_[0]);
+  }
+}
+
+sub release {
+  my $self = shift;
+  ParserRelease($self->{Parser});
+}
+
+sub DESTROY {
+  my $self = shift;
+  ParserFree($self->{Parser});
+}
+
+sub parse {
+  my $self = shift;
+  my $arg = shift;
+  croak "Parse already in progress (Expat)" if $self->{_State_};
+  $self->{_State_} = 1;
+  my $parser = $self->{Parser};
+  my $ioref;
+  my $result = 0;
+  
+  if (defined $arg) {
+    if (ref($arg) and UNIVERSAL::isa($arg, 'IO::Handle')) {
+      $ioref = $arg;
+    } elsif (tied($arg)) {
+      my $class = ref($arg);
+      no strict 'refs';
+      $ioref = $arg if defined &{"${class}::TIEHANDLE"};
+    }
+    else {
+      require IO::Handle;
+      eval {
+        no strict 'refs';
+        $ioref = *{$arg}{IO} if defined *{$arg};
+      };
+      undef $@;
+    }
+  }
+  
+  if (defined($ioref)) {
+    my $delim = $self->{Stream_Delimiter};
+    my $prev_rs;
+    
+    $prev_rs = ref($ioref)->input_record_separator("\n$delim\n")
+      if defined($delim);
+    
+    $result = ParseStream($parser, $ioref, $delim);
+    
+    ref($ioref)->input_record_separator($prev_rs)
+      if defined($delim);
+  } else {
+    $result = ParseString($parser, $arg);
+  }
+  
+  $self->{_State_} = 2;
+  $result or croak $self->{ErrorMessage};
+}
+
+sub parsestring {
+  my $self = shift;
+  $self->parse(@_);
+}
+
+sub parsefile {
+  my $self = shift;
+  croak "Parser has already been used" if $self->{_State_};
+  local(*FILE);
+  open(FILE, $_[0]) or  croak "Couldn't open $_[0]:\n$!";
+  binmode(FILE);
+  my $ret = $self->parse(*FILE);
+  close(FILE);
+  $ret;
+}
+
+################################################################
+package XML::Parser::ContentModel;
+use overload '""' => \&asString, 'eq' => \&thiseq;
+
+sub EMPTY  () {1}
+sub ANY    () {2}
+sub MIXED  () {3}
+sub NAME   () {4}
+sub CHOICE () {5}
+sub SEQ    () {6}
+
+
+sub isempty {
+  return $_[0]->{Type} == EMPTY;
+}
+
+sub isany {
+  return $_[0]->{Type} == ANY;
+}
+
+sub ismixed {
+  return $_[0]->{Type} == MIXED;
+}
+
+sub isname {
+  return $_[0]->{Type} == NAME;
+}
+
+sub name {
+  return $_[0]->{Tag};
+}
+
+sub ischoice {
+  return $_[0]->{Type} == CHOICE;
+}
+
+sub isseq {
+  return $_[0]->{Type} == SEQ;
+}
+
+sub quant {
+  return $_[0]->{Quant};
+}
+
+sub children {
+  my $children = $_[0]->{Children};
+  if (defined $children) {
+    return @$children;
+  }
+  return undef;
+}
+
+sub asString {
+  my ($self) = @_;
+  my $ret;
+
+  if ($self->{Type} == NAME) {
+    $ret = $self->{Tag};
+  }
+  elsif ($self->{Type} == EMPTY) {
+    return "EMPTY";
+  }
+  elsif ($self->{Type} == ANY) {
+    return "ANY";
+  }
+  elsif ($self->{Type} == MIXED) {
+    $ret = '(#PCDATA';
+    foreach (@{$self->{Children}}) {
+      $ret .= '|' . $_;
+    }
+    $ret .= ')';
+  }
+  else {
+    my $sep = $self->{Type} == CHOICE ? '|' : ',';
+    $ret = '(' . join($sep, map { $_->asString } @{$self->{Children}}) . ')';
+  }
+
+  $ret .= $self->{Quant} if $self->{Quant};
+  return $ret;
+}
+
+sub thiseq {
+  my $self = shift;
+
+  return $self->asString eq $_[0];
+}
+
+################################################################
+package XML::Parser::ExpatNB;
+
+use vars qw(@ISA);
+use Carp;
+
+@ISA = qw(XML::Parser::Expat);
+
+sub parse {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parse method not supported in $class";
+}
+
+sub parsestring {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parsestring method not supported in $class";
+}
+
+sub parsefile {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parsefile method not supported in $class";
+}
+
+sub parse_more {
+  my ($self, $data) = @_;
+
+  $self->{_State_} = 1;
+  my $ret = XML::Parser::Expat::ParsePartial($self->{Parser}, $data);
+
+  croak $self->{ErrorMessage} unless $ret;
+}
+
+sub parse_done {
+  my $self = shift;
+
+  my $ret = XML::Parser::Expat::ParseDone($self->{Parser});
+  unless ($ret) {
+    my $msg = $self->{ErrorMessage};
+    $self->release;
+    croak $msg;
+  }
+
+  $self->{_State_} = 2;
+
+  my $result = $ret;
+  my @result = ();
+  my $final = $self->{FinalHandler};
+  if (defined $final) {
+    if (wantarray) {
+      @result = &$final($self);
+    }
+    else {
+      $result = &$final($self);
+    }
+  }
+
+  $self->release;
+
+  return unless defined wantarray;
+  return wantarray ? @result : $result;
+}
+
+################################################################
+
+package XML::Parser::Encinfo;
+
+sub DESTROY {
+  my $self = shift;
+  XML::Parser::Expat::FreeEncoding($self);
+}
+
+1;
+
+__END__
+
+=head1 NAME
+
+XML::Parser::Expat - Lowlevel access to James Clark's expat XML parser
+
+=head1 SYNOPSIS
+
+ use XML::Parser::Expat;
+
+ $parser = new XML::Parser::Expat;
+ $parser->setHandlers('Start' => \&sh,
+                      'End'   => \&eh,
+                      'Char'  => \&ch);
+ open(FOO, 'info.xml') or die "Couldn't open";
+ $parser->parse(*FOO);
+ close(FOO);
+ # $parser->parse('<foo id="me"> here <em>we</em> go </foo>');
+
+ sub sh
+ {
+   my ($p, $el, %atts) = @_;
+   $p->setHandlers('Char' => \&spec)
+     if ($el eq 'special');
+   ...
+ }
+
+ sub eh
+ {
+   my ($p, $el) = @_;
+   $p->setHandlers('Char' => \&ch)  # Special elements won't contain
+     if ($el eq 'special');         # other special elements
+   ...
+ } 
+
+=head1 DESCRIPTION
+
+This module provides an interface to James Clark's XML parser, expat. As in
+expat, a single instance of the parser can only parse one document. Calls
+to parsestring after the first for a given instance will die.
+
+Expat (and XML::Parser::Expat) are event based. As the parser recognizes
+parts of the document (say the start or end of an XML element), then any
+handlers registered for that type of an event are called with suitable
+parameters.
+
+=head1 METHODS
+
+=over 4
+
+=item new
+
+This is a class method, the constructor for XML::Parser::Expat. Options are
+passed as keyword value pairs. The recognized options are:
+
+=over 4
+
+=item * ProtocolEncoding
+
+The protocol encoding name. The default is none. The expat built-in
+encodings are: C<UTF-8>, C<ISO-8859-1>, C<UTF-16>, and C<US-ASCII>.
+Other encodings may be used if they have encoding maps in one of the
+directories in the @Encoding_Path list. Setting the protocol encoding
+overrides any encoding in the XML declaration.
+
+=item * Namespaces
+
+When this option is given with a true value, then the parser does namespace
+processing. By default, namespace processing is turned off. When it is
+turned on, the parser consumes I<xmlns> attributes and strips off prefixes
+from element and attributes names where those prefixes have a defined
+namespace. A name's namespace can be found using the L<"namespace"> method
+and two names can be checked for absolute equality with the L<"eq_name">
+method.
+
+=item * NoExpand
+
+Normally, the parser will try to expand references to entities defined in
+the internal subset. If this option is set to a true value, and a default
+handler is also set, then the default handler will be called when an
+entity reference is seen in text. This has no effect if a default handler
+has not been registered, and it has no effect on the expansion of entity
+references inside attribute values.
+
+=item * Stream_Delimiter
+
+This option takes a string value. When this string is found alone on a line
+while parsing from a stream, then the parse is ended as if it saw an end of
+file. The intended use is with a stream of xml documents in a MIME multipart
+format. The string should not contain a trailing newline.
+
+=item * ErrorContext
+
+When this option is defined, errors are reported in context. The value
+of ErrorContext should be the number of lines to show on either side of
+the line in which the error occurred.
+
+=item * ParseParamEnt
+
+Unless standalone is set to "yes" in the XML declaration, setting this to
+a true value allows the external DTD to be read, and parameter entities
+to be parsed and expanded.
+
+=item * Base
+
+The base to use for relative pathnames or URLs. This can also be done by
+using the base method.
+
+=back
+
+=item setHandlers(TYPE, HANDLER [, TYPE, HANDLER [...]])
+
+This method registers handlers for the various events. If no handlers are
+registered, then a call to parsestring or parsefile will only determine if
+the corresponding XML document is well formed (by returning without error.)
+This may be called from within a handler, after the parse has started.
+
+Setting a handler to something that evaluates to false unsets that
+handler.
+
+This method returns a list of type, handler pairs corresponding to the
+input. The handlers returned are the ones that were in effect before the
+call to setHandlers.
+
+The recognized events and the parameters passed to the corresponding
+handlers are:
+
+=over 4
+
+=item * Start             (Parser, Element [, Attr, Val [,...]])
+
+This event is generated when an XML start tag is recognized. Parser is
+an XML::Parser::Expat instance. Element is the name of the XML element that
+is opened with the start tag. The Attr & Val pairs are generated for each
+attribute in the start tag.
+
+=item * End               (Parser, Element)
+
+This event is generated when an XML end tag is recognized. Note that
+an XML empty tag (<foo/>) generates both a start and an end event.
+
+There is always a lower level start and end handler installed that wrap
+the corresponding callbacks. This is to handle the context mechanism.
+A consequence of this is that the default handler (see below) will not
+see a start tag or end tag unless the default_current method is called.
+
+=item * Char              (Parser, String)
+
+This event is generated when non-markup is recognized. The non-markup
+sequence of characters is in String. A single non-markup sequence of
+characters may generate multiple calls to this handler. Whatever the
+encoding of the string in the original document, this is given to the
+handler in UTF-8.
+
+=item * Proc              (Parser, Target, Data)
+
+This event is generated when a processing instruction is recognized.
+
+=item * Comment           (Parser, String)
+
+This event is generated when a comment is recognized.
+
+=item * CdataStart        (Parser)
+
+This is called at the start of a CDATA section.
+
+=item * CdataEnd          (Parser)
+
+This is called at the end of a CDATA section.
+
+=item * Default           (Parser, String)
+
+This is called for any characters that don't have a registered handler.
+This includes both characters that are part of markup for which no
+events are generated (markup declarations) and characters that
+could generate events, but for which no handler has been registered.
+
+Whatever the encoding in the original document, the string is returned to
+the handler in UTF-8.
+
+=item * Unparsed          (Parser, Entity, Base, Sysid, Pubid, Notation)
+
+This is called for a declaration of an unparsed entity. Entity is the name
+of the entity. Base is the base to be used for resolving a relative URI.
+Sysid is the system id. Pubid is the public id. Notation is the notation
+name. Base and Pubid may be undefined.
+
+=item * Notation          (Parser, Notation, Base, Sysid, Pubid)
+
+This is called for a declaration of notation. Notation is the notation name.
+Base is the base to be used for resolving a relative URI. Sysid is the system
+id. Pubid is the public id. Base, Sysid, and Pubid may all be undefined.
+
+=item * ExternEnt         (Parser, Base, Sysid, Pubid)
+
+This is called when an external entity is referenced. Base is the base to be
+used for resolving a relative URI. Sysid is the system id. Pubid is the public
+id. Base, and Pubid may be undefined.
+
+This handler should either return a string, which represents the contents of
+the external entity, or return an open filehandle that can be read to obtain
+the contents of the external entity, or return undef, which indicates the
+external entity couldn't be found and will generate a parse error.
+
+If an open filehandle is returned, it must be returned as either a glob
+(*FOO) or as a reference to a glob (e.g. an instance of IO::Handle).
+
+=item * ExternEntFin      (Parser)
+
+This is called after an external entity has been parsed. It allows
+applications to perform cleanup on actions performed in the above
+ExternEnt handler.
+
+=item * Entity            (Parser, Name, Val, Sysid, Pubid, Ndata, IsParam)
+
+This is called when an entity is declared. For internal entities, the Val
+parameter will contain the value and the remaining three parameters will
+be undefined. For external entities, the Val parameter
+will be undefined, the Sysid parameter will have the system id, the Pubid
+parameter will have the public id if it was provided (it will be undefined
+otherwise), the Ndata parameter will contain the notation for unparsed
+entities. If this is a parameter entity declaration, then the IsParam
+parameter is true.
+
+Note that this handler and the Unparsed handler above overlap. If both are
+set, then this handler will not be called for unparsed entities.
+
+=item * Element           (Parser, Name, Model)
+
+The element handler is called when an element declaration is found. Name is
+the element name, and Model is the content model as an
+XML::Parser::ContentModel object. See L<"XML::Parser::ContentModel Methods">
+for methods available for this class.
+
+=item * Attlist           (Parser, Elname, Attname, Type, Default, Fixed)
+
+This handler is called for each attribute in an ATTLIST declaration.
+So an ATTLIST declaration that has multiple attributes
+will generate multiple calls to this handler. The Elname parameter is the
+name of the element with which the attribute is being associated. The Attname
+parameter is the name of the attribute. Type is the attribute type, given as
+a string. Default is the default value, which will either be "#REQUIRED",
+"#IMPLIED" or a quoted string (i.e. the returned string will begin and end
+with a quote character). If Fixed is true, then this is a fixed attribute.
+
+=item * Doctype           (Parser, Name, Sysid, Pubid, Internal)
+
+This handler is called for DOCTYPE declarations. Name is the document type
+name. Sysid is the system id of the document type, if it was provided,
+otherwise it's undefined. Pubid is the public id of the document type,
+which will be undefined if no public id was given. Internal will be
+true or false, indicating whether or not the doctype declaration contains
+an internal subset.
+
+=item * DoctypeFin        (Parser)
+
+This handler is called after parsing of the DOCTYPE declaration has finished,
+including any internal or external DTD declarations.
+
+=item * XMLDecl           (Parser, Version, Encoding, Standalone)
+
+This handler is called for XML declarations. Version is a string containg
+the version. Encoding is either undefined or contains an encoding string.
+Standalone is either undefined, or true or false. Undefined indicates
+that no standalone parameter was given in the XML declaration. True or
+false indicates "yes" or "no" respectively.
+
+=back
+
+=item namespace(name)
+
+Return the URI of the namespace that the name belongs to. If the name doesn't
+belong to any namespace, an undef is returned. This is only valid on names
+received through the Start or End handlers from a single document, or through
+a call to the generate_ns_name method. In other words, don't use names
+generated from one instance of XML::Parser::Expat with other instances.
+
+=item eq_name(name1, name2)
+
+Return true if name1 and name2 are identical (i.e. same name and from
+the same namespace.) This is only meaningful if both names were obtained
+through the Start or End handlers from a single document, or through
+a call to the generate_ns_name method.
+
+=item generate_ns_name(name, namespace)
+
+Return a name, associated with a given namespace, good for using with the
+above 2 methods. The namespace argument should be the namespace URI, not
+a prefix.
+
+=item new_ns_prefixes
+
+When called from a start tag handler, returns namespace prefixes declared
+with this start tag. If called elsewere (or if there were no namespace
+prefixes declared), it returns an empty list. Setting of the default
+namespace is indicated with '#default' as a prefix.
+
+=item expand_ns_prefix(prefix)
+
+Return the uri to which the given prefix is currently bound. Returns
+undef if the prefix isn't currently bound. Use '#default' to find the
+current binding of the default namespace (if any).
+
+=item current_ns_prefixes
+
+Return a list of currently bound namespace prefixes. The order of the
+the prefixes in the list has no meaning. If the default namespace is
+currently bound, '#default' appears in the list.
+
+=item recognized_string
+
+Returns the string from the document that was recognized in order to call
+the current handler. For instance, when called from a start handler, it
+will give us the the start-tag string. The string is encoded in UTF-8.
+This method doesn't return a meaningful string inside declaration handlers.
+
+=item original_string
+
+Returns the verbatim string from the document that was recognized in
+order to call the current handler. The string is in the original document
+encoding. This method doesn't return a meaningful string inside declaration
+handlers.
+
+=item default_current
+
+When called from a handler, causes the sequence of characters that generated
+the corresponding event to be sent to the default handler (if one is
+registered). Use of this method is deprecated in favor the recognized_string
+method, which you can use without installing a default handler. This
+method doesn't deliver a meaningful string to the default handler when
+called from inside declaration handlers.
+
+=item xpcroak(message)
+
+Concatenate onto the given message the current line number within the
+XML document plus the message implied by ErrorContext. Then croak with
+the formed message.
+
+=item xpcarp(message)
+
+Concatenate onto the given message the current line number within the
+XML document plus the message implied by ErrorContext. Then carp with
+the formed message.
+
+=item current_line
+
+Returns the line number of the current position of the parse.
+
+=item current_column
+
+Returns the column number of the current position of the parse.
+
+=item current_byte
+
+Returns the current position of the parse.
+
+=item base([NEWBASE]);
+
+Returns the current value of the base for resolving relative URIs. If
+NEWBASE is supplied, changes the base to that value.
+
+=item context
+
+Returns a list of element names that represent open elements, with the
+last one being the innermost. Inside start and end tag handlers, this
+will be the tag of the parent element.
+
+=item current_element
+
+Returns the name of the innermost currently opened element. Inside
+start or end handlers, returns the parent of the element associated
+with those tags.
+
+=item in_element(NAME)
+
+Returns true if NAME is equal to the name of the innermost currently opened
+element. If namespace processing is being used and you want to check
+against a name that may be in a namespace, then use the generate_ns_name
+method to create the NAME argument.
+
+=item within_element(NAME)
+
+Returns the number of times the given name appears in the context list.
+If namespace processing is being used and you want to check
+against a name that may be in a namespace, then use the generate_ns_name
+method to create the NAME argument.
+
+=item depth
+
+Returns the size of the context list.
+
+=item element_index
+
+Returns an integer that is the depth-first visit order of the current
+element. This will be zero outside of the root element. For example,
+this will return 1 when called from the start handler for the root element
+start tag.
+
+=item skip_until(INDEX)
+
+INDEX is an integer that represents an element index. When this method
+is called, all handlers are suspended until the start tag for an element
+that has an index number equal to INDEX is seen. If a start handler has
+been set, then this is the first tag that the start handler will see
+after skip_until has been called.
+
+
+=item position_in_context(LINES)
+
+Returns a string that shows the current parse position. LINES should be
+an integer >= 0 that represents the number of lines on either side of the
+current parse line to place into the returned string.
+
+=item xml_escape(TEXT [, CHAR [, CHAR ...]])
+
+Returns TEXT with markup characters turned into character entities. Any
+additional characters provided as arguments are also turned into character
+references where found in TEXT.
+
+=item parse (SOURCE)
+
+The SOURCE parameter should either be a string containing the whole XML
+document, or it should be an open IO::Handle. Only a single document
+may be parsed for a given instance of XML::Parser::Expat, so this will croak
+if it's been called previously for this instance.
+
+=item parsestring(XML_DOC_STRING)
+
+Parses the given string as an XML document. Only a single document may be
+parsed for a given instance of XML::Parser::Expat, so this will die if either
+parsestring or parsefile has been called for this instance previously.
+
+This method is deprecated in favor of the parse method.
+
+=item parsefile(FILENAME)
+
+Parses the XML document in the given file. Will die if parsestring or
+parsefile has been called previously for this instance.
+
+=item is_defaulted(ATTNAME)
+
+NO LONGER WORKS. To find out if an attribute is defaulted please use
+the specified_attr method.
+
+=item specified_attr
+
+When the start handler receives lists of attributes and values, the
+non-defaulted (i.e. explicitly specified) attributes occur in the list
+first. This method returns the number of specified items in the list.
+So if this number is equal to the length of the list, there were no
+defaulted values. Otherwise the number points to the index of the
+first defaulted attribute name.
+
+=item finish
+
+Unsets all handlers (including internal ones that set context), but expat
+continues parsing to the end of the document or until it finds an error.
+It should finish up a lot faster than with the handlers set.
+
+=item release
+
+There are data structures used by XML::Parser::Expat that have circular
+references. This means that these structures will never be garbage
+collected unless these references are explicitly broken. Calling this
+method breaks those references (and makes the instance unusable.)
+
+Normally, higher level calls handle this for you, but if you are using
+XML::Parser::Expat directly, then it's your responsibility to call it.
+
+=back
+
+=head2 XML::Parser::ContentModel Methods
+
+The element declaration handlers are passed objects of this class as the
+content model of the element declaration. They also represent content
+particles, components of a content model.
+
+When referred to as a string, these objects are automagicly converted to a
+string representation of the model (or content particle).
+
+=over 4
+
+=item isempty
+
+This method returns true if the object is "EMPTY", false otherwise.
+
+=item isany
+
+This method returns true if the object is "ANY", false otherwise.
+
+=item ismixed
+
+This method returns true if the object is "(#PCDATA)" or "(#PCDATA|...)*",
+false otherwise.
+
+=item isname
+
+This method returns if the object is an element name.
+
+=item ischoice
+
+This method returns true if the object is a choice of content particles.
+
+
+=item isseq
+
+This method returns true if the object is a sequence of content particles.
+
+=item quant
+
+This method returns undef or a string representing the quantifier
+('?', '*', '+') associated with the model or particle.
+
+=item children
+
+This method returns undef or (for mixed, choice, and sequence types)
+an array of component content particles. There will always be at least
+one component for choices and sequences, but for a mixed content model
+of pure PCDATA, "(#PCDATA)", then an undef is returned.
+
+=back
+
+=head2 XML::Parser::ExpatNB Methods
+
+The class XML::Parser::ExpatNB is a subclass of XML::Parser::Expat used
+for non-blocking access to the expat library. It does not support the parse,
+parsestring, or parsefile methods, but it does have these additional methods:
+
+=over 4
+
+=item parse_more(DATA)
+
+Feed expat more text to munch on.
+
+=item parse_done
+
+Tell expat that it's gotten the whole document.
+
+=back
+
+=head1 FUNCTIONS
+
+=over 4
+
+=item XML::Parser::Expat::load_encoding(ENCODING)
+
+Load an external encoding. ENCODING is either the name of an encoding or
+the name of a file. The basename is converted to lowercase and a '.enc'
+extension is appended unless there's one already there. Then, unless
+it's an absolute pathname (i.e. begins with '/'), the first file by that
+name discovered in the @Encoding_Path path list is used.
+
+The encoding in the file is loaded and kept in the %Encoding_Table
+table. Earlier encodings of the same name are replaced.
+
+This function is automaticly called by expat when it encounters an encoding
+it doesn't know about. Expat shouldn't call this twice for the same
+encoding name. The only reason users should use this function is to
+explicitly load an encoding not contained in the @Encoding_Path list.
+
+=back
+
+=head1 AUTHORS
+
+Larry Wall <F<larry@wall.org>> wrote version 1.0.
+
+Clark Cooper <F<coopercc@netheaven.com>> picked up support, changed the API
+for this version (2.x), provided documentation, and added some standard
+package features.
+
+=cut
diff -rupN RELEASE-1.5.5/XML/Parser/Expat.pm ROUGE-1.5.5/XML/Parser/Expat.pm
--- RELEASE-1.5.5/XML/Parser/Expat.pm	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/XML/Parser/Expat.pm	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,1230 @@
+package XML::Parser::Expat;
+
+require 5.004;
+
+use strict;
+use vars qw($VERSION @ISA %Handler_Setters %Encoding_Table @Encoding_Path
+            $have_File_Spec);
+use Carp;
+
+require DynaLoader;
+
+@ISA = qw(DynaLoader);
+$VERSION = "2.36" ;
+
+$have_File_Spec = $INC{'File/Spec.pm'} || do 'File/Spec.pm';
+
+%Encoding_Table = ();
+if ($have_File_Spec) {
+  @Encoding_Path = (grep(-d $_,
+                         map(File::Spec->catdir($_, qw(XML Parser Encodings)),
+                             @INC)),
+                    File::Spec->curdir);
+}
+else {
+  @Encoding_Path = (grep(-d $_, map($_ . '/XML/Parser/Encodings', @INC)), '.');
+}
+  
+
+bootstrap XML::Parser::Expat $VERSION;
+
+%Handler_Setters = (
+                    Start => \&SetStartElementHandler,
+                    End   => \&SetEndElementHandler,
+                    Char  => \&SetCharacterDataHandler,
+                    Proc  => \&SetProcessingInstructionHandler,
+                    Comment => \&SetCommentHandler,
+                    CdataStart => \&SetStartCdataHandler,
+                    CdataEnd   => \&SetEndCdataHandler,
+                    Default => \&SetDefaultHandler,
+                    Unparsed => \&SetUnparsedEntityDeclHandler,
+                    Notation => \&SetNotationDeclHandler,
+                    ExternEnt => \&SetExternalEntityRefHandler,
+                    ExternEntFin => \&SetExtEntFinishHandler,
+                    Entity => \&SetEntityDeclHandler,
+                    Element => \&SetElementDeclHandler,
+                    Attlist => \&SetAttListDeclHandler,
+                    Doctype => \&SetDoctypeHandler,
+                    DoctypeFin => \&SetEndDoctypeHandler,
+                    XMLDecl => \&SetXMLDeclHandler
+                    );
+
+sub new {
+  my ($class, %args) = @_;
+  my $self = bless \%args, $_[0];
+  $args{_State_} = 0;
+  $args{Context} = [];
+  $args{Namespaces} ||= 0;
+  $args{ErrorMessage} ||= '';
+  if ($args{Namespaces}) {
+    $args{Namespace_Table} = {};
+    $args{Namespace_List} = [undef];
+    $args{Prefix_Table} = {};
+    $args{New_Prefixes} = [];
+  }
+  $args{_Setters} = \%Handler_Setters;
+  $args{Parser} = ParserCreate($self, $args{ProtocolEncoding},
+                               $args{Namespaces});
+  $self;
+}
+
+sub load_encoding {
+  my ($file) = @_;
+
+  $file =~ s!([^/]+)$!\L$1\E!;
+  $file .= '.enc' unless $file =~ /\.enc$/;
+  unless ($file =~ m!^/!) {
+    foreach (@Encoding_Path) {
+      my $tmp = ($have_File_Spec
+                 ? File::Spec->catfile($_, $file)
+                 : "$_/$file");
+      if (-e $tmp) {
+        $file = $tmp;
+        last;
+      }
+    }
+  }
+
+  local(*ENC);
+  open(ENC, $file) or croak("Couldn't open encmap $file:\n$!\n");
+  binmode(ENC);
+  my $data;
+  my $br = sysread(ENC, $data, -s $file);
+  croak("Trouble reading $file:\n$!\n")
+    unless defined($br);
+  close(ENC);
+
+  my $name = LoadEncoding($data, $br);
+  croak("$file isn't an encmap file")
+    unless defined($name);
+
+  $name;
+}  # End load_encoding
+
+sub setHandlers {
+  my ($self, @handler_pairs) = @_;
+
+  croak("Uneven number of arguments to setHandlers method")
+    if (int(@handler_pairs) & 1);
+
+  my @ret;
+
+  while (@handler_pairs) {
+    my $type = shift @handler_pairs;
+    my $handler = shift @handler_pairs;
+    croak "Handler for $type not a Code ref"
+      unless (! defined($handler) or ! $handler or ref($handler) eq 'CODE');
+
+    my $hndl = $self->{_Setters}->{$type};
+
+    unless (defined($hndl)) {
+      my @types = sort keys %{$self->{_Setters}};
+      croak("Unknown Expat handler type: $type\n Valid types: @types");
+    }
+
+    my $old = &$hndl($self->{Parser}, $handler);
+    push (@ret, $type, $old);
+  }
+
+  return @ret;
+}
+
+sub xpcroak
+ {
+  my ($self, $message) = @_;
+
+  my $eclines = $self->{ErrorContext};
+  my $line = GetCurrentLineNumber($_[0]->{Parser});
+  $message .= " at line $line";
+  $message .= ":\n" . $self->position_in_context($eclines)
+    if defined($eclines);
+  croak $message;
+}
+
+sub xpcarp {
+  my ($self, $message) = @_;
+
+  my $eclines = $self->{ErrorContext};
+  my $line = GetCurrentLineNumber($_[0]->{Parser});
+  $message .= " at line $line";
+  $message .= ":\n" . $self->position_in_context($eclines)
+    if defined($eclines);
+  carp $message;
+}
+
+sub default_current {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return DefaultCurrent($self->{Parser});
+  }
+}
+
+sub recognized_string {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return RecognizedString($self->{Parser});
+  }
+}
+
+sub original_string {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return OriginalString($self->{Parser});
+  }
+}
+
+sub current_line {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentLineNumber($self->{Parser});
+  }
+}
+
+sub current_column {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentColumnNumber($self->{Parser});
+  }
+}
+
+sub current_byte {
+  my $self = shift;
+  if ($self->{_State_} == 1) {
+    return GetCurrentByteIndex($self->{Parser});
+  }
+}
+
+sub base {
+  my ($self, $newbase) = @_;
+  my $p = $self->{Parser};
+  my $oldbase = GetBase($p);
+  SetBase($p, $newbase) if @_ > 1;
+  return $oldbase;
+}
+
+sub context {
+  my $ctx = $_[0]->{Context};
+  @$ctx;
+}
+
+sub current_element {
+  my ($self) = @_;
+  @{$self->{Context}} ? $self->{Context}->[-1] : undef;
+}
+
+sub in_element {
+  my ($self, $element) = @_;
+  @{$self->{Context}} ? $self->eq_name($self->{Context}->[-1], $element)
+    : undef;
+}
+
+sub within_element {
+  my ($self, $element) = @_;
+  my $cnt = 0;
+  foreach (@{$self->{Context}}) {
+    $cnt++ if $self->eq_name($_, $element);
+  }
+  return $cnt;
+}
+
+sub depth {
+  my ($self) = @_;
+  int(@{$self->{Context}});
+}
+
+sub element_index {
+  my ($self) = @_;
+
+  if ($self->{_State_} == 1) {
+    return ElementIndex($self->{Parser});
+  }
+}
+
+################
+# Namespace methods
+
+sub namespace {
+  my ($self, $name) = @_;
+  local($^W) = 0;
+  $self->{Namespace_List}->[int($name)];
+}
+
+sub eq_name {
+  my ($self, $nm1, $nm2) = @_;
+  local($^W) = 0;
+
+  int($nm1) == int($nm2) and $nm1 eq $nm2;
+}
+
+sub generate_ns_name {
+  my ($self, $name, $namespace) = @_;
+
+  $namespace ?
+    GenerateNSName($name, $namespace, $self->{Namespace_Table},
+                   $self->{Namespace_List})
+      : $name;
+}
+
+sub new_ns_prefixes {
+  my ($self) = @_;
+  if ($self->{Namespaces}) {
+    return @{$self->{New_Prefixes}};
+  }
+  return ();
+}
+
+sub expand_ns_prefix {
+  my ($self, $prefix) = @_;
+
+  if ($self->{Namespaces}) {
+    my $stack = $self->{Prefix_Table}->{$prefix};
+    return (defined($stack) and @$stack) ? $stack->[-1] : undef;
+  }
+
+  return undef;
+}
+
+sub current_ns_prefixes {
+  my ($self) = @_;
+
+  if ($self->{Namespaces}) {
+    my %set = %{$self->{Prefix_Table}};
+
+    if (exists $set{'#default'} and not defined($set{'#default'}->[-1])) {
+      delete $set{'#default'};
+    }
+
+    return keys %set;
+  }
+
+  return ();
+}
+
+
+################################################################
+# Namespace declaration handlers
+#
+
+sub NamespaceStart {
+  my ($self, $prefix, $uri) = @_;
+
+  $prefix = '#default' unless defined $prefix;
+  my $stack = $self->{Prefix_Table}->{$prefix}; 
+
+  if (defined $stack) {
+    push(@$stack, $uri);
+  }
+  else {
+    $self->{Prefix_Table}->{$prefix} = [$uri];
+  }
+
+  # The New_Prefixes list gets emptied at end of startElement function
+  # in Expat.xs
+
+  push(@{$self->{New_Prefixes}}, $prefix);
+}
+
+sub NamespaceEnd {
+  my ($self, $prefix) = @_;
+
+  $prefix = '#default' unless defined $prefix;
+
+  my $stack = $self->{Prefix_Table}->{$prefix};
+  if (@$stack > 1) {
+    pop(@$stack);
+  }
+  else {
+    delete $self->{Prefix_Table}->{$prefix};
+  }
+}
+
+################
+
+sub specified_attr {
+  my $self = shift;
+  
+  if ($self->{_State_} == 1) {
+    return GetSpecifiedAttributeCount($self->{Parser});
+  }
+}
+
+sub finish {
+  my ($self) = @_;
+  if ($self->{_State_} == 1) {
+    my $parser = $self->{Parser};
+    UnsetAllHandlers($parser);
+  }
+}
+
+sub position_in_context {
+  my ($self, $lines) = @_;
+  if ($self->{_State_} == 1) {
+    my $parser = $self->{Parser};
+    my ($string, $linepos) = PositionContext($parser, $lines);
+
+    return '' unless defined($string);
+
+    my $col = GetCurrentColumnNumber($parser);
+    my $ptr = ('=' x ($col - 1)) . '^' . "\n";
+    my $ret;
+    my $dosplit = $linepos < length($string);
+  
+    $string .= "\n" unless $string =~ /\n$/;
+  
+    if ($dosplit) {
+      $ret = substr($string, 0, $linepos) . $ptr
+        . substr($string, $linepos);
+    } else {
+      $ret = $string . $ptr;
+    }
+  
+    return $ret;
+  }
+}
+
+sub xml_escape {
+  my $self = shift;
+  my $text = shift;
+
+  study $text;
+  $text =~ s/\&/\&amp;/g;
+  $text =~ s/</\&lt;/g;
+  foreach (@_) {
+    croak "xml_escape: '$_' isn't a single character" if length($_) > 1;
+
+    if ($_ eq '>') {
+      $text =~ s/>/\&gt;/g;
+    }
+    elsif ($_ eq '"') {
+      $text =~ s/\"/\&quot;/;
+    }
+    elsif ($_ eq "'") {
+      $text =~ s/\'/\&apos;/;
+    }
+    else {
+      my $rep = '&#' . sprintf('x%X', ord($_)) . ';';
+      if (/\W/) {
+        my $ptrn = "\\$_";
+        $text =~ s/$ptrn/$rep/g;
+      }
+      else {
+        $text =~ s/$_/$rep/g;
+      }
+    }
+  }
+  $text;
+}
+
+sub skip_until {
+  my $self = shift;
+  if ($self->{_State_} <= 1) {
+    SkipUntil($self->{Parser}, $_[0]);
+  }
+}
+
+sub release {
+  my $self = shift;
+  ParserRelease($self->{Parser});
+}
+
+sub DESTROY {
+  my $self = shift;
+  ParserFree($self->{Parser});
+}
+
+sub parse {
+  my $self = shift;
+  my $arg = shift;
+  croak "Parse already in progress (Expat)" if $self->{_State_};
+  $self->{_State_} = 1;
+  my $parser = $self->{Parser};
+  my $ioref;
+  my $result = 0;
+  
+  if (defined $arg) {
+    if (ref($arg) and UNIVERSAL::isa($arg, 'IO::Handle')) {
+      $ioref = $arg;
+    } elsif (tied($arg)) {
+      my $class = ref($arg);
+      no strict 'refs';
+      $ioref = $arg if defined &{"${class}::TIEHANDLE"};
+    }
+    else {
+      require IO::Handle;
+      eval {
+        no strict 'refs';
+        $ioref = *{$arg}{IO} if defined *{$arg};
+      };
+      undef $@;
+    }
+  }
+  
+  if (defined($ioref)) {
+    my $delim = $self->{Stream_Delimiter};
+    my $prev_rs;
+    
+    $prev_rs = ref($ioref)->input_record_separator("\n$delim\n")
+      if defined($delim);
+    
+    $result = ParseStream($parser, $ioref, $delim);
+    
+    ref($ioref)->input_record_separator($prev_rs)
+      if defined($delim);
+  } else {
+    $result = ParseString($parser, $arg);
+  }
+  
+  $self->{_State_} = 2;
+  $result or croak $self->{ErrorMessage};
+}
+
+sub parsestring {
+  my $self = shift;
+  $self->parse(@_);
+}
+
+sub parsefile {
+  my $self = shift;
+  croak "Parser has already been used" if $self->{_State_};
+  local(*FILE);
+  open(FILE, $_[0]) or  croak "Couldn't open $_[0]:\n$!";
+  binmode(FILE);
+  my $ret = $self->parse(*FILE);
+  close(FILE);
+  $ret;
+}
+
+################################################################
+package XML::Parser::ContentModel;
+use overload '""' => \&asString, 'eq' => \&thiseq;
+
+sub EMPTY  () {1}
+sub ANY    () {2}
+sub MIXED  () {3}
+sub NAME   () {4}
+sub CHOICE () {5}
+sub SEQ    () {6}
+
+
+sub isempty {
+  return $_[0]->{Type} == EMPTY;
+}
+
+sub isany {
+  return $_[0]->{Type} == ANY;
+}
+
+sub ismixed {
+  return $_[0]->{Type} == MIXED;
+}
+
+sub isname {
+  return $_[0]->{Type} == NAME;
+}
+
+sub name {
+  return $_[0]->{Tag};
+}
+
+sub ischoice {
+  return $_[0]->{Type} == CHOICE;
+}
+
+sub isseq {
+  return $_[0]->{Type} == SEQ;
+}
+
+sub quant {
+  return $_[0]->{Quant};
+}
+
+sub children {
+  my $children = $_[0]->{Children};
+  if (defined $children) {
+    return @$children;
+  }
+  return undef;
+}
+
+sub asString {
+  my ($self) = @_;
+  my $ret;
+
+  if ($self->{Type} == NAME) {
+    $ret = $self->{Tag};
+  }
+  elsif ($self->{Type} == EMPTY) {
+    return "EMPTY";
+  }
+  elsif ($self->{Type} == ANY) {
+    return "ANY";
+  }
+  elsif ($self->{Type} == MIXED) {
+    $ret = '(#PCDATA';
+    foreach (@{$self->{Children}}) {
+      $ret .= '|' . $_;
+    }
+    $ret .= ')';
+  }
+  else {
+    my $sep = $self->{Type} == CHOICE ? '|' : ',';
+    $ret = '(' . join($sep, map { $_->asString } @{$self->{Children}}) . ')';
+  }
+
+  $ret .= $self->{Quant} if $self->{Quant};
+  return $ret;
+}
+
+sub thiseq {
+  my $self = shift;
+
+  return $self->asString eq $_[0];
+}
+
+################################################################
+package XML::Parser::ExpatNB;
+
+use vars qw(@ISA);
+use Carp;
+
+@ISA = qw(XML::Parser::Expat);
+
+sub parse {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parse method not supported in $class";
+}
+
+sub parsestring {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parsestring method not supported in $class";
+}
+
+sub parsefile {
+  my $self = shift;
+  my $class = ref($self);
+  croak "parsefile method not supported in $class";
+}
+
+sub parse_more {
+  my ($self, $data) = @_;
+
+  $self->{_State_} = 1;
+  my $ret = XML::Parser::Expat::ParsePartial($self->{Parser}, $data);
+
+  croak $self->{ErrorMessage} unless $ret;
+}
+
+sub parse_done {
+  my $self = shift;
+
+  my $ret = XML::Parser::Expat::ParseDone($self->{Parser});
+  unless ($ret) {
+    my $msg = $self->{ErrorMessage};
+    $self->release;
+    croak $msg;
+  }
+
+  $self->{_State_} = 2;
+
+  my $result = $ret;
+  my @result = ();
+  my $final = $self->{FinalHandler};
+  if (defined $final) {
+    if (wantarray) {
+      @result = &$final($self);
+    }
+    else {
+      $result = &$final($self);
+    }
+  }
+
+  $self->release;
+
+  return unless defined wantarray;
+  return wantarray ? @result : $result;
+}
+
+################################################################
+
+package XML::Parser::Encinfo;
+
+sub DESTROY {
+  my $self = shift;
+  XML::Parser::Expat::FreeEncoding($self);
+}
+
+1;
+
+__END__
+
+=head1 NAME
+
+XML::Parser::Expat - Lowlevel access to James Clark's expat XML parser
+
+=head1 SYNOPSIS
+
+ use XML::Parser::Expat;
+
+ $parser = new XML::Parser::Expat;
+ $parser->setHandlers('Start' => \&sh,
+                      'End'   => \&eh,
+                      'Char'  => \&ch);
+ open(FOO, 'info.xml') or die "Couldn't open";
+ $parser->parse(*FOO);
+ close(FOO);
+ # $parser->parse('<foo id="me"> here <em>we</em> go </foo>');
+
+ sub sh
+ {
+   my ($p, $el, %atts) = @_;
+   $p->setHandlers('Char' => \&spec)
+     if ($el eq 'special');
+   ...
+ }
+
+ sub eh
+ {
+   my ($p, $el) = @_;
+   $p->setHandlers('Char' => \&ch)  # Special elements won't contain
+     if ($el eq 'special');         # other special elements
+   ...
+ } 
+
+=head1 DESCRIPTION
+
+This module provides an interface to James Clark's XML parser, expat. As in
+expat, a single instance of the parser can only parse one document. Calls
+to parsestring after the first for a given instance will die.
+
+Expat (and XML::Parser::Expat) are event based. As the parser recognizes
+parts of the document (say the start or end of an XML element), then any
+handlers registered for that type of an event are called with suitable
+parameters.
+
+=head1 METHODS
+
+=over 4
+
+=item new
+
+This is a class method, the constructor for XML::Parser::Expat. Options are
+passed as keyword value pairs. The recognized options are:
+
+=over 4
+
+=item * ProtocolEncoding
+
+The protocol encoding name. The default is none. The expat built-in
+encodings are: C<UTF-8>, C<ISO-8859-1>, C<UTF-16>, and C<US-ASCII>.
+Other encodings may be used if they have encoding maps in one of the
+directories in the @Encoding_Path list. Setting the protocol encoding
+overrides any encoding in the XML declaration.
+
+=item * Namespaces
+
+When this option is given with a true value, then the parser does namespace
+processing. By default, namespace processing is turned off. When it is
+turned on, the parser consumes I<xmlns> attributes and strips off prefixes
+from element and attributes names where those prefixes have a defined
+namespace. A name's namespace can be found using the L<"namespace"> method
+and two names can be checked for absolute equality with the L<"eq_name">
+method.
+
+=item * NoExpand
+
+Normally, the parser will try to expand references to entities defined in
+the internal subset. If this option is set to a true value, and a default
+handler is also set, then the default handler will be called when an
+entity reference is seen in text. This has no effect if a default handler
+has not been registered, and it has no effect on the expansion of entity
+references inside attribute values.
+
+=item * Stream_Delimiter
+
+This option takes a string value. When this string is found alone on a line
+while parsing from a stream, then the parse is ended as if it saw an end of
+file. The intended use is with a stream of xml documents in a MIME multipart
+format. The string should not contain a trailing newline.
+
+=item * ErrorContext
+
+When this option is defined, errors are reported in context. The value
+of ErrorContext should be the number of lines to show on either side of
+the line in which the error occurred.
+
+=item * ParseParamEnt
+
+Unless standalone is set to "yes" in the XML declaration, setting this to
+a true value allows the external DTD to be read, and parameter entities
+to be parsed and expanded.
+
+=item * Base
+
+The base to use for relative pathnames or URLs. This can also be done by
+using the base method.
+
+=back
+
+=item setHandlers(TYPE, HANDLER [, TYPE, HANDLER [...]])
+
+This method registers handlers for the various events. If no handlers are
+registered, then a call to parsestring or parsefile will only determine if
+the corresponding XML document is well formed (by returning without error.)
+This may be called from within a handler, after the parse has started.
+
+Setting a handler to something that evaluates to false unsets that
+handler.
+
+This method returns a list of type, handler pairs corresponding to the
+input. The handlers returned are the ones that were in effect before the
+call to setHandlers.
+
+The recognized events and the parameters passed to the corresponding
+handlers are:
+
+=over 4
+
+=item * Start             (Parser, Element [, Attr, Val [,...]])
+
+This event is generated when an XML start tag is recognized. Parser is
+an XML::Parser::Expat instance. Element is the name of the XML element that
+is opened with the start tag. The Attr & Val pairs are generated for each
+attribute in the start tag.
+
+=item * End               (Parser, Element)
+
+This event is generated when an XML end tag is recognized. Note that
+an XML empty tag (<foo/>) generates both a start and an end event.
+
+There is always a lower level start and end handler installed that wrap
+the corresponding callbacks. This is to handle the context mechanism.
+A consequence of this is that the default handler (see below) will not
+see a start tag or end tag unless the default_current method is called.
+
+=item * Char              (Parser, String)
+
+This event is generated when non-markup is recognized. The non-markup
+sequence of characters is in String. A single non-markup sequence of
+characters may generate multiple calls to this handler. Whatever the
+encoding of the string in the original document, this is given to the
+handler in UTF-8.
+
+=item * Proc              (Parser, Target, Data)
+
+This event is generated when a processing instruction is recognized.
+
+=item * Comment           (Parser, String)
+
+This event is generated when a comment is recognized.
+
+=item * CdataStart        (Parser)
+
+This is called at the start of a CDATA section.
+
+=item * CdataEnd          (Parser)
+
+This is called at the end of a CDATA section.
+
+=item * Default           (Parser, String)
+
+This is called for any characters that don't have a registered handler.
+This includes both characters that are part of markup for which no
+events are generated (markup declarations) and characters that
+could generate events, but for which no handler has been registered.
+
+Whatever the encoding in the original document, the string is returned to
+the handler in UTF-8.
+
+=item * Unparsed          (Parser, Entity, Base, Sysid, Pubid, Notation)
+
+This is called for a declaration of an unparsed entity. Entity is the name
+of the entity. Base is the base to be used for resolving a relative URI.
+Sysid is the system id. Pubid is the public id. Notation is the notation
+name. Base and Pubid may be undefined.
+
+=item * Notation          (Parser, Notation, Base, Sysid, Pubid)
+
+This is called for a declaration of notation. Notation is the notation name.
+Base is the base to be used for resolving a relative URI. Sysid is the system
+id. Pubid is the public id. Base, Sysid, and Pubid may all be undefined.
+
+=item * ExternEnt         (Parser, Base, Sysid, Pubid)
+
+This is called when an external entity is referenced. Base is the base to be
+used for resolving a relative URI. Sysid is the system id. Pubid is the public
+id. Base, and Pubid may be undefined.
+
+This handler should either return a string, which represents the contents of
+the external entity, or return an open filehandle that can be read to obtain
+the contents of the external entity, or return undef, which indicates the
+external entity couldn't be found and will generate a parse error.
+
+If an open filehandle is returned, it must be returned as either a glob
+(*FOO) or as a reference to a glob (e.g. an instance of IO::Handle).
+
+=item * ExternEntFin      (Parser)
+
+This is called after an external entity has been parsed. It allows
+applications to perform cleanup on actions performed in the above
+ExternEnt handler.
+
+=item * Entity            (Parser, Name, Val, Sysid, Pubid, Ndata, IsParam)
+
+This is called when an entity is declared. For internal entities, the Val
+parameter will contain the value and the remaining three parameters will
+be undefined. For external entities, the Val parameter
+will be undefined, the Sysid parameter will have the system id, the Pubid
+parameter will have the public id if it was provided (it will be undefined
+otherwise), the Ndata parameter will contain the notation for unparsed
+entities. If this is a parameter entity declaration, then the IsParam
+parameter is true.
+
+Note that this handler and the Unparsed handler above overlap. If both are
+set, then this handler will not be called for unparsed entities.
+
+=item * Element           (Parser, Name, Model)
+
+The element handler is called when an element declaration is found. Name is
+the element name, and Model is the content model as an
+XML::Parser::ContentModel object. See L<"XML::Parser::ContentModel Methods">
+for methods available for this class.
+
+=item * Attlist           (Parser, Elname, Attname, Type, Default, Fixed)
+
+This handler is called for each attribute in an ATTLIST declaration.
+So an ATTLIST declaration that has multiple attributes
+will generate multiple calls to this handler. The Elname parameter is the
+name of the element with which the attribute is being associated. The Attname
+parameter is the name of the attribute. Type is the attribute type, given as
+a string. Default is the default value, which will either be "#REQUIRED",
+"#IMPLIED" or a quoted string (i.e. the returned string will begin and end
+with a quote character). If Fixed is true, then this is a fixed attribute.
+
+=item * Doctype           (Parser, Name, Sysid, Pubid, Internal)
+
+This handler is called for DOCTYPE declarations. Name is the document type
+name. Sysid is the system id of the document type, if it was provided,
+otherwise it's undefined. Pubid is the public id of the document type,
+which will be undefined if no public id was given. Internal will be
+true or false, indicating whether or not the doctype declaration contains
+an internal subset.
+
+=item * DoctypeFin        (Parser)
+
+This handler is called after parsing of the DOCTYPE declaration has finished,
+including any internal or external DTD declarations.
+
+=item * XMLDecl           (Parser, Version, Encoding, Standalone)
+
+This handler is called for XML declarations. Version is a string containg
+the version. Encoding is either undefined or contains an encoding string.
+Standalone is either undefined, or true or false. Undefined indicates
+that no standalone parameter was given in the XML declaration. True or
+false indicates "yes" or "no" respectively.
+
+=back
+
+=item namespace(name)
+
+Return the URI of the namespace that the name belongs to. If the name doesn't
+belong to any namespace, an undef is returned. This is only valid on names
+received through the Start or End handlers from a single document, or through
+a call to the generate_ns_name method. In other words, don't use names
+generated from one instance of XML::Parser::Expat with other instances.
+
+=item eq_name(name1, name2)
+
+Return true if name1 and name2 are identical (i.e. same name and from
+the same namespace.) This is only meaningful if both names were obtained
+through the Start or End handlers from a single document, or through
+a call to the generate_ns_name method.
+
+=item generate_ns_name(name, namespace)
+
+Return a name, associated with a given namespace, good for using with the
+above 2 methods. The namespace argument should be the namespace URI, not
+a prefix.
+
+=item new_ns_prefixes
+
+When called from a start tag handler, returns namespace prefixes declared
+with this start tag. If called elsewere (or if there were no namespace
+prefixes declared), it returns an empty list. Setting of the default
+namespace is indicated with '#default' as a prefix.
+
+=item expand_ns_prefix(prefix)
+
+Return the uri to which the given prefix is currently bound. Returns
+undef if the prefix isn't currently bound. Use '#default' to find the
+current binding of the default namespace (if any).
+
+=item current_ns_prefixes
+
+Return a list of currently bound namespace prefixes. The order of the
+the prefixes in the list has no meaning. If the default namespace is
+currently bound, '#default' appears in the list.
+
+=item recognized_string
+
+Returns the string from the document that was recognized in order to call
+the current handler. For instance, when called from a start handler, it
+will give us the the start-tag string. The string is encoded in UTF-8.
+This method doesn't return a meaningful string inside declaration handlers.
+
+=item original_string
+
+Returns the verbatim string from the document that was recognized in
+order to call the current handler. The string is in the original document
+encoding. This method doesn't return a meaningful string inside declaration
+handlers.
+
+=item default_current
+
+When called from a handler, causes the sequence of characters that generated
+the corresponding event to be sent to the default handler (if one is
+registered). Use of this method is deprecated in favor the recognized_string
+method, which you can use without installing a default handler. This
+method doesn't deliver a meaningful string to the default handler when
+called from inside declaration handlers.
+
+=item xpcroak(message)
+
+Concatenate onto the given message the current line number within the
+XML document plus the message implied by ErrorContext. Then croak with
+the formed message.
+
+=item xpcarp(message)
+
+Concatenate onto the given message the current line number within the
+XML document plus the message implied by ErrorContext. Then carp with
+the formed message.
+
+=item current_line
+
+Returns the line number of the current position of the parse.
+
+=item current_column
+
+Returns the column number of the current position of the parse.
+
+=item current_byte
+
+Returns the current position of the parse.
+
+=item base([NEWBASE]);
+
+Returns the current value of the base for resolving relative URIs. If
+NEWBASE is supplied, changes the base to that value.
+
+=item context
+
+Returns a list of element names that represent open elements, with the
+last one being the innermost. Inside start and end tag handlers, this
+will be the tag of the parent element.
+
+=item current_element
+
+Returns the name of the innermost currently opened element. Inside
+start or end handlers, returns the parent of the element associated
+with those tags.
+
+=item in_element(NAME)
+
+Returns true if NAME is equal to the name of the innermost currently opened
+element. If namespace processing is being used and you want to check
+against a name that may be in a namespace, then use the generate_ns_name
+method to create the NAME argument.
+
+=item within_element(NAME)
+
+Returns the number of times the given name appears in the context list.
+If namespace processing is being used and you want to check
+against a name that may be in a namespace, then use the generate_ns_name
+method to create the NAME argument.
+
+=item depth
+
+Returns the size of the context list.
+
+=item element_index
+
+Returns an integer that is the depth-first visit order of the current
+element. This will be zero outside of the root element. For example,
+this will return 1 when called from the start handler for the root element
+start tag.
+
+=item skip_until(INDEX)
+
+INDEX is an integer that represents an element index. When this method
+is called, all handlers are suspended until the start tag for an element
+that has an index number equal to INDEX is seen. If a start handler has
+been set, then this is the first tag that the start handler will see
+after skip_until has been called.
+
+
+=item position_in_context(LINES)
+
+Returns a string that shows the current parse position. LINES should be
+an integer >= 0 that represents the number of lines on either side of the
+current parse line to place into the returned string.
+
+=item xml_escape(TEXT [, CHAR [, CHAR ...]])
+
+Returns TEXT with markup characters turned into character entities. Any
+additional characters provided as arguments are also turned into character
+references where found in TEXT.
+
+=item parse (SOURCE)
+
+The SOURCE parameter should either be a string containing the whole XML
+document, or it should be an open IO::Handle. Only a single document
+may be parsed for a given instance of XML::Parser::Expat, so this will croak
+if it's been called previously for this instance.
+
+=item parsestring(XML_DOC_STRING)
+
+Parses the given string as an XML document. Only a single document may be
+parsed for a given instance of XML::Parser::Expat, so this will die if either
+parsestring or parsefile has been called for this instance previously.
+
+This method is deprecated in favor of the parse method.
+
+=item parsefile(FILENAME)
+
+Parses the XML document in the given file. Will die if parsestring or
+parsefile has been called previously for this instance.
+
+=item is_defaulted(ATTNAME)
+
+NO LONGER WORKS. To find out if an attribute is defaulted please use
+the specified_attr method.
+
+=item specified_attr
+
+When the start handler receives lists of attributes and values, the
+non-defaulted (i.e. explicitly specified) attributes occur in the list
+first. This method returns the number of specified items in the list.
+So if this number is equal to the length of the list, there were no
+defaulted values. Otherwise the number points to the index of the
+first defaulted attribute name.
+
+=item finish
+
+Unsets all handlers (including internal ones that set context), but expat
+continues parsing to the end of the document or until it finds an error.
+It should finish up a lot faster than with the handlers set.
+
+=item release
+
+There are data structures used by XML::Parser::Expat that have circular
+references. This means that these structures will never be garbage
+collected unless these references are explicitly broken. Calling this
+method breaks those references (and makes the instance unusable.)
+
+Normally, higher level calls handle this for you, but if you are using
+XML::Parser::Expat directly, then it's your responsibility to call it.
+
+=back
+
+=head2 XML::Parser::ContentModel Methods
+
+The element declaration handlers are passed objects of this class as the
+content model of the element declaration. They also represent content
+particles, components of a content model.
+
+When referred to as a string, these objects are automagicly converted to a
+string representation of the model (or content particle).
+
+=over 4
+
+=item isempty
+
+This method returns true if the object is "EMPTY", false otherwise.
+
+=item isany
+
+This method returns true if the object is "ANY", false otherwise.
+
+=item ismixed
+
+This method returns true if the object is "(#PCDATA)" or "(#PCDATA|...)*",
+false otherwise.
+
+=item isname
+
+This method returns if the object is an element name.
+
+=item ischoice
+
+This method returns true if the object is a choice of content particles.
+
+
+=item isseq
+
+This method returns true if the object is a sequence of content particles.
+
+=item quant
+
+This method returns undef or a string representing the quantifier
+('?', '*', '+') associated with the model or particle.
+
+=item children
+
+This method returns undef or (for mixed, choice, and sequence types)
+an array of component content particles. There will always be at least
+one component for choices and sequences, but for a mixed content model
+of pure PCDATA, "(#PCDATA)", then an undef is returned.
+
+=back
+
+=head2 XML::Parser::ExpatNB Methods
+
+The class XML::Parser::ExpatNB is a subclass of XML::Parser::Expat used
+for non-blocking access to the expat library. It does not support the parse,
+parsestring, or parsefile methods, but it does have these additional methods:
+
+=over 4
+
+=item parse_more(DATA)
+
+Feed expat more text to munch on.
+
+=item parse_done
+
+Tell expat that it's gotten the whole document.
+
+=back
+
+=head1 FUNCTIONS
+
+=over 4
+
+=item XML::Parser::Expat::load_encoding(ENCODING)
+
+Load an external encoding. ENCODING is either the name of an encoding or
+the name of a file. The basename is converted to lowercase and a '.enc'
+extension is appended unless there's one already there. Then, unless
+it's an absolute pathname (i.e. begins with '/'), the first file by that
+name discovered in the @Encoding_Path path list is used.
+
+The encoding in the file is loaded and kept in the %Encoding_Table
+table. Earlier encodings of the same name are replaced.
+
+This function is automaticly called by expat when it encounters an encoding
+it doesn't know about. Expat shouldn't call this twice for the same
+encoding name. The only reason users should use this function is to
+explicitly load an encoding not contained in the @Encoding_Path list.
+
+=back
+
+=head1 AUTHORS
+
+Larry Wall <F<larry@wall.org>> wrote version 1.0.
+
+Clark Cooper <F<coopercc@netheaven.com>> picked up support, changed the API
+for this version (2.x), provided documentation, and added some standard
+package features.
+
+=cut
diff -rupN RELEASE-1.5.5/XML/Parser.pm ROUGE-1.5.5/XML/Parser.pm
--- RELEASE-1.5.5/XML/Parser.pm	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/XML/Parser.pm	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,840 @@
+# XML::Parser
+#
+# Copyright (c) 1998-2000 Larry Wall and Clark Cooper
+# All rights reserved.
+#
+# This program is free software; you can redistribute it and/or
+# modify it under the same terms as Perl itself.
+
+package XML::Parser;
+
+use Carp;
+
+BEGIN {
+  require XML::Parser::Expat;
+  $VERSION = '2.36';
+  die "Parser.pm and Expat.pm versions don't match"
+    unless $VERSION eq $XML::Parser::Expat::VERSION;
+}
+
+use strict;
+
+use vars qw($VERSION $LWP_load_failed);
+
+$LWP_load_failed = 0;
+
+sub new {
+  my ($class, %args) = @_;
+  my $style = $args{Style};
+  
+  my $nonexopt = $args{Non_Expat_Options} ||= {};
+  
+  $nonexopt->{Style}             = 1;
+  $nonexopt->{Non_Expat_Options} = 1;
+  $nonexopt->{Handlers}          = 1;
+  $nonexopt->{_HNDL_TYPES}       = 1;
+  $nonexopt->{NoLWP}             = 1;
+  
+  $args{_HNDL_TYPES} = {%XML::Parser::Expat::Handler_Setters};
+  $args{_HNDL_TYPES}->{Init} = 1;
+  $args{_HNDL_TYPES}->{Final} = 1;
+  
+  $args{Handlers} ||= {};
+  my $handlers = $args{Handlers};
+  
+  if (defined($style)) {
+    my $stylepkg = $style;
+    
+    if ($stylepkg !~ /::/) {
+      $stylepkg = "\u$style";
+      
+      eval {
+          my $fullpkg = 'XML::Parser::Style::' . $stylepkg;
+          my $stylefile = $fullpkg;
+          $stylefile =~ s/::/\//g;
+          require "$stylefile.pm";
+          $stylepkg = $fullpkg;
+      };
+      if ($@) {
+          # fallback to old behaviour
+          $stylepkg = 'XML::Parser::' . $stylepkg;
+      }
+    }
+    
+    my $htype;
+    foreach $htype (keys %{$args{_HNDL_TYPES}}) {
+      # Handlers explicity given override
+      # handlers from the Style package
+      unless (defined($handlers->{$htype})) {
+        
+        # A handler in the style package must either have
+        # exactly the right case as the type name or a
+        # completely lower case version of it.
+        
+        my $hname = "${stylepkg}::$htype";
+        if (defined(&$hname)) {
+          $handlers->{$htype} = \&$hname;
+          next;
+        }
+        
+        $hname = "${stylepkg}::\L$htype";
+        if (defined(&$hname)) {
+          $handlers->{$htype} = \&$hname;
+          next;
+        }
+      }
+    }
+  }
+  
+  unless (defined($handlers->{ExternEnt})
+          or defined ($handlers->{ExternEntFin})) {
+    
+    if ($args{NoLWP} or $LWP_load_failed) {
+      $handlers->{ExternEnt} = \&file_ext_ent_handler;
+      $handlers->{ExternEntFin} = \&file_ext_ent_cleanup;
+    }
+    else {
+      # The following just bootstraps the real LWP external entity
+      # handler
+
+      $handlers->{ExternEnt} = \&initial_ext_ent_handler;
+
+      # No cleanup function available until LWPExternEnt.pl loaded
+    }
+  }
+
+  $args{Pkg} ||= caller;
+  bless \%args, $class;
+}                                # End of new
+
+sub setHandlers {
+  my ($self, @handler_pairs) = @_;
+  
+  croak("Uneven number of arguments to setHandlers method")
+    if (int(@handler_pairs) & 1);
+  
+  my @ret;
+  while (@handler_pairs) {
+    my $type = shift @handler_pairs;
+    my $handler = shift @handler_pairs;
+    unless (defined($self->{_HNDL_TYPES}->{$type})) {
+      my @types = sort keys %{$self->{_HNDL_TYPES}};
+      
+      croak("Unknown Parser handler type: $type\n Valid types: @types");
+    }
+    push(@ret, $type, $self->{Handlers}->{$type});
+    $self->{Handlers}->{$type} = $handler;
+  }
+
+  return @ret;
+}
+
+sub parse_start {
+  my $self = shift;
+  my @expat_options = ();
+
+  my ($key, $val);
+  while (($key, $val) = each %{$self}) {
+    push (@expat_options, $key, $val)
+      unless exists $self->{Non_Expat_Options}->{$key};
+  }
+
+  my %handlers = %{$self->{Handlers}};
+  my $init = delete $handlers{Init};
+  my $final = delete $handlers{Final};
+
+  my $expatnb = new XML::Parser::ExpatNB(@expat_options, @_);
+  $expatnb->setHandlers(%handlers);
+
+  &$init($expatnb)
+    if defined($init);
+
+  $expatnb->{_State_} = 1;
+
+  $expatnb->{FinalHandler} = $final
+    if defined($final);
+
+  return $expatnb;
+}
+
+sub parse {
+  my $self = shift;
+  my $arg  = shift;
+  my @expat_options = ();
+  my ($key, $val);
+  while (($key, $val) = each %{$self}) {
+    push(@expat_options, $key, $val)
+      unless exists $self->{Non_Expat_Options}->{$key};
+  }
+  
+  my $expat = new XML::Parser::Expat(@expat_options, @_);
+  my %handlers = %{$self->{Handlers}};
+  my $init = delete $handlers{Init};
+  my $final = delete $handlers{Final};
+  
+  $expat->setHandlers(%handlers);
+  
+  if ($self->{Base}) {
+    $expat->base($self->{Base});
+  }
+
+  &$init($expat)
+    if defined($init);
+  
+  my @result = ();
+  my $result;
+  eval {
+    $result = $expat->parse($arg);
+  };
+  my $err = $@;
+  if ($err) {
+    $expat->release;
+    die $err;
+  }
+  
+  if ($result and defined($final)) {
+    if (wantarray) {
+      @result = &$final($expat);
+    }
+    else {
+      $result = &$final($expat);
+    }
+  }
+  
+  $expat->release;
+
+  return unless defined wantarray;
+  return wantarray ? @result : $result;
+}
+
+sub parsestring {
+  my $self = shift;
+  $self->parse(@_);
+}
+
+sub parsefile {
+  my $self = shift;
+  my $file = shift;
+  local(*FILE);
+  open(FILE, $file) or  croak "Couldn't open $file:\n$!";
+  binmode(FILE);
+  my @ret;
+  my $ret;
+
+  $self->{Base} = $file;
+
+  if (wantarray) {
+    eval {
+      @ret = $self->parse(*FILE, @_);
+    };
+  }
+  else {
+    eval {
+      $ret = $self->parse(*FILE, @_);
+    };
+  }
+  my $err = $@;
+  close(FILE);
+  die $err if $err;
+  
+  return unless defined wantarray;
+  return wantarray ? @ret : $ret;
+}
+
+sub initial_ext_ent_handler {
+  # This just bootstraps in the real lwp_ext_ent_handler which
+  # also loads the URI and LWP modules.
+
+  unless ($LWP_load_failed) {
+    local($^W) = 0;
+
+    my $stat =
+      eval {
+        require('XML/Parser/LWPExternEnt.pl');
+      };
+      
+    if ($stat) {
+      $_[0]->setHandlers(ExternEnt    => \&lwp_ext_ent_handler,
+                         ExternEntFin => \&lwp_ext_ent_cleanup);
+                       
+      goto &lwp_ext_ent_handler;
+    }
+
+    # Failed to load lwp handler, act as if NoLWP
+
+    $LWP_load_failed = 1;
+
+    my $cmsg = "Couldn't load LWP based external entity handler\n";
+    $cmsg .= "Switching to file-based external entity handler\n";
+    $cmsg .= " (To avoid this message, use NoLWP option to XML::Parser)\n";
+    warn($cmsg);
+  }
+
+  $_[0]->setHandlers(ExternEnt    => \&file_ext_ent_handler,
+                     ExternEntFin => \&file_ext_ent_cleanup);
+  goto &file_ext_ent_handler;
+
+}
+
+sub file_ext_ent_handler {
+  my ($xp, $base, $path) = @_;
+
+  # Prepend base only for relative paths
+
+  if (defined($base)
+      and not ($path =~ m!^(?:[\\/]|\w+:)!))
+    {
+      my $newpath = $base;
+      $newpath =~ s![^\\/:]*$!$path!;
+      $path = $newpath;
+    }
+
+  if ($path =~ /^\s*[|>+]/
+      or $path =~ /\|\s*$/) {
+    $xp->{ErrorMessage}
+        .= "System ID ($path) contains Perl IO control characters";
+    return undef;
+  }
+
+  require IO::File;
+  my $fh = new IO::File($path);
+  unless (defined $fh) {
+    $xp->{ErrorMessage}
+      .= "Failed to open $path:\n$!";
+    return undef;
+  }
+
+  $xp->{_BaseStack} ||= [];
+  $xp->{_FhStack} ||= [];
+
+  push(@{$xp->{_BaseStack}}, $base);
+  push(@{$xp->{_FhStack}}, $fh);
+
+  $xp->base($path);
+  
+  return $fh;
+}
+
+sub file_ext_ent_cleanup {
+  my ($xp) = @_;
+
+  my $fh = pop(@{$xp->{_FhStack}});
+  $fh->close;
+
+  my $base = pop(@{$xp->{_BaseStack}});
+  $xp->base($base);
+}
+
+1;
+
+__END__
+
+=head1 NAME
+
+XML::Parser - A perl module for parsing XML documents
+
+=head1 SYNOPSIS
+
+  use XML::Parser;
+  
+  $p1 = new XML::Parser(Style => 'Debug');
+  $p1->parsefile('REC-xml-19980210.xml');
+  $p1->parse('<foo id="me">Hello World</foo>');
+
+  # Alternative
+  $p2 = new XML::Parser(Handlers => {Start => \&handle_start,
+                                     End   => \&handle_end,
+                                     Char  => \&handle_char});
+  $p2->parse($socket);
+
+  # Another alternative
+  $p3 = new XML::Parser(ErrorContext => 2);
+
+  $p3->setHandlers(Char    => \&text,
+                   Default => \&other);
+
+  open(FOO, 'xmlgenerator |');
+  $p3->parse(*FOO, ProtocolEncoding => 'ISO-8859-1');
+  close(FOO);
+
+  $p3->parsefile('junk.xml', ErrorContext => 3);
+
+=begin man
+.ds PI PI
+
+=end man
+
+=head1 DESCRIPTION
+
+This module provides ways to parse XML documents. It is built on top of
+L<XML::Parser::Expat>, which is a lower level interface to James Clark's
+expat library. Each call to one of the parsing methods creates a new
+instance of XML::Parser::Expat which is then used to parse the document.
+Expat options may be provided when the XML::Parser object is created.
+These options are then passed on to the Expat object on each parse call.
+They can also be given as extra arguments to the parse methods, in which
+case they override options given at XML::Parser creation time.
+
+The behavior of the parser is controlled either by C<L</Style>> and/or
+C<L</Handlers>> options, or by L</setHandlers> method. These all provide
+mechanisms for XML::Parser to set the handlers needed by XML::Parser::Expat.
+If neither C<Style> nor C<Handlers> are specified, then parsing just
+checks the document for being well-formed.
+
+When underlying handlers get called, they receive as their first parameter
+the I<Expat> object, not the Parser object.
+
+=head1 METHODS
+
+=over 4
+
+=item new
+
+This is a class method, the constructor for XML::Parser. Options are passed
+as keyword value pairs. Recognized options are:
+
+=over 4
+
+=item * Style
+
+This option provides an easy way to create a given style of parser. The
+built in styles are: L<"Debug">, L<"Subs">, L<"Tree">, L<"Objects">,
+and L<"Stream">. These are all defined in separate packages under
+C<XML::Parser::Style::*>, and you can find further documentation for
+each style both below, and in those packages.
+
+Custom styles can be provided by giving a full package name containing
+at least one '::'. This package should then have subs defined for each
+handler it wishes to have installed. See L<"STYLES"> below
+for a discussion of each built in style.
+
+=item * Handlers
+
+When provided, this option should be an anonymous hash containing as
+keys the type of handler and as values a sub reference to handle that
+type of event. All the handlers get passed as their 1st parameter the
+instance of expat that is parsing the document. Further details on
+handlers can be found in L<"HANDLERS">. Any handler set here
+overrides the corresponding handler set with the Style option.
+
+=item * Pkg
+
+Some styles will refer to subs defined in this package. If not provided,
+it defaults to the package which called the constructor.
+
+=item * ErrorContext
+
+This is an Expat option. When this option is defined, errors are reported
+in context. The value should be the number of lines to show on either side
+of the line in which the error occurred.
+
+=item * ProtocolEncoding
+
+This is an Expat option. This sets the protocol encoding name. It defaults
+to none. The built-in encodings are: C<UTF-8>, C<ISO-8859-1>, C<UTF-16>, and
+C<US-ASCII>. Other encodings may be used if they have encoding maps in one
+of the directories in the @Encoding_Path list. Check L<"ENCODINGS"> for
+more information on encoding maps. Setting the protocol encoding overrides
+any encoding in the XML declaration.
+
+=item * Namespaces
+
+This is an Expat option. If this is set to a true value, then namespace
+processing is done during the parse. See L<XML::Parser::Expat/"Namespaces">
+for further discussion of namespace processing.
+
+=item * NoExpand
+
+This is an Expat option. Normally, the parser will try to expand references
+to entities defined in the internal subset. If this option is set to a true
+value, and a default handler is also set, then the default handler will be
+called when an entity reference is seen in text. This has no effect if a
+default handler has not been registered, and it has no effect on the expansion
+of entity references inside attribute values.
+
+=item * Stream_Delimiter
+
+This is an Expat option. It takes a string value. When this string is found
+alone on a line while parsing from a stream, then the parse is ended as if it
+saw an end of file. The intended use is with a stream of xml documents in a
+MIME multipart format. The string should not contain a trailing newline.
+
+=item * ParseParamEnt
+
+This is an Expat option. Unless standalone is set to "yes" in the XML
+declaration, setting this to a true value allows the external DTD to be read,
+and parameter entities to be parsed and expanded.
+
+=item * NoLWP
+
+This option has no effect if the ExternEnt or ExternEntFin handlers are
+directly set. Otherwise, if true, it forces the use of a file based external
+entity handler.
+
+=item * Non-Expat-Options
+
+If provided, this should be an anonymous hash whose keys are options that
+shouldn't be passed to Expat. This should only be of concern to those
+subclassing XML::Parser.
+
+=back
+
+=item  setHandlers(TYPE, HANDLER [, TYPE, HANDLER [...]])
+
+This method registers handlers for various parser events. It overrides any
+previous handlers registered through the Style or Handler options or through
+earlier calls to setHandlers. By providing a false or undefined value as
+the handler, the existing handler can be unset.
+
+This method returns a list of type, handler pairs corresponding to the
+input. The handlers returned are the ones that were in effect prior to
+the call.
+
+See a description of the handler types in L<"HANDLERS">.
+
+=item parse(SOURCE [, OPT => OPT_VALUE [...]])
+
+The SOURCE parameter should either be a string containing the whole XML
+document, or it should be an open IO::Handle. Constructor options to
+XML::Parser::Expat given as keyword-value pairs may follow the SOURCE
+parameter. These override, for this call, any options or attributes passed
+through from the XML::Parser instance.
+
+A die call is thrown if a parse error occurs. Otherwise it will return 1
+or whatever is returned from the B<Final> handler, if one is installed.
+In other words, what parse may return depends on the style.
+
+=item parsestring
+
+This is just an alias for parse for backwards compatibility.
+
+=item parsefile(FILE [, OPT => OPT_VALUE [...]])
+
+Open FILE for reading, then call parse with the open handle. The file
+is closed no matter how parse returns. Returns what parse returns.
+
+=item parse_start([ OPT => OPT_VALUE [...]])
+
+Create and return a new instance of XML::Parser::ExpatNB. Constructor
+options may be provided. If an init handler has been provided, it is
+called before returning the ExpatNB object. Documents are parsed by
+making incremental calls to the parse_more method of this object, which
+takes a string. A single call to the parse_done method of this object,
+which takes no arguments, indicates that the document is finished.
+
+If there is a final handler installed, it is executed by the parse_done
+method before returning and the parse_done method returns whatever is
+returned by the final handler.
+
+=back
+
+=head1 HANDLERS
+
+Expat is an event based parser. As the parser recognizes parts of the
+document (say the start or end tag for an XML element), then any handlers
+registered for that type of an event are called with suitable parameters.
+All handlers receive an instance of XML::Parser::Expat as their first
+argument. See L<XML::Parser::Expat/"METHODS"> for a discussion of the
+methods that can be called on this object.
+
+=head2 Init                (Expat)
+
+This is called just before the parsing of the document starts.
+
+=head2 Final                (Expat)
+
+This is called just after parsing has finished, but only if no errors
+occurred during the parse. Parse returns what this returns.
+
+=head2 Start                (Expat, Element [, Attr, Val [,...]])
+
+This event is generated when an XML start tag is recognized. Element is the
+name of the XML element type that is opened with the start tag. The Attr &
+Val pairs are generated for each attribute in the start tag.
+
+=head2 End                (Expat, Element)
+
+This event is generated when an XML end tag is recognized. Note that
+an XML empty tag (<foo/>) generates both a start and an end event.
+
+=head2 Char                (Expat, String)
+
+This event is generated when non-markup is recognized. The non-markup
+sequence of characters is in String. A single non-markup sequence of
+characters may generate multiple calls to this handler. Whatever the
+encoding of the string in the original document, this is given to the
+handler in UTF-8.
+
+=head2 Proc                (Expat, Target, Data)
+
+This event is generated when a processing instruction is recognized.
+
+=head2 Comment                (Expat, Data)
+
+This event is generated when a comment is recognized.
+
+=head2 CdataStart        (Expat)
+
+This is called at the start of a CDATA section.
+
+=head2 CdataEnd                (Expat)
+
+This is called at the end of a CDATA section.
+
+=head2 Default                (Expat, String)
+
+This is called for any characters that don't have a registered handler.
+This includes both characters that are part of markup for which no
+events are generated (markup declarations) and characters that
+could generate events, but for which no handler has been registered.
+
+Whatever the encoding in the original document, the string is returned to
+the handler in UTF-8.
+
+=head2 Unparsed                (Expat, Entity, Base, Sysid, Pubid, Notation)
+
+This is called for a declaration of an unparsed entity. Entity is the name
+of the entity. Base is the base to be used for resolving a relative URI.
+Sysid is the system id. Pubid is the public id. Notation is the notation
+name. Base and Pubid may be undefined.
+
+=head2 Notation                (Expat, Notation, Base, Sysid, Pubid)
+
+This is called for a declaration of notation. Notation is the notation name.
+Base is the base to be used for resolving a relative URI. Sysid is the system
+id. Pubid is the public id. Base, Sysid, and Pubid may all be undefined.
+
+=head2 ExternEnt        (Expat, Base, Sysid, Pubid)
+
+This is called when an external entity is referenced. Base is the base to be
+used for resolving a relative URI. Sysid is the system id. Pubid is the public
+id. Base, and Pubid may be undefined.
+
+This handler should either return a string, which represents the contents of
+the external entity, or return an open filehandle that can be read to obtain
+the contents of the external entity, or return undef, which indicates the
+external entity couldn't be found and will generate a parse error.
+
+If an open filehandle is returned, it must be returned as either a glob
+(*FOO) or as a reference to a glob (e.g. an instance of IO::Handle).
+
+A default handler is installed for this event. The default handler is
+XML::Parser::lwp_ext_ent_handler unless the NoLWP option was provided with
+a true value, otherwise XML::Parser::file_ext_ent_handler is the default
+handler for external entities. Even without the NoLWP option, if the
+URI or LWP modules are missing, the file based handler ends up being used
+after giving a warning on the first external entity reference.
+
+The LWP external entity handler will use proxies defined in the environment
+(http_proxy, ftp_proxy, etc.).
+
+Please note that the LWP external entity handler reads the entire
+entity into a string and returns it, where as the file handler opens a
+filehandle.
+
+Also note that the file external entity handler will likely choke on
+absolute URIs or file names that don't fit the conventions of the local
+operating system.
+
+The expat base method can be used to set a basename for
+relative pathnames. If no basename is given, or if the basename is itself
+a relative name, then it is relative to the current working directory.
+
+=head2 ExternEntFin        (Expat)
+
+This is called after parsing an external entity. It's not called unless
+an ExternEnt handler is also set. There is a default handler installed
+that pairs with the default ExternEnt handler.
+
+If you're going to install your own ExternEnt handler, then you should
+set (or unset) this handler too.
+
+=head2 Entity                (Expat, Name, Val, Sysid, Pubid, Ndata, IsParam)
+
+This is called when an entity is declared. For internal entities, the Val
+parameter will contain the value and the remaining three parameters will be
+undefined. For external entities, the Val parameter will be undefined, the
+Sysid parameter will have the system id, the Pubid parameter will have the
+public id if it was provided (it will be undefined otherwise), the Ndata
+parameter will contain the notation for unparsed entities. If this is a
+parameter entity declaration, then the IsParam parameter is true.
+
+Note that this handler and the Unparsed handler above overlap. If both are
+set, then this handler will not be called for unparsed entities.
+
+=head2 Element                (Expat, Name, Model)
+
+The element handler is called when an element declaration is found. Name
+is the element name, and Model is the content model as an XML::Parser::Content
+object. See L<XML::Parser::Expat/"XML::Parser::ContentModel Methods">
+for methods available for this class.
+
+=head2 Attlist                (Expat, Elname, Attname, Type, Default, Fixed)
+
+This handler is called for each attribute in an ATTLIST declaration.
+So an ATTLIST declaration that has multiple attributes will generate multiple
+calls to this handler. The Elname parameter is the name of the element with
+which the attribute is being associated. The Attname parameter is the name
+of the attribute. Type is the attribute type, given as a string. Default is
+the default value, which will either be "#REQUIRED", "#IMPLIED" or a quoted
+string (i.e. the returned string will begin and end with a quote character).
+If Fixed is true, then this is a fixed attribute.
+
+=head2 Doctype                (Expat, Name, Sysid, Pubid, Internal)
+
+This handler is called for DOCTYPE declarations. Name is the document type
+name. Sysid is the system id of the document type, if it was provided,
+otherwise it's undefined. Pubid is the public id of the document type,
+which will be undefined if no public id was given. Internal is the internal
+subset, given as a string. If there was no internal subset, it will be
+undefined. Internal will contain all whitespace, comments, processing
+instructions, and declarations seen in the internal subset. The declarations
+will be there whether or not they have been processed by another handler
+(except for unparsed entities processed by the Unparsed handler). However,
+comments and processing instructions will not appear if they've been processed
+by their respective handlers.
+
+=head2 * DoctypeFin                (Parser)
+
+This handler is called after parsing of the DOCTYPE declaration has finished,
+including any internal or external DTD declarations.
+
+=head2 XMLDecl                (Expat, Version, Encoding, Standalone)
+
+This handler is called for xml declarations. Version is a string containg
+the version. Encoding is either undefined or contains an encoding string.
+Standalone will be either true, false, or undefined if the standalone attribute
+is yes, no, or not made respectively.
+
+=head1 STYLES
+
+=head2 Debug
+
+This just prints out the document in outline form. Nothing special is
+returned by parse.
+
+=head2 Subs
+
+Each time an element starts, a sub by that name in the package specified
+by the Pkg option is called with the same parameters that the Start
+handler gets called with.
+
+Each time an element ends, a sub with that name appended with an underscore
+("_"), is called with the same parameters that the End handler gets called
+with.
+
+Nothing special is returned by parse.
+
+=head2 Tree
+
+Parse will return a parse tree for the document. Each node in the tree
+takes the form of a tag, content pair. Text nodes are represented with
+a pseudo-tag of "0" and the string that is their content. For elements,
+the content is an array reference. The first item in the array is a
+(possibly empty) hash reference containing attributes. The remainder of
+the array is a sequence of tag-content pairs representing the content
+of the element.
+
+So for example the result of parsing:
+
+  <foo><head id="a">Hello <em>there</em></head><bar>Howdy<ref/></bar>do</foo>
+
+would be:
+
+             Tag   Content
+  ==================================================================
+  [foo, [{}, head, [{id => "a"}, 0, "Hello ",  em, [{}, 0, "there"]],
+              bar, [         {}, 0, "Howdy",  ref, [{}]],
+                0, "do"
+        ]
+  ]
+
+The root document "foo", has 3 children: a "head" element, a "bar"
+element and the text "do". After the empty attribute hash, these are
+represented in it's contents by 3 tag-content pairs.
+
+=head2 Objects
+
+This is similar to the Tree style, except that a hash object is created for
+each element. The corresponding object will be in the class whose name
+is created by appending "::" and the element name to the package set with
+the Pkg option. Non-markup text will be in the ::Characters class. The
+contents of the corresponding object will be in an anonymous array that
+is the value of the Kids property for that object.
+
+=head2 Stream
+
+This style also uses the Pkg package. If none of the subs that this
+style looks for is there, then the effect of parsing with this style is
+to print a canonical copy of the document without comments or declarations.
+All the subs receive as their 1st parameter the Expat instance for the
+document they're parsing.
+
+It looks for the following routines:
+
+=over 4
+
+=item * StartDocument
+
+Called at the start of the parse .
+
+=item * StartTag
+
+Called for every start tag with a second parameter of the element type. The $_
+variable will contain a copy of the tag and the %_ variable will contain
+attribute values supplied for that element.
+
+=item * EndTag
+
+Called for every end tag with a second parameter of the element type. The $_
+variable will contain a copy of the end tag.
+
+=item * Text
+
+Called just before start or end tags with accumulated non-markup text in
+the $_ variable.
+
+=item * PI
+
+Called for processing instructions. The $_ variable will contain a copy of
+the PI and the target and data are sent as 2nd and 3rd parameters
+respectively.
+
+=item * EndDocument
+
+Called at conclusion of the parse.
+
+=back
+
+=head1 ENCODINGS
+
+XML documents may be encoded in character sets other than Unicode as
+long as they may be mapped into the Unicode character set. Expat has
+further restrictions on encodings. Read the xmlparse.h header file in
+the expat distribution to see details on these restrictions.
+
+Expat has built-in encodings for: C<UTF-8>, C<ISO-8859-1>, C<UTF-16>, and
+C<US-ASCII>. Encodings are set either through the XML declaration
+encoding attribute or through the ProtocolEncoding option to XML::Parser
+or XML::Parser::Expat.
+
+For encodings other than the built-ins, expat calls the function
+load_encoding in the Expat package with the encoding name. This function
+looks for a file in the path list @XML::Parser::Expat::Encoding_Path, that
+matches the lower-cased name with a '.enc' extension. The first one it
+finds, it loads.
+
+If you wish to build your own encoding maps, check out the XML::Encoding
+module from CPAN.
+
+=head1 AUTHORS
+
+Larry Wall <F<larry@wall.org>> wrote version 1.0.
+
+Clark Cooper <F<coopercc@netheaven.com>> picked up support, changed the API
+for this version (2.x), provided documentation,
+and added some standard package features.
+
+Matt Sergeant <F<matt@sergeant.org>> is now maintaining XML::Parser
+
+=cut
diff -rupN RELEASE-1.5.5/XML/RegExp.pm ROUGE-1.5.5/XML/RegExp.pm
--- RELEASE-1.5.5/XML/RegExp.pm	1969-12-31 18:00:00.000000000 -0600
+++ ROUGE-1.5.5/XML/RegExp.pm	2010-11-16 08:48:10.000000000 -0600
@@ -0,0 +1,82 @@
+package XML::RegExp;
+
+use vars qw( $BaseChar $Ideographic $Letter $Digit $Extender 
+	     $CombiningChar $NameChar 
+	     $EntityRef $CharRef $Reference
+	     $Name $NmToken $AttValue
+	     $NCNameChar $NCName $Prefix $LocalPart $QName 
+	     $VERSION );
+
+$VERSION = '0.02';
+
+$BaseChar = '(?:[a-zA-Z]|\xC3[\x80-\x96\x98-\xB6\xB8-\xBF]|\xC4[\x80-\xB1\xB4-\xBE]|\xC5[\x81-\x88\x8A-\xBE]|\xC6[\x80-\xBF]|\xC7[\x80-\x83\x8D-\xB0\xB4\xB5\xBA-\xBF]|\xC8[\x80-\x97]|\xC9[\x90-\xBF]|\xCA[\x80-\xA8\xBB-\xBF]|\xCB[\x80\x81]|\xCE[\x86\x88-\x8A\x8C\x8E-\xA1\xA3-\xBF]|\xCF[\x80-\x8E\x90-\x96\x9A\x9C\x9E\xA0\xA2-\xB3]|\xD0[\x81-\x8C\x8E-\xBF]|\xD1[\x80-\x8F\x91-\x9C\x9E-\xBF]|\xD2[\x80\x81\x90-\xBF]|\xD3[\x80-\x84\x87\x88\x8B\x8C\x90-\xAB\xAE-\xB5\xB8\xB9]|\xD4[\xB1-\xBF]|\xD5[\x80-\x96\x99\xA1-\xBF]|\xD6[\x80-\x86]|\xD7[\x90-\xAA\xB0-\xB2]|\xD8[\xA1-\xBA]|\xD9[\x81-\x8A\xB1-\xBF]|\xDA[\x80-\xB7\xBA-\xBE]|\xDB[\x80-\x8E\x90-\x93\x95\xA5\xA6]|\xE0(?:\xA4[\x85-\xB9\xBD]|\xA5[\x98-\xA1]|\xA6[\x85-\x8C\x8F\x90\x93-\xA8\xAA-\xB0\xB2\xB6-\xB9]|\xA7[\x9C\x9D\x9F-\xA1\xB0\xB1]|\xA8[\x85-\x8A\x8F\x90\x93-\xA8\xAA-\xB0\xB2\xB3\xB5\xB6\xB8\xB9]|\xA9[\x99-\x9C\x9E\xB2-\xB4]|\xAA[\x85-\x8B\x8D\x8F-\x91\x93-\xA8\xAA-\xB0\xB2\xB3\xB5-\xB9\xBD]|\xAB\xA0|\xAC[\x85-\x8C\x8F\x90\x93-\xA8\xAA-\xB0\xB2\xB3\xB6-\xB9\xBD]|\xAD[\x9C\x9D\x9F-\xA1]|\xAE[\x85-\x8A\x8E-\x90\x92-\x95\x99\x9A\x9C\x9E\x9F\xA3\xA4\xA8-\xAA\xAE-\xB5\xB7-\xB9]|\xB0[\x85-\x8C\x8E-\x90\x92-\xA8\xAA-\xB3\xB5-\xB9]|\xB1[\xA0\xA1]|\xB2[\x85-\x8C\x8E-\x90\x92-\xA8\xAA-\xB3\xB5-\xB9]|\xB3[\x9E\xA0\xA1]|\xB4[\x85-\x8C\x8E-\x90\x92-\xA8\xAA-\xB9]|\xB5[\xA0\xA1]|\xB8[\x81-\xAE\xB0\xB2\xB3]|\xB9[\x80-\x85]|\xBA[\x81\x82\x84\x87\x88\x8A\x8D\x94-\x97\x99-\x9F\xA1-\xA3\xA5\xA7\xAA\xAB\xAD\xAE\xB0\xB2\xB3\xBD]|\xBB[\x80-\x84]|\xBD[\x80-\x87\x89-\xA9])|\xE1(?:\x82[\xA0-\xBF]|\x83[\x80-\x85\x90-\xB6]|\x84[\x80\x82\x83\x85-\x87\x89\x8B\x8C\x8E-\x92\xBC\xBE]|\x85[\x80\x8C\x8E\x90\x94\x95\x99\x9F-\xA1\xA3\xA5\xA7\xA9\xAD\xAE\xB2\xB3\xB5]|\x86[\x9E\xA8\xAB\xAE\xAF\xB7\xB8\xBA\xBC-\xBF]|\x87[\x80-\x82\xAB\xB0\xB9]|[\xB8\xB9][\x80-\xBF]|\xBA[\x80-\x9B\xA0-\xBF]|\xBB[\x80-\xB9]|\xBC[\x80-\x95\x98-\x9D\xA0-\xBF]|\xBD[\x80-\x85\x88-\x8D\x90-\x97\x99\x9B\x9D\x9F-\xBD]|\xBE[\x80-\xB4\xB6-\xBC\xBE]|\xBF[\x82-\x84\x86-\x8C\x90-\x93\x96-\x9B\xA0-\xAC\xB2-\xB4\xB6-\xBC])|\xE2(?:\x84[\xA6\xAA\xAB\xAE]|\x86[\x80-\x82])|\xE3(?:\x81[\x81-\xBF]|\x82[\x80-\x94\xA1-\xBF]|\x83[\x80-\xBA]|\x84[\x85-\xAC])|\xEA(?:[\xB0-\xBF][\x80-\xBF])|\xEB(?:[\x80-\xBF][\x80-\xBF])|\xEC(?:[\x80-\xBF][\x80-\xBF])|\xED(?:[\x80-\x9D][\x80-\xBF]|\x9E[\x80-\xA3]))';
+
+$Ideographic = '(?:\xE3\x80[\x87\xA1-\xA9]|\xE4(?:[\xB8-\xBF][\x80-\xBF])|\xE5(?:[\x80-\xBF][\x80-\xBF])|\xE6(?:[\x80-\xBF][\x80-\xBF])|\xE7(?:[\x80-\xBF][\x80-\xBF])|\xE8(?:[\x80-\xBF][\x80-\xBF])|\xE9(?:[\x80-\xBD][\x80-\xBF]|\xBE[\x80-\xA5]))';
+
+$Digit = '(?:[0-9]|\xD9[\xA0-\xA9]|\xDB[\xB0-\xB9]|\xE0(?:\xA5[\xA6-\xAF]|\xA7[\xA6-\xAF]|\xA9[\xA6-\xAF]|\xAB[\xA6-\xAF]|\xAD[\xA6-\xAF]|\xAF[\xA7-\xAF]|\xB1[\xA6-\xAF]|\xB3[\xA6-\xAF]|\xB5[\xA6-\xAF]|\xB9[\x90-\x99]|\xBB[\x90-\x99]|\xBC[\xA0-\xA9]))';
+
+$Extender = '(?:\xC2\xB7|\xCB[\x90\x91]|\xCE\x87|\xD9\x80|\xE0(?:\xB9\x86|\xBB\x86)|\xE3(?:\x80[\x85\xB1-\xB5]|\x82[\x9D\x9E]|\x83[\xBC-\xBE]))';
+
+$CombiningChar = '(?:\xCC[\x80-\xBF]|\xCD[\x80-\x85\xA0\xA1]|\xD2[\x83-\x86]|\xD6[\x91-\xA1\xA3-\xB9\xBB-\xBD\xBF]|\xD7[\x81\x82\x84]|\xD9[\x8B-\x92\xB0]|\xDB[\x96-\xA4\xA7\xA8\xAA-\xAD]|\xE0(?:\xA4[\x81-\x83\xBC\xBE\xBF]|\xA5[\x80-\x8D\x91-\x94\xA2\xA3]|\xA6[\x81-\x83\xBC\xBE\xBF]|\xA7[\x80-\x84\x87\x88\x8B-\x8D\x97\xA2\xA3]|\xA8[\x82\xBC\xBE\xBF]|\xA9[\x80-\x82\x87\x88\x8B-\x8D\xB0\xB1]|\xAA[\x81-\x83\xBC\xBE\xBF]|\xAB[\x80-\x85\x87-\x89\x8B-\x8D]|\xAC[\x81-\x83\xBC\xBE\xBF]|\xAD[\x80-\x83\x87\x88\x8B-\x8D\x96\x97]|\xAE[\x82\x83\xBE\xBF]|\xAF[\x80-\x82\x86-\x88\x8A-\x8D\x97]|\xB0[\x81-\x83\xBE\xBF]|\xB1[\x80-\x84\x86-\x88\x8A-\x8D\x95\x96]|\xB2[\x82\x83\xBE\xBF]|\xB3[\x80-\x84\x86-\x88\x8A-\x8D\x95\x96]|\xB4[\x82\x83\xBE\xBF]|\xB5[\x80-\x83\x86-\x88\x8A-\x8D\x97]|\xB8[\xB1\xB4-\xBA]|\xB9[\x87-\x8E]|\xBA[\xB1\xB4-\xB9\xBB\xBC]|\xBB[\x88-\x8D]|\xBC[\x98\x99\xB5\xB7\xB9\xBE\xBF]|\xBD[\xB1-\xBF]|\xBE[\x80-\x84\x86-\x8B\x90-\x95\x97\x99-\xAD\xB1-\xB7\xB9])|\xE2\x83[\x90-\x9C\xA1]|\xE3(?:\x80[\xAA-\xAF]|\x82[\x99\x9A]))';
+
+$Letter	=	 "(?:$BaseChar|$Ideographic)";
+$NameChar	= "(?:[-._:]|$Letter|$Digit|$CombiningChar|$Extender)";
+
+$Name		= "(?:(?:[:_]|$Letter)$NameChar*)";
+$NmToken	= "(?:$NameChar+)";
+$EntityRef	= "(?:\&$Name;)";
+$CharRef	= "(?:\&#(?:[0-9]+|x[0-9a-fA-F]+);)";
+$Reference	= "(?:$EntityRef|$CharRef)";
+
+#?? what if it contains entity references?
+$AttValue     = "(?:\"(?:[^\"&<]*|$Reference)\"|'(?:[^\'&<]|$Reference)*')";
+
+#########################################################################
+# The following definitions came from the XML Namespaces spec:
+#########################################################################
+
+# Same as $NameChar without the ":"
+$NCNameChar	= "(?:[-._]|$Letter|$Digit|$CombiningChar|$Extender)";
+
+# Same as $Name without the colons
+$NCName		= "(?:(?:_|$Letter)$NCNameChar*)";
+
+$Prefix		= $NCName;
+$LocalPart	= $NCName;
+$QName		= "(?:(?:$Prefix:)?$LocalPart)";
+
+return 1;
+
+__END__
+
+=head1 NAME
+
+XML::RegExp - Regular expressions for XML tokens
+
+=head1 SYNOPSIS
+
+ use XML::RegExp;
+
+ if ($my_name =~ /^$XML::RegExp::Name$/)
+ {
+   # $my_name is a valid XML 'Name'
+ }
+
+=head1 DESCRIPTION
+
+This package contains regular expressions for the following XML tokens:
+BaseChar, Ideographic, Letter, Digit, Extender, CombiningChar, NameChar, 
+EntityRef, CharRef, Reference, Name, NmToken, and AttValue.
+
+The definitions of these tokens were taken from the XML spec 
+(Extensible Markup Language 1.0) at L<http://www.w3.org/TR/REC-xml>.
+
+Also contains the regular expressions for the following tokens from the
+XML Namespaces spec at L<http://www.w3.org/TR/REC-xml-names>:
+NCNameChar, NCName, QName, Prefix and LocalPart.
+
+=head1 AUTHOR
+
+Original Author is Enno Derksen <F<enno@att.com>>
+
+Please send bugs, comments and suggestions to T.J. Mather <F<tjmather@tjmather.com>>
